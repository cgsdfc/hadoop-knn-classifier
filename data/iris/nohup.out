+ configFile=/home/cong/Code/demo/data/iris/finetune-config.json
+ jarFile=/home/cong/Code/demo/target/demo-1.0.jar
+ mainClass=com.example.KnnFineTune
+ Kmax=20
+ outputFile=/home/cong/Code/demo/data/iris/result/finetune-result.json
+ mvn package -f /home/cong/Code/demo/pom.xml
[[1;34mINFO[m] Scanning for projects...
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--------------------------< [0;36mcom.example:demo[0;1m >--------------------------[m
[[1;34mINFO[m] [1mBuilding demo 1.0[m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:3.0.2:resources[m [1m(default-resources)[m @ [36mdemo[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cong/Code/demo/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.0:compile[m [1m(default-compile)[m @ [36mdemo[0;1m ---[m
[[1;34mINFO[m] Changes detected - recompiling the module!
[[1;34mINFO[m] Compiling 25 source files to /home/cong/Code/demo/target/classes
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:3.0.2:testResources[m [1m(default-testResources)[m @ [36mdemo[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cong/Code/demo/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.0:testCompile[m [1m(default-testCompile)[m @ [36mdemo[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:2.22.1:test[m [1m(default-test)[m @ [36mdemo[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] Running com.example.[1mKnnClassifierTest[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.081 s - in com.example.[1mKnnClassifierTest[m
[[1;34mINFO[m] Running com.example.[1mVarargsTest[m
a
b
c
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.003 s - in com.example.[1mVarargsTest[m
[[1;34mINFO[m] Running com.example.[1mKSmallestMapTest[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.006 s - in com.example.[1mKSmallestMapTest[m
[[1;34mINFO[m] Running com.example.[1mCarOwnerRecordTest[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 s - in com.example.[1mCarOwnerRecordTest[m
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] [1;32mTests run: 4, Failures: 0, Errors: 0, Skipped: 0[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.0.2:jar[m [1m(default-jar)[m @ [36mdemo[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/cong/Code/demo/target/demo-1.0.jar
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1;32mBUILD SUCCESS[m
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] Total time:  7.292 s
[[1;34mINFO[m] Finished at: 2021-10-10T18:58:23-07:00
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
+ hadoop jar /home/cong/Code/demo/target/demo-1.0.jar com.example.KnnFineTune /home/cong/Code/demo/data/iris/finetune-config.json 20 /home/cong/Code/demo/data/iris/result/finetune-result.json
Exception in thread "main" java.net.ConnectException: Call From hadoop100/192.168.10.100 to hadoop100:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:755)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy9.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:657)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy10.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2420)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2396)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1319)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1316)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1333)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1308)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2275)
	at com.example.KnnEvaluator.setup(KnnEvaluator.java:70)
	at com.example.KnnEvaluator.doEvaluation(KnnEvaluator.java:41)
	at com.example.KnnExperiment.run(KnnExperiment.java:55)
	at com.example.KnnFineTune.findBestParams(KnnFineTune.java:47)
	at com.example.KnnFineTune.run(KnnFineTune.java:76)
	at com.example.KnnFineTune.main(KnnFineTune.java:91)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:318)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:232)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:804)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:421)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1606)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	... 35 more
+ configFile=/home/cong/Code/demo/data/iris/finetune-config.json
+ jarFile=/home/cong/Code/demo/target/demo-1.0.jar
+ mainClass=com.example.KnnFineTune
+ Kmax=20
+ outputFile=/home/cong/Code/demo/data/iris/result/finetune-result.json
+ mvn package -f /home/cong/Code/demo/pom.xml
[[1;34mINFO[m] Scanning for projects...
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--------------------------< [0;36mcom.example:demo[0;1m >--------------------------[m
[[1;34mINFO[m] [1mBuilding demo 1.0[m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:3.0.2:resources[m [1m(default-resources)[m @ [36mdemo[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cong/Code/demo/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.0:compile[m [1m(default-compile)[m @ [36mdemo[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:3.0.2:testResources[m [1m(default-testResources)[m @ [36mdemo[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cong/Code/demo/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.0:testCompile[m [1m(default-testCompile)[m @ [36mdemo[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:2.22.1:test[m [1m(default-test)[m @ [36mdemo[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] Running com.example.[1mKnnClassifierTest[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.136 s - in com.example.[1mKnnClassifierTest[m
[[1;34mINFO[m] Running com.example.[1mVarargsTest[m
a
b
c
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.002 s - in com.example.[1mVarargsTest[m
[[1;34mINFO[m] Running com.example.[1mKSmallestMapTest[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in com.example.[1mKSmallestMapTest[m
[[1;34mINFO[m] Running com.example.[1mCarOwnerRecordTest[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 s - in com.example.[1mCarOwnerRecordTest[m
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] [1;32mTests run: 4, Failures: 0, Errors: 0, Skipped: 0[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.0.2:jar[m [1m(default-jar)[m @ [36mdemo[0;1m ---[m
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1;32mBUILD SUCCESS[m
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] Total time:  5.741 s
[[1;34mINFO[m] Finished at: 2021-10-10T18:59:51-07:00
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
+ hadoop jar /home/cong/Code/demo/target/demo-1.0.jar com.example.KnnFineTune /home/cong/Code/demo/data/iris/finetune-config.json 20 /home/cong/Code/demo/data/iris/result/finetune-result.json
2021-10-10 18:59:54,085 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 18:59:54,587 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 18:59:54,641 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 18:59:54,691 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 18:59:55,004 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 18:59:55,762 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 18:59:55,789 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0001
2021-10-10 18:59:55,853 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 18:59:56,007 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 18:59:56,055 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 18:59:56,093 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 18:59:56,110 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 18:59:56,143 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 18:59:56,405 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 18:59:56,462 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0001
2021-10-10 18:59:56,462 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 18:59:56,717 INFO conf.Configuration: resource-types.xml not found
2021-10-10 18:59:56,718 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-10-10 18:59:57,002 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0001
2021-10-10 18:59:57,047 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0001/
2021-10-10 18:59:57,048 INFO mapreduce.Job: Running job: job_1633917566916_0001
2021-10-10 19:00:10,364 INFO mapreduce.Job: Job job_1633917566916_0001 running in uber mode : false
2021-10-10 19:00:10,373 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:00:16,589 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:00:24,703 INFO mapreduce.Job: Task Id : attempt_1633917566916_0001_r_000000_0, Status : FAILED
[2021-10-10 19:00:23.963]Container [pid=2031,containerID=container_1633917566916_0001_01_000003] is running 308918784B beyond the 'VIRTUAL' memory limit. Current usage: 94.2 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0001_01_000003 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 2031 2029 2031 2031 (bash) 0 0 10162176 677 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0001/container_1633917566916_0001_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0001/container_1633917566916_0001_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.101 42729 attempt_1633917566916_0001_r_000000_0 3 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0001/container_1633917566916_0001_01_000003/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0001/container_1633917566916_0001_01_000003/stderr  
	|- 2042 2031 2031 2031 (java) 101 145 2553614336 23437 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0001/container_1633917566916_0001_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0001/container_1633917566916_0001_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.101 42729 attempt_1633917566916_0001_r_000000_0 3 

[2021-10-10 19:00:24.022]Container killed on request. Exit code is 143
[2021-10-10 19:00:24.070]Container exited with a non-zero exit code 143. 

2021-10-10 19:00:33,845 INFO mapreduce.Job: Task Id : attempt_1633917566916_0001_r_000000_1, Status : FAILED
[2021-10-10 19:00:32.725]Container [pid=5836,containerID=container_1633917566916_0001_01_000004] is running 326945280B beyond the 'VIRTUAL' memory limit. Current usage: 102.5 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0001_01_000004 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 5836 5834 5836 5836 (bash) 0 0 10162176 686 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0001/container_1633917566916_0001_01_000004/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0001/container_1633917566916_0001_01_000004 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.101 42729 attempt_1633917566916_0001_r_000000_1 4 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0001/container_1633917566916_0001_01_000004/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0001/container_1633917566916_0001_01_000004/stderr  
	|- 5847 5836 5836 5836 (java) 239 63 2571640832 25545 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0001/container_1633917566916_0001_01_000004/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0001/container_1633917566916_0001_01_000004 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.101 42729 attempt_1633917566916_0001_r_000000_1 4 

[2021-10-10 19:00:32.774]Container killed on request. Exit code is 143
[2021-10-10 19:00:32.801]Container exited with a non-zero exit code 143. 

2021-10-10 19:00:41,944 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:00:41,955 INFO mapreduce.Job: Job job_1633917566916_0001 completed successfully
2021-10-10 19:00:42,120 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=1470
		FILE: Number of bytes written=439835
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed reduce tasks=2
		Launched map tasks=1
		Launched reduce tasks=3
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3726
		Total time spent by all reduces in occupied slots (ms)=14552
		Total time spent by all map tasks (ms)=3726
		Total time spent by all reduce tasks (ms)=14552
		Total vcore-milliseconds taken by all map tasks=3726
		Total vcore-milliseconds taken by all reduce tasks=14552
		Total megabyte-milliseconds taken by all map tasks=3815424
		Total megabyte-milliseconds taken by all reduce tasks=14901248
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=1416
		Map output materialized bytes=1470
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=1470
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=138
		CPU time spent (ms)=1260
		Physical memory (bytes) snapshot=331534336
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216072192
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115462144
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:00:42,231 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:00:42,262 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:00:42,366 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:00:42,464 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:00:42,484 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:00:42,506 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0002
2021-10-10 19:00:42,562 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:00:42,679 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:00:42,700 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:00:42,798 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:00:42,842 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:00:42,913 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:00:43,013 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0002
2021-10-10 19:00:43,013 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:00:43,100 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0002
2021-10-10 19:00:43,112 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0002/
2021-10-10 19:00:43,115 INFO mapreduce.Job: Running job: job_1633917566916_0002
2021-10-10 19:00:56,379 INFO mapreduce.Job: Job job_1633917566916_0002 running in uber mode : false
2021-10-10 19:00:56,382 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:01:01,454 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:01:07,509 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:01:07,539 INFO mapreduce.Job: Job job_1633917566916_0002 completed successfully
2021-10-10 19:01:07,583 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=1470
		FILE: Number of bytes written=439835
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3498
		Total time spent by all reduces in occupied slots (ms)=3325
		Total time spent by all map tasks (ms)=3498
		Total time spent by all reduce tasks (ms)=3325
		Total vcore-milliseconds taken by all map tasks=3498
		Total vcore-milliseconds taken by all reduce tasks=3325
		Total megabyte-milliseconds taken by all map tasks=3581952
		Total megabyte-milliseconds taken by all reduce tasks=3404800
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=1416
		Map output materialized bytes=1470
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=1470
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=151
		CPU time spent (ms)=1130
		Physical memory (bytes) snapshot=333062144
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216543232
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=116518912
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:01:07,602 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:01:07,616 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:01:07,641 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:01:07,656 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:01:07,723 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:01:07,739 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:01:07,747 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0003
2021-10-10 19:01:07,767 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:01:07,823 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:01:07,838 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:01:07,865 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:01:07,889 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:01:07,928 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:01:07,932 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:01:07,967 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:01:08,008 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0003
2021-10-10 19:01:08,010 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:01:08,045 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0003
2021-10-10 19:01:08,053 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0003/
2021-10-10 19:01:08,055 INFO mapreduce.Job: Running job: job_1633917566916_0003
2021-10-10 19:01:21,201 INFO mapreduce.Job: Job job_1633917566916_0003 running in uber mode : false
2021-10-10 19:01:21,203 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:01:27,283 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:01:33,335 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:01:33,365 INFO mapreduce.Job: Job job_1633917566916_0003 completed successfully
2021-10-10 19:01:33,418 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=1470
		FILE: Number of bytes written=439835
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3860
		Total time spent by all reduces in occupied slots (ms)=3356
		Total time spent by all map tasks (ms)=3860
		Total time spent by all reduce tasks (ms)=3356
		Total vcore-milliseconds taken by all map tasks=3860
		Total vcore-milliseconds taken by all reduce tasks=3356
		Total megabyte-milliseconds taken by all map tasks=3952640
		Total megabyte-milliseconds taken by all reduce tasks=3436544
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=1416
		Map output materialized bytes=1470
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=1470
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=152
		CPU time spent (ms)=1440
		Physical memory (bytes) snapshot=328007680
		Virtual memory (bytes) snapshot=5163999232
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=212045824
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115961856
		Peak Reduce Virtual memory (bytes)=2586570752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:01:33,442 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:01:33,456 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:01:33,482 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:01:33,496 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:01:33,518 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:01:33,551 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:01:33,570 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:01:33,578 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0004
2021-10-10 19:01:33,599 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:01:33,626 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:01:33,644 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:01:33,669 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:01:33,695 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:01:33,712 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:01:33,738 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:01:33,743 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:01:33,770 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:01:33,805 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0004
2021-10-10 19:01:33,807 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:01:33,833 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0004
2021-10-10 19:01:33,841 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0004/
2021-10-10 19:01:33,844 INFO mapreduce.Job: Running job: job_1633917566916_0004
2021-10-10 19:01:47,091 INFO mapreduce.Job: Job job_1633917566916_0004 running in uber mode : false
2021-10-10 19:01:47,098 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:01:52,181 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:01:58,255 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:01:59,304 INFO mapreduce.Job: Job job_1633917566916_0004 completed successfully
2021-10-10 19:01:59,337 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=1470
		FILE: Number of bytes written=439835
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2945
		Total time spent by all reduces in occupied slots (ms)=3334
		Total time spent by all map tasks (ms)=2945
		Total time spent by all reduce tasks (ms)=3334
		Total vcore-milliseconds taken by all map tasks=2945
		Total vcore-milliseconds taken by all reduce tasks=3334
		Total megabyte-milliseconds taken by all map tasks=3015680
		Total megabyte-milliseconds taken by all reduce tasks=3414016
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=1416
		Map output materialized bytes=1470
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=1470
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=137
		CPU time spent (ms)=1020
		Physical memory (bytes) snapshot=330989568
		Virtual memory (bytes) snapshot=5164003328
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215625728
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115363840
		Peak Reduce Virtual memory (bytes)=2586574848
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:01:59,355 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:01:59,373 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:01:59,406 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:01:59,476 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:01:59,490 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:01:59,498 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0005
2021-10-10 19:01:59,512 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:01:59,545 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:01:59,565 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:01:59,578 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:01:59,622 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:01:59,648 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:01:59,687 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:01:59,718 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:01:59,723 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0005
2021-10-10 19:01:59,725 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:01:59,778 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0005
2021-10-10 19:01:59,785 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0005/
2021-10-10 19:01:59,787 INFO mapreduce.Job: Running job: job_1633917566916_0005
2021-10-10 19:02:12,003 INFO mapreduce.Job: Job job_1633917566916_0005 running in uber mode : false
2021-10-10 19:02:12,005 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:02:17,205 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:02:24,259 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:02:24,271 INFO mapreduce.Job: Job job_1633917566916_0005 completed successfully
2021-10-10 19:02:24,330 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=1470
		FILE: Number of bytes written=439835
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3235
		Total time spent by all reduces in occupied slots (ms)=4352
		Total time spent by all map tasks (ms)=3235
		Total time spent by all reduce tasks (ms)=4352
		Total vcore-milliseconds taken by all map tasks=3235
		Total vcore-milliseconds taken by all reduce tasks=4352
		Total megabyte-milliseconds taken by all map tasks=3312640
		Total megabyte-milliseconds taken by all reduce tasks=4456448
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=1416
		Map output materialized bytes=1470
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=1470
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=135
		CPU time spent (ms)=1160
		Physical memory (bytes) snapshot=323883008
		Virtual memory (bytes) snapshot=5163872256
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216092672
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=107790336
		Peak Reduce Virtual memory (bytes)=2586443776
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:02:24,348 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:02:24,370 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:02:24,395 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:02:24,432 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:02:24,460 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:02:24,468 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:02:24,485 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:02:24,507 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:02:24,522 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:02:24,581 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:02:24,600 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:02:24,605 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0006
2021-10-10 19:02:24,620 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:02:24,646 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:02:24,667 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:02:24,683 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:02:24,717 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:02:24,740 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:02:24,767 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:02:24,808 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0006
2021-10-10 19:02:24,809 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:02:24,856 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0006
2021-10-10 19:02:24,864 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0006/
2021-10-10 19:02:24,866 INFO mapreduce.Job: Running job: job_1633917566916_0006
2021-10-10 19:02:37,066 INFO mapreduce.Job: Job job_1633917566916_0006 running in uber mode : false
2021-10-10 19:02:37,067 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:02:43,148 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:02:50,199 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:02:50,208 INFO mapreduce.Job: Job job_1633917566916_0006 completed successfully
2021-10-10 19:02:50,251 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=1758
		FILE: Number of bytes written=440411
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3981
		Total time spent by all reduces in occupied slots (ms)=3327
		Total time spent by all map tasks (ms)=3981
		Total time spent by all reduce tasks (ms)=3327
		Total vcore-milliseconds taken by all map tasks=3981
		Total vcore-milliseconds taken by all reduce tasks=3327
		Total megabyte-milliseconds taken by all map tasks=4076544
		Total megabyte-milliseconds taken by all reduce tasks=3406848
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=1704
		Map output materialized bytes=1758
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=1758
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=136
		CPU time spent (ms)=2080
		Physical memory (bytes) snapshot=329371648
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=213598208
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115773440
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:02:50,265 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:02:50,280 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:02:50,315 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:02:50,382 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:02:50,411 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:02:50,418 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0007
2021-10-10 19:02:50,451 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:02:50,502 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:02:50,525 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:02:50,565 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:02:50,599 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:02:50,603 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:02:50,625 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:02:50,708 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0007
2021-10-10 19:02:50,710 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:02:50,949 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0007
2021-10-10 19:02:50,969 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0007/
2021-10-10 19:02:50,974 INFO mapreduce.Job: Running job: job_1633917566916_0007
2021-10-10 19:03:03,135 INFO mapreduce.Job: Job job_1633917566916_0007 running in uber mode : false
2021-10-10 19:03:03,139 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:03:08,216 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:03:16,297 INFO mapreduce.Job: Task Id : attempt_1633917566916_0007_r_000000_0, Status : FAILED
[2021-10-10 19:03:15.004]Container [pid=7063,containerID=container_1633917566916_0007_01_000003] is running 329042432B beyond the 'VIRTUAL' memory limit. Current usage: 105.8 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0007_01_000003 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 7063 7061 7063 7063 (bash) 0 1 10162176 680 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0007/container_1633917566916_0007_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0007/container_1633917566916_0007_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.101 40337 attempt_1633917566916_0007_r_000000_0 3 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0007/container_1633917566916_0007_01_000003/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0007/container_1633917566916_0007_01_000003/stderr  
	|- 7074 7063 7063 7063 (java) 192 191 2573737984 26417 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0007/container_1633917566916_0007_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0007/container_1633917566916_0007_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.101 40337 attempt_1633917566916_0007_r_000000_0 3 

[2021-10-10 19:03:15.055]Container killed on request. Exit code is 143
[2021-10-10 19:03:15.075]Container exited with a non-zero exit code 143. 

2021-10-10 19:03:24,399 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:03:24,425 INFO mapreduce.Job: Job job_1633917566916_0007 completed successfully
2021-10-10 19:03:24,497 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=1758
		FILE: Number of bytes written=440411
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed reduce tasks=1
		Launched map tasks=1
		Launched reduce tasks=2
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3012
		Total time spent by all reduces in occupied slots (ms)=9479
		Total time spent by all map tasks (ms)=3012
		Total time spent by all reduce tasks (ms)=9479
		Total vcore-milliseconds taken by all map tasks=3012
		Total vcore-milliseconds taken by all reduce tasks=9479
		Total megabyte-milliseconds taken by all map tasks=3084288
		Total megabyte-milliseconds taken by all reduce tasks=9706496
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=1704
		Map output materialized bytes=1758
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=1758
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=150
		CPU time spent (ms)=1180
		Physical memory (bytes) snapshot=333053952
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215592960
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117460992
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:03:24,514 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:03:24,535 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:03:24,611 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:03:24,721 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:03:24,736 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:03:24,749 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0008
2021-10-10 19:03:24,805 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:03:24,891 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:03:24,916 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:03:24,994 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:03:25,022 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:03:25,043 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:03:25,144 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0008
2021-10-10 19:03:25,146 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:03:25,189 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0008
2021-10-10 19:03:25,200 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0008/
2021-10-10 19:03:25,203 INFO mapreduce.Job: Running job: job_1633917566916_0008
2021-10-10 19:03:36,417 INFO mapreduce.Job: Job job_1633917566916_0008 running in uber mode : false
2021-10-10 19:03:36,418 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:03:42,532 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:03:48,586 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:03:48,594 INFO mapreduce.Job: Job job_1633917566916_0008 completed successfully
2021-10-10 19:03:48,658 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=1758
		FILE: Number of bytes written=440411
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=263
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3271
		Total time spent by all reduces in occupied slots (ms)=3297
		Total time spent by all map tasks (ms)=3271
		Total time spent by all reduce tasks (ms)=3297
		Total vcore-milliseconds taken by all map tasks=3271
		Total vcore-milliseconds taken by all reduce tasks=3297
		Total megabyte-milliseconds taken by all map tasks=3349504
		Total megabyte-milliseconds taken by all reduce tasks=3376128
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=1704
		Map output materialized bytes=1758
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=1758
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=136
		CPU time spent (ms)=1080
		Physical memory (bytes) snapshot=329490432
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=214687744
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=114802688
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=263
2021-10-10 19:03:48,679 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:03:48,690 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:03:48,727 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:03:48,823 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:03:48,850 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:03:48,858 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0009
2021-10-10 19:03:48,873 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:03:48,909 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:03:48,923 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:03:48,968 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:03:49,001 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:03:49,029 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:03:49,075 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0009
2021-10-10 19:03:49,077 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:03:49,313 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0009
2021-10-10 19:03:49,322 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0009/
2021-10-10 19:03:49,324 INFO mapreduce.Job: Running job: job_1633917566916_0009
2021-10-10 19:04:01,474 INFO mapreduce.Job: Job job_1633917566916_0009 running in uber mode : false
2021-10-10 19:04:01,479 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:04:06,559 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:04:13,620 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:04:13,643 INFO mapreduce.Job: Job job_1633917566916_0009 completed successfully
2021-10-10 19:04:13,690 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=1758
		FILE: Number of bytes written=440411
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2956
		Total time spent by all reduces in occupied slots (ms)=3766
		Total time spent by all map tasks (ms)=2956
		Total time spent by all reduce tasks (ms)=3766
		Total vcore-milliseconds taken by all map tasks=2956
		Total vcore-milliseconds taken by all reduce tasks=3766
		Total megabyte-milliseconds taken by all map tasks=3026944
		Total megabyte-milliseconds taken by all reduce tasks=3856384
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=1704
		Map output materialized bytes=1758
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=1758
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=133
		CPU time spent (ms)=1060
		Physical memory (bytes) snapshot=332574720
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216592384
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115982336
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:04:13,711 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:04:13,728 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:04:13,754 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:04:13,840 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:04:13,855 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:04:13,860 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0010
2021-10-10 19:04:13,871 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:04:13,905 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:04:13,922 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:04:13,948 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:04:13,971 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:04:14,002 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:04:14,041 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:04:14,045 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0010
2021-10-10 19:04:14,047 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:04:14,074 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0010
2021-10-10 19:04:14,079 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0010/
2021-10-10 19:04:14,081 INFO mapreduce.Job: Running job: job_1633917566916_0010
2021-10-10 19:04:26,294 INFO mapreduce.Job: Job job_1633917566916_0010 running in uber mode : false
2021-10-10 19:04:26,295 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:04:32,386 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:04:37,448 INFO mapreduce.Job: Task Id : attempt_1633917566916_0010_r_000000_0, Status : FAILED
[2021-10-10 19:04:36.261]Container [pid=7924,containerID=container_1633917566916_0010_01_000003] is running 326945280B beyond the 'VIRTUAL' memory limit. Current usage: 105.0 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0010_01_000003 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 7924 7922 7924 7924 (bash) 0 0 10162176 697 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0010/container_1633917566916_0010_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0010/container_1633917566916_0010_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.102 42349 attempt_1633917566916_0010_r_000000_0 3 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0010/container_1633917566916_0010_01_000003/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0010/container_1633917566916_0010_01_000003/stderr  
	|- 7935 7924 7924 7924 (java) 228 60 2571640832 26175 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0010/container_1633917566916_0010_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0010/container_1633917566916_0010_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.102 42349 attempt_1633917566916_0010_r_000000_0 3 

[2021-10-10 19:04:36.296]Container killed on request. Exit code is 143
[2021-10-10 19:04:36.300]Container exited with a non-zero exit code 143. 

2021-10-10 19:04:45,547 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:04:45,581 INFO mapreduce.Job: Job job_1633917566916_0010 completed successfully
2021-10-10 19:04:45,669 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=1758
		FILE: Number of bytes written=440411
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=263
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed reduce tasks=1
		Launched map tasks=1
		Launched reduce tasks=2
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3420
		Total time spent by all reduces in occupied slots (ms)=7772
		Total time spent by all map tasks (ms)=3420
		Total time spent by all reduce tasks (ms)=7772
		Total vcore-milliseconds taken by all map tasks=3420
		Total vcore-milliseconds taken by all reduce tasks=7772
		Total megabyte-milliseconds taken by all map tasks=3502080
		Total megabyte-milliseconds taken by all reduce tasks=7958528
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=1704
		Map output materialized bytes=1758
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=1758
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=165
		CPU time spent (ms)=1200
		Physical memory (bytes) snapshot=330113024
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=214114304
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115998720
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=263
2021-10-10 19:04:45,679 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:04:45,693 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:04:45,752 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:04:45,813 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:04:45,829 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:04:45,850 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:04:45,892 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:04:45,918 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:04:45,924 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0011
2021-10-10 19:04:45,942 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:04:45,975 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:04:45,987 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:04:46,010 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:04:46,033 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:04:46,046 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:04:46,071 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:04:46,096 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:04:46,143 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0011
2021-10-10 19:04:46,146 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:04:46,197 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0011
2021-10-10 19:04:46,205 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0011/
2021-10-10 19:04:46,209 INFO mapreduce.Job: Running job: job_1633917566916_0011
2021-10-10 19:04:58,388 INFO mapreduce.Job: Job job_1633917566916_0011 running in uber mode : false
2021-10-10 19:04:58,392 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:05:03,494 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:05:09,566 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:05:09,600 INFO mapreduce.Job: Job job_1633917566916_0011 completed successfully
2021-10-10 19:05:09,647 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=2046
		FILE: Number of bytes written=440987
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3249
		Total time spent by all reduces in occupied slots (ms)=3298
		Total time spent by all map tasks (ms)=3249
		Total time spent by all reduce tasks (ms)=3298
		Total vcore-milliseconds taken by all map tasks=3249
		Total vcore-milliseconds taken by all reduce tasks=3298
		Total megabyte-milliseconds taken by all map tasks=3326976
		Total megabyte-milliseconds taken by all reduce tasks=3377152
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=1992
		Map output materialized bytes=2046
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=2046
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=161
		CPU time spent (ms)=1200
		Physical memory (bytes) snapshot=330510336
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=213786624
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=116723712
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:05:09,661 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:05:09,675 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:05:09,742 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:05:09,783 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:05:09,800 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:05:09,808 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0012
2021-10-10 19:05:09,818 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:05:09,851 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:05:09,867 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:05:09,898 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:05:09,924 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:05:09,949 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:05:09,971 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0012
2021-10-10 19:05:09,973 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:05:09,997 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0012
2021-10-10 19:05:10,007 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0012/
2021-10-10 19:05:10,009 INFO mapreduce.Job: Running job: job_1633917566916_0012
2021-10-10 19:05:24,281 INFO mapreduce.Job: Job job_1633917566916_0012 running in uber mode : false
2021-10-10 19:05:24,286 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:05:31,451 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:05:37,491 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:05:37,500 INFO mapreduce.Job: Job job_1633917566916_0012 completed successfully
2021-10-10 19:05:37,545 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=2046
		FILE: Number of bytes written=440987
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=4070
		Total time spent by all reduces in occupied slots (ms)=3399
		Total time spent by all map tasks (ms)=4070
		Total time spent by all reduce tasks (ms)=3399
		Total vcore-milliseconds taken by all map tasks=4070
		Total vcore-milliseconds taken by all reduce tasks=3399
		Total megabyte-milliseconds taken by all map tasks=4167680
		Total megabyte-milliseconds taken by all reduce tasks=3480576
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=1992
		Map output materialized bytes=2046
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=2046
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=160
		CPU time spent (ms)=1120
		Physical memory (bytes) snapshot=318857216
		Virtual memory (bytes) snapshot=5163855872
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=200155136
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=118702080
		Peak Reduce Virtual memory (bytes)=2586427392
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:05:37,559 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:05:37,575 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:05:37,602 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:05:37,685 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:05:37,703 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:05:37,709 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0013
2021-10-10 19:05:37,726 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:05:37,766 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:05:37,784 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:05:37,808 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:05:37,831 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:05:37,853 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:05:37,887 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:05:37,889 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0013
2021-10-10 19:05:37,890 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:05:37,913 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0013
2021-10-10 19:05:37,919 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0013/
2021-10-10 19:05:37,920 INFO mapreduce.Job: Running job: job_1633917566916_0013
2021-10-10 19:05:52,087 INFO mapreduce.Job: Job job_1633917566916_0013 running in uber mode : false
2021-10-10 19:05:52,090 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:05:59,181 INFO mapreduce.Job: Task Id : attempt_1633917566916_0013_m_000000_0, Status : FAILED
[2021-10-10 19:05:57.706]Container [pid=8746,containerID=container_1633917566916_0013_01_000002] is running 322570752B beyond the 'VIRTUAL' memory limit. Current usage: 205.6 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0013_01_000002 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 8764 8746 8746 8746 (java) 212 183 2567266304 51949 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0013/container_1633917566916_0013_01_000002/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0013/container_1633917566916_0013_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.10.101 42373 attempt_1633917566916_0013_m_000000_0 2 
	|- 8746 8743 8746 8746 (bash) 0 0 10162176 682 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0013/container_1633917566916_0013_01_000002/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0013/container_1633917566916_0013_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.10.101 42373 attempt_1633917566916_0013_m_000000_0 2 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0013/container_1633917566916_0013_01_000002/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0013/container_1633917566916_0013_01_000002/stderr  

[2021-10-10 19:05:57.730]Container killed on request. Exit code is 143
[2021-10-10 19:05:57.752]Container exited with a non-zero exit code 143. 

2021-10-10 19:06:05,241 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:06:11,292 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:06:12,323 INFO mapreduce.Job: Job job_1633917566916_0013 completed successfully
2021-10-10 19:06:12,366 INFO mapreduce.Job: Counters: 55
	File System Counters
		FILE: Number of bytes read=2046
		FILE: Number of bytes written=440987
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed map tasks=1
		Launched map tasks=2
		Launched reduce tasks=1
		Other local map tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=8854
		Total time spent by all reduces in occupied slots (ms)=3196
		Total time spent by all map tasks (ms)=8854
		Total time spent by all reduce tasks (ms)=3196
		Total vcore-milliseconds taken by all map tasks=8854
		Total vcore-milliseconds taken by all reduce tasks=3196
		Total megabyte-milliseconds taken by all map tasks=9066496
		Total megabyte-milliseconds taken by all reduce tasks=3272704
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=1992
		Map output materialized bytes=2046
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=2046
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=146
		CPU time spent (ms)=1190
		Physical memory (bytes) snapshot=334450688
		Virtual memory (bytes) snapshot=5163855872
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216449024
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=118001664
		Peak Reduce Virtual memory (bytes)=2586427392
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:06:12,380 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:06:12,396 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:06:12,422 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:06:12,499 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:06:12,515 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:06:12,520 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0014
2021-10-10 19:06:12,534 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:06:12,569 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:06:12,578 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:06:12,613 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:06:12,644 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:06:12,663 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:06:12,735 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0014
2021-10-10 19:06:12,737 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:06:12,962 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0014
2021-10-10 19:06:12,974 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0014/
2021-10-10 19:06:12,974 INFO mapreduce.Job: Running job: job_1633917566916_0014
2021-10-10 19:06:25,140 INFO mapreduce.Job: Job job_1633917566916_0014 running in uber mode : false
2021-10-10 19:06:25,140 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:06:30,192 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:06:36,226 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:06:36,270 INFO mapreduce.Job: Job job_1633917566916_0014 completed successfully
2021-10-10 19:06:36,311 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=2046
		FILE: Number of bytes written=440987
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3036
		Total time spent by all reduces in occupied slots (ms)=3185
		Total time spent by all map tasks (ms)=3036
		Total time spent by all reduce tasks (ms)=3185
		Total vcore-milliseconds taken by all map tasks=3036
		Total vcore-milliseconds taken by all reduce tasks=3185
		Total megabyte-milliseconds taken by all map tasks=3108864
		Total megabyte-milliseconds taken by all reduce tasks=3261440
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=1992
		Map output materialized bytes=2046
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=2046
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=139
		CPU time spent (ms)=1160
		Physical memory (bytes) snapshot=329195520
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=213553152
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115642368
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:06:36,327 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:06:36,344 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:06:36,359 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:06:36,370 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:06:36,415 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:06:36,430 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:06:36,435 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0015
2021-10-10 19:06:36,444 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:06:36,485 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:06:36,512 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:06:36,547 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:06:36,569 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:06:36,587 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:06:36,623 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0015
2021-10-10 19:06:36,623 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:06:36,660 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0015
2021-10-10 19:06:36,669 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0015/
2021-10-10 19:06:36,671 INFO mapreduce.Job: Running job: job_1633917566916_0015
2021-10-10 19:06:48,844 INFO mapreduce.Job: Job job_1633917566916_0015 running in uber mode : false
2021-10-10 19:06:48,844 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:06:54,922 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:07:03,014 INFO mapreduce.Job: Task Id : attempt_1633917566916_0015_r_000000_0, Status : FAILED
[2021-10-10 19:07:00.976]Container [pid=9342,containerID=container_1633917566916_0015_01_000003] is running 331561472B beyond the 'VIRTUAL' memory limit. Current usage: 109.1 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0015_01_000003 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 9342 9340 9342 9342 (bash) 0 0 10162176 697 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0015/container_1633917566916_0015_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0015/container_1633917566916_0015_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.101 43935 attempt_1633917566916_0015_r_000000_0 3 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0015/container_1633917566916_0015_01_000003/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0015/container_1633917566916_0015_01_000003/stderr  
	|- 9353 9342 9342 9342 (java) 285 138 2576257024 27234 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0015/container_1633917566916_0015_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0015/container_1633917566916_0015_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.101 43935 attempt_1633917566916_0015_r_000000_0 3 

[2021-10-10 19:07:01.044]Container killed on request. Exit code is 143
[2021-10-10 19:07:01.047]Container exited with a non-zero exit code 143. 

2021-10-10 19:07:10,082 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:07:10,091 INFO mapreduce.Job: Job job_1633917566916_0015 completed successfully
2021-10-10 19:07:10,132 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=2046
		FILE: Number of bytes written=440987
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed reduce tasks=1
		Launched map tasks=1
		Launched reduce tasks=2
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3010
		Total time spent by all reduces in occupied slots (ms)=9571
		Total time spent by all map tasks (ms)=3010
		Total time spent by all reduce tasks (ms)=9571
		Total vcore-milliseconds taken by all map tasks=3010
		Total vcore-milliseconds taken by all reduce tasks=9571
		Total megabyte-milliseconds taken by all map tasks=3082240
		Total megabyte-milliseconds taken by all reduce tasks=9800704
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=1992
		Map output materialized bytes=2046
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=2046
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=136
		CPU time spent (ms)=1050
		Physical memory (bytes) snapshot=329269248
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=214548480
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=114720768
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:07:10,165 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:07:10,201 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:07:10,316 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:07:10,339 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:07:10,358 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:07:10,384 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:07:10,464 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:07:10,552 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:07:10,580 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:07:10,591 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0016
2021-10-10 19:07:10,619 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:07:10,709 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:07:10,735 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:07:10,799 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:07:10,841 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:07:10,893 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:07:10,964 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0016
2021-10-10 19:07:10,964 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:07:11,002 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0016
2021-10-10 19:07:11,015 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0016/
2021-10-10 19:07:11,016 INFO mapreduce.Job: Running job: job_1633917566916_0016
2021-10-10 19:07:24,177 INFO mapreduce.Job: Job job_1633917566916_0016 running in uber mode : false
2021-10-10 19:07:24,177 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:07:29,220 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:07:36,292 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:07:36,317 INFO mapreduce.Job: Job job_1633917566916_0016 completed successfully
2021-10-10 19:07:36,370 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=2334
		FILE: Number of bytes written=441563
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3047
		Total time spent by all reduces in occupied slots (ms)=3864
		Total time spent by all map tasks (ms)=3047
		Total time spent by all reduce tasks (ms)=3864
		Total vcore-milliseconds taken by all map tasks=3047
		Total vcore-milliseconds taken by all reduce tasks=3864
		Total megabyte-milliseconds taken by all map tasks=3120128
		Total megabyte-milliseconds taken by all reduce tasks=3956736
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=2280
		Map output materialized bytes=2334
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=2334
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=171
		CPU time spent (ms)=1090
		Physical memory (bytes) snapshot=330362880
		Virtual memory (bytes) snapshot=5163999232
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=214974464
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115388416
		Peak Reduce Virtual memory (bytes)=2586570752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:07:36,388 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:07:36,400 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:07:36,433 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:07:36,486 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:07:36,510 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:07:36,514 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0017
2021-10-10 19:07:36,527 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:07:36,546 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:07:36,558 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:07:36,569 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:07:36,589 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:07:36,603 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:07:36,622 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:07:36,627 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:07:36,647 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:07:36,689 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0017
2021-10-10 19:07:36,691 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:07:36,709 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0017
2021-10-10 19:07:36,715 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0017/
2021-10-10 19:07:36,717 INFO mapreduce.Job: Running job: job_1633917566916_0017
2021-10-10 19:07:48,917 INFO mapreduce.Job: Job job_1633917566916_0017 running in uber mode : false
2021-10-10 19:07:48,921 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:07:54,124 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:08:00,194 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:08:00,221 INFO mapreduce.Job: Job job_1633917566916_0017 completed successfully
2021-10-10 19:08:00,288 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=2334
		FILE: Number of bytes written=441563
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3326
		Total time spent by all reduces in occupied slots (ms)=3230
		Total time spent by all map tasks (ms)=3326
		Total time spent by all reduce tasks (ms)=3230
		Total vcore-milliseconds taken by all map tasks=3326
		Total vcore-milliseconds taken by all reduce tasks=3230
		Total megabyte-milliseconds taken by all map tasks=3405824
		Total megabyte-milliseconds taken by all reduce tasks=3307520
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=2280
		Map output materialized bytes=2334
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=2334
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=141
		CPU time spent (ms)=1320
		Physical memory (bytes) snapshot=330334208
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=213430272
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=116903936
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:08:00,298 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:08:00,313 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:08:00,349 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:08:00,374 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:08:00,401 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:08:00,414 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:08:00,419 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0018
2021-10-10 19:08:00,427 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:08:00,443 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:08:00,475 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:08:00,488 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:08:00,509 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:08:00,534 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:08:00,551 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:08:00,597 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0018
2021-10-10 19:08:00,597 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:08:00,631 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0018
2021-10-10 19:08:00,636 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0018/
2021-10-10 19:08:00,636 INFO mapreduce.Job: Running job: job_1633917566916_0018
2021-10-10 19:08:12,810 INFO mapreduce.Job: Job job_1633917566916_0018 running in uber mode : false
2021-10-10 19:08:12,813 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:08:17,882 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:08:23,928 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:08:23,948 INFO mapreduce.Job: Job job_1633917566916_0018 completed successfully
2021-10-10 19:08:24,012 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=2334
		FILE: Number of bytes written=441563
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2924
		Total time spent by all reduces in occupied slots (ms)=3471
		Total time spent by all map tasks (ms)=2924
		Total time spent by all reduce tasks (ms)=3471
		Total vcore-milliseconds taken by all map tasks=2924
		Total vcore-milliseconds taken by all reduce tasks=3471
		Total megabyte-milliseconds taken by all map tasks=2994176
		Total megabyte-milliseconds taken by all reduce tasks=3554304
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=2280
		Map output materialized bytes=2334
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=2334
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=189
		CPU time spent (ms)=1070
		Physical memory (bytes) snapshot=333377536
		Virtual memory (bytes) snapshot=5163999232
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215797760
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117579776
		Peak Reduce Virtual memory (bytes)=2586570752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:08:24,022 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:08:24,034 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:08:24,052 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:08:24,064 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:08:24,083 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:08:24,127 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:08:24,150 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:08:24,155 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0019
2021-10-10 19:08:24,165 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:08:24,188 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:08:24,200 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:08:24,211 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:08:24,238 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:08:24,259 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:08:24,279 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:08:24,308 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:08:24,312 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0019
2021-10-10 19:08:24,312 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:08:24,539 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0019
2021-10-10 19:08:24,557 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0019/
2021-10-10 19:08:24,560 INFO mapreduce.Job: Running job: job_1633917566916_0019
2021-10-10 19:08:37,745 INFO mapreduce.Job: Job job_1633917566916_0019 running in uber mode : false
2021-10-10 19:08:37,747 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:08:42,813 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:08:48,851 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:08:49,871 INFO mapreduce.Job: Job job_1633917566916_0019 completed successfully
2021-10-10 19:08:49,915 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=2334
		FILE: Number of bytes written=441563
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2860
		Total time spent by all reduces in occupied slots (ms)=3580
		Total time spent by all map tasks (ms)=2860
		Total time spent by all reduce tasks (ms)=3580
		Total vcore-milliseconds taken by all map tasks=2860
		Total vcore-milliseconds taken by all reduce tasks=3580
		Total megabyte-milliseconds taken by all map tasks=2928640
		Total megabyte-milliseconds taken by all reduce tasks=3665920
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=2280
		Map output materialized bytes=2334
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=2334
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=208
		CPU time spent (ms)=1080
		Physical memory (bytes) snapshot=330833920
		Virtual memory (bytes) snapshot=5164003328
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215695360
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115138560
		Peak Reduce Virtual memory (bytes)=2586574848
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:08:49,931 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:08:49,942 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:08:49,958 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:08:49,967 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:08:49,986 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:08:50,013 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:08:50,025 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:08:50,029 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0020
2021-10-10 19:08:50,039 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:08:50,065 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:08:50,081 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:08:50,101 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:08:50,112 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:08:50,144 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:08:50,171 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:08:50,216 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0020
2021-10-10 19:08:50,217 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:08:50,459 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0020
2021-10-10 19:08:50,463 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0020/
2021-10-10 19:08:50,463 INFO mapreduce.Job: Running job: job_1633917566916_0020
2021-10-10 19:09:01,609 INFO mapreduce.Job: Job job_1633917566916_0020 running in uber mode : false
2021-10-10 19:09:01,610 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:09:07,691 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:09:13,731 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:09:13,740 INFO mapreduce.Job: Job job_1633917566916_0020 completed successfully
2021-10-10 19:09:13,773 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=2334
		FILE: Number of bytes written=441563
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3296
		Total time spent by all reduces in occupied slots (ms)=3393
		Total time spent by all map tasks (ms)=3296
		Total time spent by all reduce tasks (ms)=3393
		Total vcore-milliseconds taken by all map tasks=3296
		Total vcore-milliseconds taken by all reduce tasks=3393
		Total megabyte-milliseconds taken by all map tasks=3375104
		Total megabyte-milliseconds taken by all reduce tasks=3474432
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=2280
		Map output materialized bytes=2334
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=2334
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=129
		CPU time spent (ms)=1580
		Physical memory (bytes) snapshot=328941568
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=213434368
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115507200
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:09:13,782 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:09:13,803 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:09:13,884 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:09:13,913 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:09:13,922 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:09:13,956 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:09:13,997 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:09:14,010 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:09:14,019 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0021
2021-10-10 19:09:14,030 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:09:14,075 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:09:14,089 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:09:14,111 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:09:14,129 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:09:14,147 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:09:14,169 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:09:14,175 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0021
2021-10-10 19:09:14,176 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:09:14,415 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0021
2021-10-10 19:09:14,430 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0021/
2021-10-10 19:09:14,431 INFO mapreduce.Job: Running job: job_1633917566916_0021
2021-10-10 19:09:26,627 INFO mapreduce.Job: Job job_1633917566916_0021 running in uber mode : false
2021-10-10 19:09:26,627 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:09:32,726 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:09:38,776 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:09:38,809 INFO mapreduce.Job: Job job_1633917566916_0021 completed successfully
2021-10-10 19:09:38,916 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=2622
		FILE: Number of bytes written=442139
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2999
		Total time spent by all reduces in occupied slots (ms)=3184
		Total time spent by all map tasks (ms)=2999
		Total time spent by all reduce tasks (ms)=3184
		Total vcore-milliseconds taken by all map tasks=2999
		Total vcore-milliseconds taken by all reduce tasks=3184
		Total megabyte-milliseconds taken by all map tasks=3070976
		Total megabyte-milliseconds taken by all reduce tasks=3260416
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=2568
		Map output materialized bytes=2622
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=2622
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=139
		CPU time spent (ms)=1010
		Physical memory (bytes) snapshot=334114816
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216305664
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117809152
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:09:38,937 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:09:38,949 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:09:38,977 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:09:39,013 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:09:39,031 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:09:39,037 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0022
2021-10-10 19:09:39,047 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:09:39,069 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:09:39,085 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:09:39,108 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:09:39,128 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:09:39,133 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:09:39,155 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:09:39,172 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:09:39,179 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0022
2021-10-10 19:09:39,179 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:09:39,200 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0022
2021-10-10 19:09:39,206 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0022/
2021-10-10 19:09:39,208 INFO mapreduce.Job: Running job: job_1633917566916_0022
2021-10-10 19:09:51,372 INFO mapreduce.Job: Job job_1633917566916_0022 running in uber mode : false
2021-10-10 19:09:51,372 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:09:56,410 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:10:02,464 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:10:02,472 INFO mapreduce.Job: Job job_1633917566916_0022 completed successfully
2021-10-10 19:10:02,529 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=2622
		FILE: Number of bytes written=442139
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3223
		Total time spent by all reduces in occupied slots (ms)=3227
		Total time spent by all map tasks (ms)=3223
		Total time spent by all reduce tasks (ms)=3227
		Total vcore-milliseconds taken by all map tasks=3223
		Total vcore-milliseconds taken by all reduce tasks=3227
		Total megabyte-milliseconds taken by all map tasks=3300352
		Total megabyte-milliseconds taken by all reduce tasks=3304448
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=2568
		Map output materialized bytes=2622
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=2622
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=149
		CPU time spent (ms)=1470
		Physical memory (bytes) snapshot=328478720
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=213450752
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115027968
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:10:02,542 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:10:02,552 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:10:02,569 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:10:02,579 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:10:02,621 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:10:02,648 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:10:02,652 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0023
2021-10-10 19:10:02,669 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:10:02,697 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:10:02,706 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:10:02,731 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:10:02,750 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:10:02,765 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:10:02,784 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:10:02,790 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0023
2021-10-10 19:10:02,790 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:10:02,805 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0023
2021-10-10 19:10:02,810 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0023/
2021-10-10 19:10:02,811 INFO mapreduce.Job: Running job: job_1633917566916_0023
2021-10-10 19:10:15,977 INFO mapreduce.Job: Job job_1633917566916_0023 running in uber mode : false
2021-10-10 19:10:15,981 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:10:21,059 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:10:27,110 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:10:27,124 INFO mapreduce.Job: Job job_1633917566916_0023 completed successfully
2021-10-10 19:10:27,173 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=2622
		FILE: Number of bytes written=442139
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3167
		Total time spent by all reduces in occupied slots (ms)=3158
		Total time spent by all map tasks (ms)=3167
		Total time spent by all reduce tasks (ms)=3158
		Total vcore-milliseconds taken by all map tasks=3167
		Total vcore-milliseconds taken by all reduce tasks=3158
		Total megabyte-milliseconds taken by all map tasks=3243008
		Total megabyte-milliseconds taken by all reduce tasks=3233792
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=2568
		Map output materialized bytes=2622
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=2622
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=143
		CPU time spent (ms)=1270
		Physical memory (bytes) snapshot=328785920
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=213897216
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=114888704
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:10:27,185 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:10:27,196 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:10:27,214 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:10:27,230 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:10:27,249 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:10:27,276 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:10:27,289 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:10:27,293 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0024
2021-10-10 19:10:27,302 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:10:27,316 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:10:27,333 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:10:27,342 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:10:27,362 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:10:27,380 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:10:27,396 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:10:27,400 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:10:27,418 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:10:27,438 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:10:27,443 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0024
2021-10-10 19:10:27,444 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:10:27,466 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0024
2021-10-10 19:10:27,471 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0024/
2021-10-10 19:10:27,473 INFO mapreduce.Job: Running job: job_1633917566916_0024
2021-10-10 19:10:39,687 INFO mapreduce.Job: Job job_1633917566916_0024 running in uber mode : false
2021-10-10 19:10:39,688 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:10:45,854 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:10:51,892 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:10:51,903 INFO mapreduce.Job: Job job_1633917566916_0024 completed successfully
2021-10-10 19:10:51,974 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=2622
		FILE: Number of bytes written=442139
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=263
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3593
		Total time spent by all reduces in occupied slots (ms)=3181
		Total time spent by all map tasks (ms)=3593
		Total time spent by all reduce tasks (ms)=3181
		Total vcore-milliseconds taken by all map tasks=3593
		Total vcore-milliseconds taken by all reduce tasks=3181
		Total megabyte-milliseconds taken by all map tasks=3679232
		Total megabyte-milliseconds taken by all reduce tasks=3257344
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=2568
		Map output materialized bytes=2622
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=2622
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=179
		CPU time spent (ms)=1240
		Physical memory (bytes) snapshot=333058048
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215388160
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117669888
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=263
2021-10-10 19:10:51,996 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:10:52,005 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:10:52,036 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:10:52,053 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:10:52,101 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:10:52,112 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:10:52,116 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0025
2021-10-10 19:10:52,125 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:10:52,140 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:10:52,156 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:10:52,166 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:10:52,189 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:10:52,206 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:10:52,235 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:10:52,266 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0025
2021-10-10 19:10:52,266 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:10:52,284 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0025
2021-10-10 19:10:52,290 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0025/
2021-10-10 19:10:52,292 INFO mapreduce.Job: Running job: job_1633917566916_0025
2021-10-10 19:11:04,446 INFO mapreduce.Job: Job job_1633917566916_0025 running in uber mode : false
2021-10-10 19:11:04,447 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:11:10,501 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:11:15,536 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:11:16,550 INFO mapreduce.Job: Job job_1633917566916_0025 completed successfully
2021-10-10 19:11:16,617 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=2622
		FILE: Number of bytes written=442139
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3311
		Total time spent by all reduces in occupied slots (ms)=3366
		Total time spent by all map tasks (ms)=3311
		Total time spent by all reduce tasks (ms)=3366
		Total vcore-milliseconds taken by all map tasks=3311
		Total vcore-milliseconds taken by all reduce tasks=3366
		Total megabyte-milliseconds taken by all map tasks=3390464
		Total megabyte-milliseconds taken by all reduce tasks=3446784
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=2568
		Map output materialized bytes=2622
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=2622
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=147
		CPU time spent (ms)=1490
		Physical memory (bytes) snapshot=330153984
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=212303872
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117850112
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:11:16,635 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:11:16,646 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:11:16,712 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:11:16,760 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:11:16,777 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:11:16,809 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:11:16,850 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:11:16,862 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:11:16,866 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0026
2021-10-10 19:11:16,874 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:11:16,909 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:11:16,919 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:11:16,958 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:11:16,992 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:11:17,009 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:11:17,038 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0026
2021-10-10 19:11:17,042 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:11:17,263 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0026
2021-10-10 19:11:17,267 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0026/
2021-10-10 19:11:17,267 INFO mapreduce.Job: Running job: job_1633917566916_0026
2021-10-10 19:11:29,455 INFO mapreduce.Job: Job job_1633917566916_0026 running in uber mode : false
2021-10-10 19:11:29,455 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:11:34,515 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:11:40,567 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:11:41,618 INFO mapreduce.Job: Job job_1633917566916_0026 completed successfully
2021-10-10 19:11:41,693 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=2910
		FILE: Number of bytes written=442715
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2924
		Total time spent by all reduces in occupied slots (ms)=3151
		Total time spent by all map tasks (ms)=2924
		Total time spent by all reduce tasks (ms)=3151
		Total vcore-milliseconds taken by all map tasks=2924
		Total vcore-milliseconds taken by all reduce tasks=3151
		Total megabyte-milliseconds taken by all map tasks=2994176
		Total megabyte-milliseconds taken by all reduce tasks=3226624
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=2856
		Map output materialized bytes=2910
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=2910
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=135
		CPU time spent (ms)=1050
		Physical memory (bytes) snapshot=333389824
		Virtual memory (bytes) snapshot=5163995136
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216334336
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117055488
		Peak Reduce Virtual memory (bytes)=2586566656
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:11:41,714 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:11:41,725 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:11:41,759 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:11:41,794 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:11:41,818 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:11:41,822 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0027
2021-10-10 19:11:41,834 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:11:41,888 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:11:41,909 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:11:41,984 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:11:42,012 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:11:42,029 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:11:42,058 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0027
2021-10-10 19:11:42,059 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:11:42,076 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0027
2021-10-10 19:11:42,081 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0027/
2021-10-10 19:11:42,082 INFO mapreduce.Job: Running job: job_1633917566916_0027
2021-10-10 19:11:54,216 INFO mapreduce.Job: Job job_1633917566916_0027 running in uber mode : false
2021-10-10 19:11:54,218 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:11:59,275 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:12:05,308 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:12:06,327 INFO mapreduce.Job: Job job_1633917566916_0027 completed successfully
2021-10-10 19:12:06,360 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=2910
		FILE: Number of bytes written=442715
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3149
		Total time spent by all reduces in occupied slots (ms)=3263
		Total time spent by all map tasks (ms)=3149
		Total time spent by all reduce tasks (ms)=3263
		Total vcore-milliseconds taken by all map tasks=3149
		Total vcore-milliseconds taken by all reduce tasks=3263
		Total megabyte-milliseconds taken by all map tasks=3224576
		Total megabyte-milliseconds taken by all reduce tasks=3341312
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=2856
		Map output materialized bytes=2910
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=2910
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=138
		CPU time spent (ms)=1210
		Physical memory (bytes) snapshot=329326592
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215592960
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=113733632
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:12:06,372 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:12:06,387 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:12:06,418 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:12:06,462 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:12:06,473 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:12:06,477 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0028
2021-10-10 19:12:06,485 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:12:06,511 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:12:06,521 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:12:06,536 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:12:06,546 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:12:06,565 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:12:06,588 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:12:06,610 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0028
2021-10-10 19:12:06,610 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:12:06,624 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0028
2021-10-10 19:12:06,628 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0028/
2021-10-10 19:12:06,628 INFO mapreduce.Job: Running job: job_1633917566916_0028
2021-10-10 19:12:18,792 INFO mapreduce.Job: Job job_1633917566916_0028 running in uber mode : false
2021-10-10 19:12:18,793 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:12:23,855 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:12:29,922 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:12:30,958 INFO mapreduce.Job: Job job_1633917566916_0028 completed successfully
2021-10-10 19:12:31,053 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=2910
		FILE: Number of bytes written=442715
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3185
		Total time spent by all reduces in occupied slots (ms)=3455
		Total time spent by all map tasks (ms)=3185
		Total time spent by all reduce tasks (ms)=3455
		Total vcore-milliseconds taken by all map tasks=3185
		Total vcore-milliseconds taken by all reduce tasks=3455
		Total megabyte-milliseconds taken by all map tasks=3261440
		Total megabyte-milliseconds taken by all reduce tasks=3537920
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=2856
		Map output materialized bytes=2910
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=2910
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=144
		CPU time spent (ms)=1130
		Physical memory (bytes) snapshot=333271040
		Virtual memory (bytes) snapshot=5164273664
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215666688
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117604352
		Peak Reduce Virtual memory (bytes)=2586845184
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:12:31,065 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:12:31,078 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:12:31,102 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:12:31,141 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:12:31,153 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:12:31,158 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0029
2021-10-10 19:12:31,168 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:12:31,191 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:12:31,208 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:12:31,237 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:12:31,253 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:12:31,272 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:12:31,297 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:12:31,301 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0029
2021-10-10 19:12:31,301 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:12:31,320 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0029
2021-10-10 19:12:31,327 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0029/
2021-10-10 19:12:31,328 INFO mapreduce.Job: Running job: job_1633917566916_0029
2021-10-10 19:12:43,492 INFO mapreduce.Job: Job job_1633917566916_0029 running in uber mode : false
2021-10-10 19:12:43,494 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:12:48,579 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:12:54,649 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:12:54,678 INFO mapreduce.Job: Job job_1633917566916_0029 completed successfully
2021-10-10 19:12:54,743 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=2910
		FILE: Number of bytes written=442715
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3051
		Total time spent by all reduces in occupied slots (ms)=3295
		Total time spent by all map tasks (ms)=3051
		Total time spent by all reduce tasks (ms)=3295
		Total vcore-milliseconds taken by all map tasks=3051
		Total vcore-milliseconds taken by all reduce tasks=3295
		Total megabyte-milliseconds taken by all map tasks=3124224
		Total megabyte-milliseconds taken by all reduce tasks=3374080
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=2856
		Map output materialized bytes=2910
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=2910
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=150
		CPU time spent (ms)=1000
		Physical memory (bytes) snapshot=334082048
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215846912
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=118235136
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:12:54,759 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:12:54,775 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:12:54,802 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:12:54,852 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:12:54,864 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:12:54,869 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0030
2021-10-10 19:12:54,877 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:12:54,917 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:12:54,927 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:12:54,954 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:12:54,988 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:12:55,006 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:12:55,028 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:12:55,033 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0030
2021-10-10 19:12:55,034 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:12:55,257 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0030
2021-10-10 19:12:55,268 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0030/
2021-10-10 19:12:55,272 INFO mapreduce.Job: Running job: job_1633917566916_0030
2021-10-10 19:13:08,489 INFO mapreduce.Job: Job job_1633917566916_0030 running in uber mode : false
2021-10-10 19:13:08,489 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:13:14,638 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:13:20,721 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:13:20,750 INFO mapreduce.Job: Job job_1633917566916_0030 completed successfully
2021-10-10 19:13:20,817 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=2910
		FILE: Number of bytes written=442715
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2909
		Total time spent by all reduces in occupied slots (ms)=3167
		Total time spent by all map tasks (ms)=2909
		Total time spent by all reduce tasks (ms)=3167
		Total vcore-milliseconds taken by all map tasks=2909
		Total vcore-milliseconds taken by all reduce tasks=3167
		Total megabyte-milliseconds taken by all map tasks=2978816
		Total megabyte-milliseconds taken by all reduce tasks=3243008
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=2856
		Map output materialized bytes=2910
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=2910
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=136
		CPU time spent (ms)=1040
		Physical memory (bytes) snapshot=330043392
		Virtual memory (bytes) snapshot=5163872256
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=214589440
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115453952
		Peak Reduce Virtual memory (bytes)=2586443776
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:13:20,828 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:13:20,850 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:13:20,875 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:13:20,944 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:13:20,963 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:13:20,971 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:13:20,980 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:13:20,997 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:13:21,006 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:13:21,022 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.closeInternal(DataStreamer.java:847)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:843)
2021-10-10 19:13:21,045 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:13:21,064 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:13:21,069 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0031
2021-10-10 19:13:21,082 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:13:21,109 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:13:21,117 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:13:21,142 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:13:21,162 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:13:21,180 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:13:21,210 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0031
2021-10-10 19:13:21,210 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:13:21,229 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0031
2021-10-10 19:13:21,233 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0031/
2021-10-10 19:13:21,235 INFO mapreduce.Job: Running job: job_1633917566916_0031
2021-10-10 19:13:33,389 INFO mapreduce.Job: Job job_1633917566916_0031 running in uber mode : false
2021-10-10 19:13:33,395 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:13:38,444 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:13:44,486 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:13:44,497 INFO mapreduce.Job: Job job_1633917566916_0031 completed successfully
2021-10-10 19:13:44,530 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=3198
		FILE: Number of bytes written=443291
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2968
		Total time spent by all reduces in occupied slots (ms)=3156
		Total time spent by all map tasks (ms)=2968
		Total time spent by all reduce tasks (ms)=3156
		Total vcore-milliseconds taken by all map tasks=2968
		Total vcore-milliseconds taken by all reduce tasks=3156
		Total megabyte-milliseconds taken by all map tasks=3039232
		Total megabyte-milliseconds taken by all reduce tasks=3231744
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=3144
		Map output materialized bytes=3198
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=3198
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=146
		CPU time spent (ms)=1060
		Physical memory (bytes) snapshot=331608064
		Virtual memory (bytes) snapshot=5163872256
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215982080
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115625984
		Peak Reduce Virtual memory (bytes)=2586443776
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:13:44,541 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:13:44,558 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:13:44,581 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:13:44,622 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:13:44,635 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:13:44,641 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0032
2021-10-10 19:13:44,658 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:13:44,681 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:13:44,694 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:13:44,707 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:13:44,725 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:13:44,744 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:13:44,757 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:13:44,786 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:13:44,793 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0032
2021-10-10 19:13:44,793 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:13:44,816 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0032
2021-10-10 19:13:44,821 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0032/
2021-10-10 19:13:44,822 INFO mapreduce.Job: Running job: job_1633917566916_0032
2021-10-10 19:13:57,993 INFO mapreduce.Job: Job job_1633917566916_0032 running in uber mode : false
2021-10-10 19:13:58,004 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:14:05,086 INFO mapreduce.Job: Task Id : attempt_1633917566916_0032_m_000000_0, Status : FAILED
[2021-10-10 19:14:03.113]Container [pid=6610,containerID=container_1633917566916_0032_01_000002] is running 316271104B beyond the 'VIRTUAL' memory limit. Current usage: 102.7 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0032_01_000002 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 6610 6608 6610 6610 (bash) 0 0 10162176 689 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0032/container_1633917566916_0032_01_000002/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0032/container_1633917566916_0032_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.10.102 34465 attempt_1633917566916_0032_m_000000_0 2 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0032/container_1633917566916_0032_01_000002/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0032/container_1633917566916_0032_01_000002/stderr  
	|- 6621 6610 6610 6610 (java) 141 162 2560966656 25608 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0032/container_1633917566916_0032_01_000002/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0032/container_1633917566916_0032_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.10.102 34465 attempt_1633917566916_0032_m_000000_0 2 

[2021-10-10 19:14:03.161]Container killed on request. Exit code is 143
[2021-10-10 19:14:03.168]Container exited with a non-zero exit code 143. 

2021-10-10 19:14:11,155 INFO mapreduce.Job: Task Id : attempt_1633917566916_0032_m_000000_1, Status : FAILED
[2021-10-10 19:14:09.224]Container [pid=6668,containerID=container_1633917566916_0032_01_000003] is running 322570752B beyond the 'VIRTUAL' memory limit. Current usage: 203.3 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0032_01_000003 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 6668 6666 6668 6668 (bash) 0 0 10162176 698 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0032/container_1633917566916_0032_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0032/container_1633917566916_0032_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.10.102 34465 attempt_1633917566916_0032_m_000000_1 3 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0032/container_1633917566916_0032_01_000003/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0032/container_1633917566916_0032_01_000003/stderr  
	|- 6679 6668 6668 6668 (java) 254 37 2567266304 51349 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0032/container_1633917566916_0032_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0032/container_1633917566916_0032_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.10.102 34465 attempt_1633917566916_0032_m_000000_1 3 

[2021-10-10 19:14:09.270]Container killed on request. Exit code is 143
[2021-10-10 19:14:09.280]Container exited with a non-zero exit code 143. 

2021-10-10 19:14:17,215 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:14:23,267 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:14:23,297 INFO mapreduce.Job: Job job_1633917566916_0032 completed successfully
2021-10-10 19:14:23,351 INFO mapreduce.Job: Counters: 55
	File System Counters
		FILE: Number of bytes read=3198
		FILE: Number of bytes written=443291
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed map tasks=2
		Launched map tasks=3
		Launched reduce tasks=1
		Other local map tasks=2
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=12884
		Total time spent by all reduces in occupied slots (ms)=3205
		Total time spent by all map tasks (ms)=12884
		Total time spent by all reduce tasks (ms)=3205
		Total vcore-milliseconds taken by all map tasks=12884
		Total vcore-milliseconds taken by all reduce tasks=3205
		Total megabyte-milliseconds taken by all map tasks=13193216
		Total megabyte-milliseconds taken by all reduce tasks=3281920
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=3144
		Map output materialized bytes=3198
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=3198
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=136
		CPU time spent (ms)=1000
		Physical memory (bytes) snapshot=329568256
		Virtual memory (bytes) snapshot=5163704320
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215879680
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=113688576
		Peak Reduce Virtual memory (bytes)=2586275840
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:14:23,364 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:14:23,373 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:14:23,387 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:14:23,395 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:14:23,412 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:14:23,435 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:14:23,448 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:14:23,457 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0033
2021-10-10 19:14:23,471 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:14:23,503 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:14:23,510 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:14:23,516 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:14:23,533 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:14:23,544 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:14:23,559 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:14:23,572 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:14:23,612 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:14:23,617 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0033
2021-10-10 19:14:23,617 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:14:23,849 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0033
2021-10-10 19:14:23,859 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0033/
2021-10-10 19:14:23,860 INFO mapreduce.Job: Running job: job_1633917566916_0033
2021-10-10 19:14:36,019 INFO mapreduce.Job: Job job_1633917566916_0033 running in uber mode : false
2021-10-10 19:14:36,019 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:14:41,091 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:14:48,183 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:14:48,214 INFO mapreduce.Job: Job job_1633917566916_0033 completed successfully
2021-10-10 19:14:48,280 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=3198
		FILE: Number of bytes written=443291
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3023
		Total time spent by all reduces in occupied slots (ms)=3911
		Total time spent by all map tasks (ms)=3023
		Total time spent by all reduce tasks (ms)=3911
		Total vcore-milliseconds taken by all map tasks=3023
		Total vcore-milliseconds taken by all reduce tasks=3911
		Total megabyte-milliseconds taken by all map tasks=3095552
		Total megabyte-milliseconds taken by all reduce tasks=4004864
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=3144
		Map output materialized bytes=3198
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=3198
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=164
		CPU time spent (ms)=1140
		Physical memory (bytes) snapshot=331571200
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216059904
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115511296
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:14:48,293 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:14:48,303 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:14:48,330 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:14:48,368 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:14:48,379 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:14:48,383 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0034
2021-10-10 19:14:48,391 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:14:48,408 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:14:48,420 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:14:48,439 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:14:48,473 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:14:48,493 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:14:48,513 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:14:48,556 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0034
2021-10-10 19:14:48,557 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:14:48,577 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0034
2021-10-10 19:14:48,581 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0034/
2021-10-10 19:14:48,583 INFO mapreduce.Job: Running job: job_1633917566916_0034
2021-10-10 19:15:00,733 INFO mapreduce.Job: Job job_1633917566916_0034 running in uber mode : false
2021-10-10 19:15:00,733 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:15:05,794 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:15:11,857 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:15:11,872 INFO mapreduce.Job: Job job_1633917566916_0034 completed successfully
2021-10-10 19:15:11,906 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=3198
		FILE: Number of bytes written=443291
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3113
		Total time spent by all reduces in occupied slots (ms)=3068
		Total time spent by all map tasks (ms)=3113
		Total time spent by all reduce tasks (ms)=3068
		Total vcore-milliseconds taken by all map tasks=3113
		Total vcore-milliseconds taken by all reduce tasks=3068
		Total megabyte-milliseconds taken by all map tasks=3187712
		Total megabyte-milliseconds taken by all reduce tasks=3141632
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=3144
		Map output materialized bytes=3198
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=3198
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=137
		CPU time spent (ms)=1090
		Physical memory (bytes) snapshot=328351744
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=213307392
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115044352
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:15:11,936 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:15:11,949 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:15:11,962 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:15:11,974 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:15:11,991 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:15:12,018 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:15:12,035 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:15:12,039 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0035
2021-10-10 19:15:12,050 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:15:12,064 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:15:12,077 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:15:12,091 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:15:12,107 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:15:12,123 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:15:12,155 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:15:12,172 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:15:12,204 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0035
2021-10-10 19:15:12,204 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:15:12,224 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0035
2021-10-10 19:15:12,230 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0035/
2021-10-10 19:15:12,231 INFO mapreduce.Job: Running job: job_1633917566916_0035
2021-10-10 19:15:26,360 INFO mapreduce.Job: Job job_1633917566916_0035 running in uber mode : false
2021-10-10 19:15:26,363 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:15:33,446 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:15:38,485 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:15:38,515 INFO mapreduce.Job: Job job_1633917566916_0035 completed successfully
2021-10-10 19:15:38,565 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=3198
		FILE: Number of bytes written=443291
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=4637
		Total time spent by all reduces in occupied slots (ms)=3089
		Total time spent by all map tasks (ms)=4637
		Total time spent by all reduce tasks (ms)=3089
		Total vcore-milliseconds taken by all map tasks=4637
		Total vcore-milliseconds taken by all reduce tasks=3089
		Total megabyte-milliseconds taken by all map tasks=4748288
		Total megabyte-milliseconds taken by all reduce tasks=3163136
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=3144
		Map output materialized bytes=3198
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=3198
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=129
		CPU time spent (ms)=1630
		Physical memory (bytes) snapshot=332365824
		Virtual memory (bytes) snapshot=5163986944
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216371200
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115994624
		Peak Reduce Virtual memory (bytes)=2586558464
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:15:38,574 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:15:38,582 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:15:38,601 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:15:38,628 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:15:38,644 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:15:38,651 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:15:38,659 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:15:38,677 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:15:38,688 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:15:38,709 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:15:38,735 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:15:38,748 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:15:38,751 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0036
2021-10-10 19:15:38,765 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:15:38,812 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:15:38,824 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:15:38,850 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:15:38,863 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:15:38,893 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:15:38,904 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:15:38,931 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0036
2021-10-10 19:15:38,932 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:15:38,960 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0036
2021-10-10 19:15:38,966 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0036/
2021-10-10 19:15:38,968 INFO mapreduce.Job: Running job: job_1633917566916_0036
2021-10-10 19:15:51,183 INFO mapreduce.Job: Job job_1633917566916_0036 running in uber mode : false
2021-10-10 19:15:51,186 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:15:57,361 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:16:04,399 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:16:04,426 INFO mapreduce.Job: Job job_1633917566916_0036 completed successfully
2021-10-10 19:16:04,465 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=3510
		FILE: Number of bytes written=443915
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=263
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2994
		Total time spent by all reduces in occupied slots (ms)=4170
		Total time spent by all map tasks (ms)=2994
		Total time spent by all reduce tasks (ms)=4170
		Total vcore-milliseconds taken by all map tasks=2994
		Total vcore-milliseconds taken by all reduce tasks=4170
		Total megabyte-milliseconds taken by all map tasks=3065856
		Total megabyte-milliseconds taken by all reduce tasks=4270080
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=3432
		Map output materialized bytes=3510
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=3510
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=263
		CPU time spent (ms)=1410
		Physical memory (bytes) snapshot=333684736
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215695360
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117989376
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=263
2021-10-10 19:16:04,478 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:16:04,501 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:16:04,529 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:16:04,581 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:16:04,594 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:16:04,598 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0037
2021-10-10 19:16:04,609 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:16:04,626 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:16:04,639 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:16:04,659 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:16:04,680 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:16:04,696 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:16:04,717 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:16:04,749 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0037
2021-10-10 19:16:04,749 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:16:04,772 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0037
2021-10-10 19:16:04,776 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0037/
2021-10-10 19:16:04,776 INFO mapreduce.Job: Running job: job_1633917566916_0037
2021-10-10 19:16:17,911 INFO mapreduce.Job: Job job_1633917566916_0037 running in uber mode : false
2021-10-10 19:16:17,914 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:16:23,994 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:16:30,039 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:16:30,072 INFO mapreduce.Job: Job job_1633917566916_0037 completed successfully
2021-10-10 19:16:30,109 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=3510
		FILE: Number of bytes written=443915
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3243
		Total time spent by all reduces in occupied slots (ms)=3376
		Total time spent by all map tasks (ms)=3243
		Total time spent by all reduce tasks (ms)=3376
		Total vcore-milliseconds taken by all map tasks=3243
		Total vcore-milliseconds taken by all reduce tasks=3376
		Total megabyte-milliseconds taken by all map tasks=3320832
		Total megabyte-milliseconds taken by all reduce tasks=3457024
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=3432
		Map output materialized bytes=3510
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=3510
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=146
		CPU time spent (ms)=1280
		Physical memory (bytes) snapshot=332423168
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216465408
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115957760
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:16:30,116 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:16:30,125 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:16:30,140 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:16:30,148 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:16:30,194 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:16:30,204 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:16:30,208 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0038
2021-10-10 19:16:30,216 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:16:30,233 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:16:30,244 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:16:30,259 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:16:30,275 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:16:30,288 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:16:30,312 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:16:30,331 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0038
2021-10-10 19:16:30,332 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:16:30,350 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0038
2021-10-10 19:16:30,356 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0038/
2021-10-10 19:16:30,358 INFO mapreduce.Job: Running job: job_1633917566916_0038
2021-10-10 19:16:42,534 INFO mapreduce.Job: Job job_1633917566916_0038 running in uber mode : false
2021-10-10 19:16:42,534 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:16:47,600 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:16:53,647 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:16:54,686 INFO mapreduce.Job: Job job_1633917566916_0038 completed successfully
2021-10-10 19:16:54,757 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=3510
		FILE: Number of bytes written=443915
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2859
		Total time spent by all reduces in occupied slots (ms)=3198
		Total time spent by all map tasks (ms)=2859
		Total time spent by all reduce tasks (ms)=3198
		Total vcore-milliseconds taken by all map tasks=2859
		Total vcore-milliseconds taken by all reduce tasks=3198
		Total megabyte-milliseconds taken by all map tasks=2927616
		Total megabyte-milliseconds taken by all reduce tasks=3274752
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=3432
		Map output materialized bytes=3510
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=3510
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=136
		CPU time spent (ms)=1040
		Physical memory (bytes) snapshot=331059200
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=213295104
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117764096
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:16:54,768 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:16:54,786 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:16:54,803 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:16:54,818 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:16:54,851 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:16:54,862 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:16:54,867 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0039
2021-10-10 19:16:54,882 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:16:54,900 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:16:54,913 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:16:54,928 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:16:54,944 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:16:54,957 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:16:54,970 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:16:54,974 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:16:54,989 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:16:55,011 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0039
2021-10-10 19:16:55,012 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:16:55,034 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0039
2021-10-10 19:16:55,039 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0039/
2021-10-10 19:16:55,040 INFO mapreduce.Job: Running job: job_1633917566916_0039
2021-10-10 19:17:07,176 INFO mapreduce.Job: Job job_1633917566916_0039 running in uber mode : false
2021-10-10 19:17:07,176 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:17:13,283 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:17:19,347 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:17:19,359 INFO mapreduce.Job: Job job_1633917566916_0039 completed successfully
2021-10-10 19:17:19,406 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=3510
		FILE: Number of bytes written=443915
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3058
		Total time spent by all reduces in occupied slots (ms)=3512
		Total time spent by all map tasks (ms)=3058
		Total time spent by all reduce tasks (ms)=3512
		Total vcore-milliseconds taken by all map tasks=3058
		Total vcore-milliseconds taken by all reduce tasks=3512
		Total megabyte-milliseconds taken by all map tasks=3131392
		Total megabyte-milliseconds taken by all reduce tasks=3596288
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=3432
		Map output materialized bytes=3510
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=3510
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=134
		CPU time spent (ms)=1070
		Physical memory (bytes) snapshot=329584640
		Virtual memory (bytes) snapshot=5164003328
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215785472
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=113799168
		Peak Reduce Virtual memory (bytes)=2586574848
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:17:19,415 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:17:19,423 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:17:19,440 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:17:19,449 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:17:19,465 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:17:19,488 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:17:19,499 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:17:19,503 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0040
2021-10-10 19:17:19,510 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:17:19,529 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:17:19,545 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:17:19,560 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:17:19,592 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:17:19,606 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:17:19,611 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:17:19,632 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:17:19,660 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0040
2021-10-10 19:17:19,662 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:17:19,680 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0040
2021-10-10 19:17:19,686 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0040/
2021-10-10 19:17:19,688 INFO mapreduce.Job: Running job: job_1633917566916_0040
2021-10-10 19:17:31,839 INFO mapreduce.Job: Job job_1633917566916_0040 running in uber mode : false
2021-10-10 19:17:31,839 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:17:36,938 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:17:44,028 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:17:44,050 INFO mapreduce.Job: Job job_1633917566916_0040 completed successfully
2021-10-10 19:17:44,101 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=3510
		FILE: Number of bytes written=443915
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3021
		Total time spent by all reduces in occupied slots (ms)=3240
		Total time spent by all map tasks (ms)=3021
		Total time spent by all reduce tasks (ms)=3240
		Total vcore-milliseconds taken by all map tasks=3021
		Total vcore-milliseconds taken by all reduce tasks=3240
		Total megabyte-milliseconds taken by all map tasks=3093504
		Total megabyte-milliseconds taken by all reduce tasks=3317760
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=3432
		Map output materialized bytes=3510
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=3510
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=139
		CPU time spent (ms)=1110
		Physical memory (bytes) snapshot=330575872
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215719936
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=114855936
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:17:44,117 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:17:44,133 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:17:44,154 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:17:44,189 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:17:44,202 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:17:44,208 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:17:44,223 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:17:44,247 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:17:44,297 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:17:44,313 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:17:44,317 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0041
2021-10-10 19:17:44,323 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:17:44,337 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:17:44,348 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:17:44,357 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:17:44,370 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:17:44,379 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:17:44,395 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.closeInternal(DataStreamer.java:847)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:843)
2021-10-10 19:17:44,398 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:17:44,416 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:17:44,434 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:17:44,439 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0041
2021-10-10 19:17:44,440 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:17:44,659 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0041
2021-10-10 19:17:44,669 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0041/
2021-10-10 19:17:44,672 INFO mapreduce.Job: Running job: job_1633917566916_0041
2021-10-10 19:17:56,813 INFO mapreduce.Job: Job job_1633917566916_0041 running in uber mode : false
2021-10-10 19:17:56,813 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:18:03,935 INFO mapreduce.Job: Task Id : attempt_1633917566916_0041_m_000000_0, Status : FAILED
[2021-10-10 19:18:02.386]Container [pid=8904,containerID=container_1633917566916_0041_01_000002] is running 319420928B beyond the 'VIRTUAL' memory limit. Current usage: 169.9 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0041_01_000002 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 8904 8902 8904 8904 (bash) 0 0 10162176 691 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0041/container_1633917566916_0041_01_000002/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0041/container_1633917566916_0041_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.10.100 38087 attempt_1633917566916_0041_m_000000_0 2 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0041/container_1633917566916_0041_01_000002/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0041/container_1633917566916_0041_01_000002/stderr  
	|- 8915 8904 8904 8904 (java) 168 279 2564116480 42809 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0041/container_1633917566916_0041_01_000002/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0041/container_1633917566916_0041_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.10.100 38087 attempt_1633917566916_0041_m_000000_0 2 

[2021-10-10 19:18:02.463]Container killed on request. Exit code is 143
[2021-10-10 19:18:02.481]Container exited with a non-zero exit code 143. 

2021-10-10 19:18:11,022 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:18:17,061 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:18:18,106 INFO mapreduce.Job: Job job_1633917566916_0041 completed successfully
2021-10-10 19:18:18,148 INFO mapreduce.Job: Counters: 55
	File System Counters
		FILE: Number of bytes read=3798
		FILE: Number of bytes written=444491
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed map tasks=1
		Launched map tasks=2
		Launched reduce tasks=1
		Other local map tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=9844
		Total time spent by all reduces in occupied slots (ms)=3502
		Total time spent by all map tasks (ms)=9844
		Total time spent by all reduce tasks (ms)=3502
		Total vcore-milliseconds taken by all map tasks=9844
		Total vcore-milliseconds taken by all reduce tasks=3502
		Total megabyte-milliseconds taken by all map tasks=10080256
		Total megabyte-milliseconds taken by all reduce tasks=3586048
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=3720
		Map output materialized bytes=3798
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=3798
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=144
		CPU time spent (ms)=1390
		Physical memory (bytes) snapshot=332472320
		Virtual memory (bytes) snapshot=5163851776
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216154112
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=116318208
		Peak Reduce Virtual memory (bytes)=2586423296
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:18:18,161 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:18:18,174 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:18:18,188 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:18:18,197 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:18:18,236 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:18:18,250 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:18:18,254 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0042
2021-10-10 19:18:18,263 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:18:18,285 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:18:18,296 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:18:18,322 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:18:18,335 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:18:18,353 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:18:18,369 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:18:18,373 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0042
2021-10-10 19:18:18,373 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:18:18,394 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0042
2021-10-10 19:18:18,399 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0042/
2021-10-10 19:18:18,401 INFO mapreduce.Job: Running job: job_1633917566916_0042
2021-10-10 19:18:30,530 INFO mapreduce.Job: Job job_1633917566916_0042 running in uber mode : false
2021-10-10 19:18:30,532 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:18:36,587 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:18:42,625 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:18:43,637 INFO mapreduce.Job: Job job_1633917566916_0042 completed successfully
2021-10-10 19:18:43,681 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=3798
		FILE: Number of bytes written=444491
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3912
		Total time spent by all reduces in occupied slots (ms)=3568
		Total time spent by all map tasks (ms)=3912
		Total time spent by all reduce tasks (ms)=3568
		Total vcore-milliseconds taken by all map tasks=3912
		Total vcore-milliseconds taken by all reduce tasks=3568
		Total megabyte-milliseconds taken by all map tasks=4005888
		Total megabyte-milliseconds taken by all reduce tasks=3653632
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=3720
		Map output materialized bytes=3798
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=3798
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=179
		CPU time spent (ms)=1490
		Physical memory (bytes) snapshot=332083200
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216719360
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115363840
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:18:43,697 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:18:43,705 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:18:43,719 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:18:43,724 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:18:43,737 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:18:43,762 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:18:43,773 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:18:43,776 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0043
2021-10-10 19:18:43,788 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:18:43,801 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:18:43,815 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:18:43,829 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:18:43,856 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:18:43,877 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:18:43,896 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:18:43,922 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0043
2021-10-10 19:18:43,923 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:18:43,948 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0043
2021-10-10 19:18:43,953 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0043/
2021-10-10 19:18:43,954 INFO mapreduce.Job: Running job: job_1633917566916_0043
2021-10-10 19:18:56,098 INFO mapreduce.Job: Job job_1633917566916_0043 running in uber mode : false
2021-10-10 19:18:56,098 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:19:02,177 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:19:07,227 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:19:08,271 INFO mapreduce.Job: Job job_1633917566916_0043 completed successfully
2021-10-10 19:19:08,343 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=3798
		FILE: Number of bytes written=444491
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3569
		Total time spent by all reduces in occupied slots (ms)=3262
		Total time spent by all map tasks (ms)=3569
		Total time spent by all reduce tasks (ms)=3262
		Total vcore-milliseconds taken by all map tasks=3569
		Total vcore-milliseconds taken by all reduce tasks=3262
		Total megabyte-milliseconds taken by all map tasks=3654656
		Total megabyte-milliseconds taken by all reduce tasks=3340288
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=3720
		Map output materialized bytes=3798
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=3798
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=145
		CPU time spent (ms)=1070
		Physical memory (bytes) snapshot=320462848
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=204222464
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=116240384
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:19:08,363 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:19:08,369 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:19:08,393 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:19:08,433 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:19:08,444 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:19:08,449 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0044
2021-10-10 19:19:08,457 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:19:08,472 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:19:08,483 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:19:08,491 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:19:08,518 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:19:08,549 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:19:08,582 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:19:08,611 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:19:08,615 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0044
2021-10-10 19:19:08,615 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:19:08,835 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0044
2021-10-10 19:19:08,840 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0044/
2021-10-10 19:19:08,840 INFO mapreduce.Job: Running job: job_1633917566916_0044
2021-10-10 19:19:23,024 INFO mapreduce.Job: Job job_1633917566916_0044 running in uber mode : false
2021-10-10 19:19:23,024 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:19:28,081 INFO mapreduce.Job: Task Id : attempt_1633917566916_0044_m_000000_0, Status : FAILED
[2021-10-10 19:19:27.690]Container [pid=16591,containerID=container_1633917566916_0044_01_000002] is running 307866112B beyond the 'VIRTUAL' memory limit. Current usage: 88.6 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0044_01_000002 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 16591 16589 16591 16591 (bash) 0 0 10162176 683 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0044/container_1633917566916_0044_01_000002/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0044/container_1633917566916_0044_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.10.101 43741 attempt_1633917566916_0044_m_000000_0 2 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0044/container_1633917566916_0044_01_000002/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0044/container_1633917566916_0044_01_000002/stderr  
	|- 16602 16591 16591 16591 (java) 132 156 2552561664 21994 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0044/container_1633917566916_0044_01_000002/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0044/container_1633917566916_0044_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.10.101 43741 attempt_1633917566916_0044_m_000000_0 2 

[2021-10-10 19:19:27.712]Container killed on request. Exit code is 143
[2021-10-10 19:19:27.729]Container exited with a non-zero exit code 143. 

2021-10-10 19:19:36,155 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:19:42,198 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:19:42,233 INFO mapreduce.Job: Job job_1633917566916_0044 completed successfully
2021-10-10 19:19:42,276 INFO mapreduce.Job: Counters: 55
	File System Counters
		FILE: Number of bytes read=3798
		FILE: Number of bytes written=444491
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed map tasks=1
		Launched map tasks=2
		Launched reduce tasks=1
		Other local map tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=8012
		Total time spent by all reduces in occupied slots (ms)=3199
		Total time spent by all map tasks (ms)=8012
		Total time spent by all reduce tasks (ms)=3199
		Total vcore-milliseconds taken by all map tasks=8012
		Total vcore-milliseconds taken by all reduce tasks=3199
		Total megabyte-milliseconds taken by all map tasks=8204288
		Total megabyte-milliseconds taken by all reduce tasks=3275776
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=3720
		Map output materialized bytes=3798
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=3798
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=136
		CPU time spent (ms)=1620
		Physical memory (bytes) snapshot=330321920
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216420352
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=113901568
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:19:42,285 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:19:42,295 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:19:42,331 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:19:42,355 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:19:42,378 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:19:42,401 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:19:42,404 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0045
2021-10-10 19:19:42,417 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:19:42,437 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:19:42,448 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:19:42,463 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:19:42,471 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:19:42,488 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:19:42,494 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:19:42,508 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:19:42,531 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:19:42,536 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0045
2021-10-10 19:19:42,536 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:19:42,554 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0045
2021-10-10 19:19:42,560 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0045/
2021-10-10 19:19:42,561 INFO mapreduce.Job: Running job: job_1633917566916_0045
2021-10-10 19:19:54,680 INFO mapreduce.Job: Job job_1633917566916_0045 running in uber mode : false
2021-10-10 19:19:54,681 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:19:59,725 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:20:06,787 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:20:06,812 INFO mapreduce.Job: Job job_1633917566916_0045 completed successfully
2021-10-10 19:20:06,881 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=3798
		FILE: Number of bytes written=444491
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2930
		Total time spent by all reduces in occupied slots (ms)=3393
		Total time spent by all map tasks (ms)=2930
		Total time spent by all reduce tasks (ms)=3393
		Total vcore-milliseconds taken by all map tasks=2930
		Total vcore-milliseconds taken by all reduce tasks=3393
		Total megabyte-milliseconds taken by all map tasks=3000320
		Total megabyte-milliseconds taken by all reduce tasks=3474432
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=3720
		Map output materialized bytes=3798
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=3798
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=134
		CPU time spent (ms)=1090
		Physical memory (bytes) snapshot=331321344
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216383488
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=114937856
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:20:06,894 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:06,904 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:06,946 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:06,966 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:20:06,973 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:06,985 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:07,005 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:20:07,013 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:07,029 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.closeInternal(DataStreamer.java:847)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:843)
2021-10-10 19:20:07,067 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:20:07,089 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:20:07,095 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0046
2021-10-10 19:20:07,107 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:07,128 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:20:07,149 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:20:07,161 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:07,184 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:20:07,199 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:07,213 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:20:07,218 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:20:07,233 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:07,256 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0046
2021-10-10 19:20:07,257 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:20:07,482 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0046
2021-10-10 19:20:07,487 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0046/
2021-10-10 19:20:07,489 INFO mapreduce.Job: Running job: job_1633917566916_0046
2021-10-10 19:20:19,675 INFO mapreduce.Job: Job job_1633917566916_0046 running in uber mode : false
2021-10-10 19:20:19,677 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:20:24,743 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:20:30,808 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:20:30,819 INFO mapreduce.Job: Job job_1633917566916_0046 completed successfully
2021-10-10 19:20:30,874 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=4086
		FILE: Number of bytes written=445067
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2895
		Total time spent by all reduces in occupied slots (ms)=3483
		Total time spent by all map tasks (ms)=2895
		Total time spent by all reduce tasks (ms)=3483
		Total vcore-milliseconds taken by all map tasks=2895
		Total vcore-milliseconds taken by all reduce tasks=3483
		Total megabyte-milliseconds taken by all map tasks=2964480
		Total megabyte-milliseconds taken by all reduce tasks=3566592
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=4008
		Map output materialized bytes=4086
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=4086
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=166
		CPU time spent (ms)=1210
		Physical memory (bytes) snapshot=331837440
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216526848
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115310592
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:20:30,890 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:30,897 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:30,918 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:30,954 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:20:30,964 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:20:30,967 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0047
2021-10-10 19:20:30,973 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:30,992 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:20:31,000 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:31,015 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:20:31,024 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:31,039 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:20:31,044 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:20:31,055 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:31,110 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0047
2021-10-10 19:20:31,111 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:20:31,332 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0047
2021-10-10 19:20:31,344 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0047/
2021-10-10 19:20:31,344 INFO mapreduce.Job: Running job: job_1633917566916_0047
2021-10-10 19:20:43,525 INFO mapreduce.Job: Job job_1633917566916_0047 running in uber mode : false
2021-10-10 19:20:43,527 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:20:48,686 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:20:55,758 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:20:55,786 INFO mapreduce.Job: Job job_1633917566916_0047 completed successfully
2021-10-10 19:20:55,856 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=4086
		FILE: Number of bytes written=445067
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2889
		Total time spent by all reduces in occupied slots (ms)=3386
		Total time spent by all map tasks (ms)=2889
		Total time spent by all reduce tasks (ms)=3386
		Total vcore-milliseconds taken by all map tasks=2889
		Total vcore-milliseconds taken by all reduce tasks=3386
		Total megabyte-milliseconds taken by all map tasks=2958336
		Total megabyte-milliseconds taken by all reduce tasks=3467264
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=4008
		Map output materialized bytes=4086
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=4086
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=176
		CPU time spent (ms)=1190
		Physical memory (bytes) snapshot=333041664
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216002560
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117039104
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:20:55,865 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:55,875 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:55,892 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:55,922 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:20:55,933 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:20:55,938 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0048
2021-10-10 19:20:55,944 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:55,965 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:20:55,974 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:55,998 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:56,018 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:20:56,040 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:20:56,056 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0048
2021-10-10 19:20:56,058 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:20:56,073 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0048
2021-10-10 19:20:56,077 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0048/
2021-10-10 19:20:56,080 INFO mapreduce.Job: Running job: job_1633917566916_0048
2021-10-10 19:21:09,318 INFO mapreduce.Job: Job job_1633917566916_0048 running in uber mode : false
2021-10-10 19:21:09,320 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:21:14,389 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:21:20,420 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:21:21,443 INFO mapreduce.Job: Job job_1633917566916_0048 completed successfully
2021-10-10 19:21:21,498 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=4086
		FILE: Number of bytes written=445067
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3141
		Total time spent by all reduces in occupied slots (ms)=3314
		Total time spent by all map tasks (ms)=3141
		Total time spent by all reduce tasks (ms)=3314
		Total vcore-milliseconds taken by all map tasks=3141
		Total vcore-milliseconds taken by all reduce tasks=3314
		Total megabyte-milliseconds taken by all map tasks=3216384
		Total megabyte-milliseconds taken by all reduce tasks=3393536
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=4008
		Map output materialized bytes=4086
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=4086
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=129
		CPU time spent (ms)=1200
		Physical memory (bytes) snapshot=329502720
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216174592
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=113328128
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:21:21,509 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:21:21,515 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:21:21,531 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:21:21,538 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:21:21,583 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:21:21,595 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:21:21,599 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0049
2021-10-10 19:21:21,608 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:21:21,634 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:21:21,644 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:21:21,657 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:21:21,667 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:21:21,680 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:21:21,697 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:21:21,719 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0049
2021-10-10 19:21:21,721 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:21:21,740 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0049
2021-10-10 19:21:21,744 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0049/
2021-10-10 19:21:21,746 INFO mapreduce.Job: Running job: job_1633917566916_0049
2021-10-10 19:21:35,903 INFO mapreduce.Job: Job job_1633917566916_0049 running in uber mode : false
2021-10-10 19:21:35,903 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:21:41,967 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:21:48,059 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:21:48,074 INFO mapreduce.Job: Job job_1633917566916_0049 completed successfully
2021-10-10 19:21:48,109 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=4086
		FILE: Number of bytes written=445067
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3849
		Total time spent by all reduces in occupied slots (ms)=3247
		Total time spent by all map tasks (ms)=3849
		Total time spent by all reduce tasks (ms)=3247
		Total vcore-milliseconds taken by all map tasks=3849
		Total vcore-milliseconds taken by all reduce tasks=3247
		Total megabyte-milliseconds taken by all map tasks=3941376
		Total megabyte-milliseconds taken by all reduce tasks=3324928
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=4008
		Map output materialized bytes=4086
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=4086
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=136
		CPU time spent (ms)=1410
		Physical memory (bytes) snapshot=331599872
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=214183936
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117415936
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:21:48,118 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:21:48,128 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:21:48,141 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:21:48,151 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:21:48,203 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:21:48,216 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:21:48,223 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0050
2021-10-10 19:21:48,234 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:21:48,253 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:21:48,268 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:21:48,276 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:21:48,290 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:21:48,303 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:21:48,320 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:21:48,347 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0050
2021-10-10 19:21:48,348 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:21:48,363 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0050
2021-10-10 19:21:48,367 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0050/
2021-10-10 19:21:48,369 INFO mapreduce.Job: Running job: job_1633917566916_0050
2021-10-10 19:22:01,534 INFO mapreduce.Job: Job job_1633917566916_0050 running in uber mode : false
2021-10-10 19:22:01,536 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:22:06,588 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:22:12,647 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:22:12,663 INFO mapreduce.Job: Job job_1633917566916_0050 completed successfully
2021-10-10 19:22:12,726 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=4086
		FILE: Number of bytes written=445067
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2976
		Total time spent by all reduces in occupied slots (ms)=3346
		Total time spent by all map tasks (ms)=2976
		Total time spent by all reduce tasks (ms)=3346
		Total vcore-milliseconds taken by all map tasks=2976
		Total vcore-milliseconds taken by all reduce tasks=3346
		Total megabyte-milliseconds taken by all map tasks=3047424
		Total megabyte-milliseconds taken by all reduce tasks=3426304
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=4008
		Map output materialized bytes=4086
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=4086
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=146
		CPU time spent (ms)=1060
		Physical memory (bytes) snapshot=329588736
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=213954560
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115634176
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:22:12,735 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:22:12,742 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:22:12,761 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:22:12,788 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:22:12,801 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:22:12,808 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:22:12,822 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:22:12,837 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:22:12,849 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:22:12,870 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:22:12,901 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:22:12,914 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:22:12,917 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0051
2021-10-10 19:22:12,926 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:22:12,944 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:22:12,951 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:22:12,967 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:22:12,983 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:22:12,999 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:22:13,016 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:22:13,021 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0051
2021-10-10 19:22:13,021 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:22:13,035 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0051
2021-10-10 19:22:13,040 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0051/
2021-10-10 19:22:13,043 INFO mapreduce.Job: Running job: job_1633917566916_0051
2021-10-10 19:22:26,184 INFO mapreduce.Job: Job job_1633917566916_0051 running in uber mode : false
2021-10-10 19:22:26,184 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:22:31,243 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:22:37,306 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:22:37,335 INFO mapreduce.Job: Job job_1633917566916_0051 completed successfully
2021-10-10 19:22:37,416 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=4374
		FILE: Number of bytes written=445643
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3052
		Total time spent by all reduces in occupied slots (ms)=3269
		Total time spent by all map tasks (ms)=3052
		Total time spent by all reduce tasks (ms)=3269
		Total vcore-milliseconds taken by all map tasks=3052
		Total vcore-milliseconds taken by all reduce tasks=3269
		Total megabyte-milliseconds taken by all map tasks=3125248
		Total megabyte-milliseconds taken by all reduce tasks=3347456
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=4296
		Map output materialized bytes=4374
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=4374
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=137
		CPU time spent (ms)=1030
		Physical memory (bytes) snapshot=330641408
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215355392
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115286016
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:22:37,434 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:22:37,445 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:22:37,461 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:22:37,512 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:22:37,525 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:22:37,530 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0052
2021-10-10 19:22:37,538 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:22:37,551 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:22:37,562 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:22:37,572 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:22:37,583 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:22:37,593 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:22:37,614 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:22:37,619 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:22:37,635 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:22:37,659 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0052
2021-10-10 19:22:37,660 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:22:37,673 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0052
2021-10-10 19:22:37,678 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0052/
2021-10-10 19:22:37,680 INFO mapreduce.Job: Running job: job_1633917566916_0052
2021-10-10 19:22:49,881 INFO mapreduce.Job: Job job_1633917566916_0052 running in uber mode : false
2021-10-10 19:22:49,884 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:22:54,964 INFO mapreduce.Job: Task Id : attempt_1633917566916_0052_m_000000_0, Status : FAILED
[2021-10-10 19:22:54.545]Container [pid=10665,containerID=container_1633917566916_0052_01_000002] is running 322570752B beyond the 'VIRTUAL' memory limit. Current usage: 205.1 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0052_01_000002 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 10665 10663 10665 10665 (bash) 0 0 10162176 703 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0052/container_1633917566916_0052_01_000002/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0052/container_1633917566916_0052_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.10.101 42145 attempt_1633917566916_0052_m_000000_0 2 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0052/container_1633917566916_0052_01_000002/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0052/container_1633917566916_0052_01_000002/stderr  
	|- 10676 10665 10665 10665 (java) 248 79 2567266304 51811 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0052/container_1633917566916_0052_01_000002/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0052/container_1633917566916_0052_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.10.101 42145 attempt_1633917566916_0052_m_000000_0 2 

[2021-10-10 19:22:54.596]Container killed on request. Exit code is 143
[2021-10-10 19:22:54.605]Container exited with a non-zero exit code 143. 

2021-10-10 19:23:02,019 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:23:08,060 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:23:08,091 INFO mapreduce.Job: Job job_1633917566916_0052 completed successfully
2021-10-10 19:23:08,143 INFO mapreduce.Job: Counters: 55
	File System Counters
		FILE: Number of bytes read=4374
		FILE: Number of bytes written=445643
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed map tasks=1
		Launched map tasks=2
		Launched reduce tasks=1
		Other local map tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=6847
		Total time spent by all reduces in occupied slots (ms)=3220
		Total time spent by all map tasks (ms)=6847
		Total time spent by all reduce tasks (ms)=3220
		Total vcore-milliseconds taken by all map tasks=6847
		Total vcore-milliseconds taken by all reduce tasks=3220
		Total megabyte-milliseconds taken by all map tasks=7011328
		Total megabyte-milliseconds taken by all reduce tasks=3297280
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=4296
		Map output materialized bytes=4374
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=4374
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=138
		CPU time spent (ms)=1040
		Physical memory (bytes) snapshot=325836800
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=211046400
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=114790400
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:23:08,152 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:23:08,161 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:23:08,174 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:23:08,180 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:23:08,193 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:23:08,221 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:23:08,232 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:23:08,236 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0053
2021-10-10 19:23:08,244 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:23:08,258 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:23:08,266 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:23:08,277 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:23:08,292 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:23:08,304 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:23:08,317 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:23:08,336 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:23:08,341 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0053
2021-10-10 19:23:08,341 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:23:08,359 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0053
2021-10-10 19:23:08,364 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0053/
2021-10-10 19:23:08,366 INFO mapreduce.Job: Running job: job_1633917566916_0053
2021-10-10 19:23:21,522 INFO mapreduce.Job: Job job_1633917566916_0053 running in uber mode : false
2021-10-10 19:23:21,522 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:23:26,558 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:23:32,581 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:23:32,586 INFO mapreduce.Job: Job job_1633917566916_0053 completed successfully
2021-10-10 19:23:32,637 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=4374
		FILE: Number of bytes written=445643
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2990
		Total time spent by all reduces in occupied slots (ms)=3098
		Total time spent by all map tasks (ms)=2990
		Total time spent by all reduce tasks (ms)=3098
		Total vcore-milliseconds taken by all map tasks=2990
		Total vcore-milliseconds taken by all reduce tasks=3098
		Total megabyte-milliseconds taken by all map tasks=3061760
		Total megabyte-milliseconds taken by all reduce tasks=3172352
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=4296
		Map output materialized bytes=4374
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=4374
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=139
		CPU time spent (ms)=1100
		Physical memory (bytes) snapshot=333418496
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215674880
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117743616
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:23:32,649 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:23:32,666 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:23:32,683 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:23:32,691 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:23:32,705 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:23:32,725 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:23:32,735 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:23:32,740 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0054
2021-10-10 19:23:32,747 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:23:32,762 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:23:32,771 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:23:32,777 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:23:32,796 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:23:32,806 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:23:32,827 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:23:32,841 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:23:32,877 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0054
2021-10-10 19:23:32,878 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:23:32,892 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0054
2021-10-10 19:23:32,897 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0054/
2021-10-10 19:23:32,899 INFO mapreduce.Job: Running job: job_1633917566916_0054
2021-10-10 19:23:45,076 INFO mapreduce.Job: Job job_1633917566916_0054 running in uber mode : false
2021-10-10 19:23:45,077 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:23:51,135 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:23:57,185 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:23:57,211 INFO mapreduce.Job: Job job_1633917566916_0054 completed successfully
2021-10-10 19:23:57,283 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=4374
		FILE: Number of bytes written=445643
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3010
		Total time spent by all reduces in occupied slots (ms)=3170
		Total time spent by all map tasks (ms)=3010
		Total time spent by all reduce tasks (ms)=3170
		Total vcore-milliseconds taken by all map tasks=3010
		Total vcore-milliseconds taken by all reduce tasks=3170
		Total megabyte-milliseconds taken by all map tasks=3082240
		Total megabyte-milliseconds taken by all reduce tasks=3246080
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=4296
		Map output materialized bytes=4374
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=4374
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=141
		CPU time spent (ms)=1120
		Physical memory (bytes) snapshot=330797056
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216223744
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=114573312
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:23:57,292 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:23:57,302 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:23:57,327 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:23:57,344 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:23:57,368 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:23:57,378 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:23:57,381 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0055
2021-10-10 19:23:57,389 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:23:57,409 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:23:57,415 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:23:57,427 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:23:57,436 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:23:57,449 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.closeInternal(DataStreamer.java:847)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:843)
2021-10-10 19:23:57,450 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:23:57,471 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:23:57,487 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0055
2021-10-10 19:23:57,489 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:23:57,507 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0055
2021-10-10 19:23:57,511 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0055/
2021-10-10 19:23:57,513 INFO mapreduce.Job: Running job: job_1633917566916_0055
2021-10-10 19:24:09,646 INFO mapreduce.Job: Job job_1633917566916_0055 running in uber mode : false
2021-10-10 19:24:09,646 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:24:15,723 INFO mapreduce.Job: Task Id : attempt_1633917566916_0055_m_000000_0, Status : FAILED
[2021-10-10 19:24:14.574]Container [pid=9951,containerID=container_1633917566916_0055_01_000002] is running 319420928B beyond the 'VIRTUAL' memory limit. Current usage: 200.7 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0055_01_000002 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 9951 9950 9951 9951 (bash) 0 0 10162176 695 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0055/container_1633917566916_0055_01_000002/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0055/container_1633917566916_0055_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.10.102 40635 attempt_1633917566916_0055_m_000000_0 2 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0055/container_1633917566916_0055_01_000002/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0055/container_1633917566916_0055_01_000002/stderr  
	|- 9963 9951 9951 9951 (java) 181 194 2564116480 50685 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0055/container_1633917566916_0055_01_000002/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0055/container_1633917566916_0055_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.10.102 40635 attempt_1633917566916_0055_m_000000_0 2 

[2021-10-10 19:24:14.661]Container killed on request. Exit code is 143
[2021-10-10 19:24:14.697]Container exited with a non-zero exit code 143. 

2021-10-10 19:24:21,801 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:24:27,846 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:24:27,853 INFO mapreduce.Job: Job job_1633917566916_0055 completed successfully
2021-10-10 19:24:27,903 INFO mapreduce.Job: Counters: 55
	File System Counters
		FILE: Number of bytes read=4374
		FILE: Number of bytes written=445643
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=263
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed map tasks=1
		Launched map tasks=2
		Launched reduce tasks=1
		Other local map tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=7752
		Total time spent by all reduces in occupied slots (ms)=3128
		Total time spent by all map tasks (ms)=7752
		Total time spent by all reduce tasks (ms)=3128
		Total vcore-milliseconds taken by all map tasks=7752
		Total vcore-milliseconds taken by all reduce tasks=3128
		Total megabyte-milliseconds taken by all map tasks=7938048
		Total megabyte-milliseconds taken by all reduce tasks=3203072
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=4296
		Map output materialized bytes=4374
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=4374
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=141
		CPU time spent (ms)=1030
		Physical memory (bytes) snapshot=330145792
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=213266432
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=116879360
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=263
2021-10-10 19:24:27,911 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:24:27,919 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:24:27,937 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:24:27,959 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:24:27,976 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:24:27,990 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:24:28,004 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:24:28,016 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:24:28,050 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:24:28,061 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:24:28,065 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0056
2021-10-10 19:24:28,074 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:24:28,086 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:24:28,094 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:24:28,100 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:24:28,112 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:24:28,116 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:24:28,131 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:24:28,143 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:24:28,161 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:24:28,165 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0056
2021-10-10 19:24:28,165 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:24:28,183 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0056
2021-10-10 19:24:28,189 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0056/
2021-10-10 19:24:28,189 INFO mapreduce.Job: Running job: job_1633917566916_0056
2021-10-10 19:24:41,355 INFO mapreduce.Job: Job job_1633917566916_0056 running in uber mode : false
2021-10-10 19:24:41,356 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:24:46,420 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:24:52,471 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:24:52,484 INFO mapreduce.Job: Job job_1633917566916_0056 completed successfully
2021-10-10 19:24:52,553 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=4662
		FILE: Number of bytes written=446219
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3183
		Total time spent by all reduces in occupied slots (ms)=3272
		Total time spent by all map tasks (ms)=3183
		Total time spent by all reduce tasks (ms)=3272
		Total vcore-milliseconds taken by all map tasks=3183
		Total vcore-milliseconds taken by all reduce tasks=3272
		Total megabyte-milliseconds taken by all map tasks=3259392
		Total megabyte-milliseconds taken by all reduce tasks=3350528
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=4584
		Map output materialized bytes=4662
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=4662
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=166
		CPU time spent (ms)=1050
		Physical memory (bytes) snapshot=329437184
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=213962752
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115474432
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:24:52,564 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:24:52,571 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:24:52,588 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:24:52,617 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:24:52,628 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:24:52,631 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0057
2021-10-10 19:24:52,640 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:24:52,654 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:24:52,665 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:24:52,679 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:24:52,691 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:24:52,700 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:24:52,715 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:24:52,733 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:24:52,758 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0057
2021-10-10 19:24:52,759 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:24:52,991 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0057
2021-10-10 19:24:52,995 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0057/
2021-10-10 19:24:52,995 INFO mapreduce.Job: Running job: job_1633917566916_0057
2021-10-10 19:25:05,149 INFO mapreduce.Job: Job job_1633917566916_0057 running in uber mode : false
2021-10-10 19:25:05,150 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:25:11,249 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:25:18,310 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:25:18,332 INFO mapreduce.Job: Job job_1633917566916_0057 completed successfully
2021-10-10 19:25:18,390 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=4662
		FILE: Number of bytes written=446219
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3743
		Total time spent by all reduces in occupied slots (ms)=3371
		Total time spent by all map tasks (ms)=3743
		Total time spent by all reduce tasks (ms)=3371
		Total vcore-milliseconds taken by all map tasks=3743
		Total vcore-milliseconds taken by all reduce tasks=3371
		Total megabyte-milliseconds taken by all map tasks=3832832
		Total megabyte-milliseconds taken by all reduce tasks=3451904
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=4584
		Map output materialized bytes=4662
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=4662
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=165
		CPU time spent (ms)=1660
		Physical memory (bytes) snapshot=330702848
		Virtual memory (bytes) snapshot=5163855872
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215502848
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115200000
		Peak Reduce Virtual memory (bytes)=2586427392
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:25:18,399 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:25:18,410 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:25:18,422 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:25:18,430 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:25:18,462 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:25:18,473 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:25:18,477 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0058
2021-10-10 19:25:18,483 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:25:18,498 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:25:18,507 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:25:18,533 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:25:18,545 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:25:18,557 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:25:18,573 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:25:18,578 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0058
2021-10-10 19:25:18,578 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:25:18,796 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0058
2021-10-10 19:25:18,807 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0058/
2021-10-10 19:25:18,809 INFO mapreduce.Job: Running job: job_1633917566916_0058
2021-10-10 19:25:30,996 INFO mapreduce.Job: Job job_1633917566916_0058 running in uber mode : false
2021-10-10 19:25:30,996 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:25:36,067 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:25:42,126 INFO mapreduce.Job: Task Id : attempt_1633917566916_0058_r_000000_0, Status : FAILED
[2021-10-10 19:25:40.986]Container [pid=20277,containerID=container_1633917566916_0058_01_000003] is running 331561472B beyond the 'VIRTUAL' memory limit. Current usage: 108.9 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0058_01_000003 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 20277 20275 20277 20277 (bash) 0 0 10162176 711 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0058/container_1633917566916_0058_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0058/container_1633917566916_0058_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.101 39259 attempt_1633917566916_0058_r_000000_0 3 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0058/container_1633917566916_0058_01_000003/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0058/container_1633917566916_0058_01_000003/stderr  
	|- 20288 20277 20277 20277 (java) 281 15 2576257024 27160 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0058/container_1633917566916_0058_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0058/container_1633917566916_0058_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.101 39259 attempt_1633917566916_0058_r_000000_0 3 

[2021-10-10 19:25:41.011]Container killed on request. Exit code is 143
[2021-10-10 19:25:41.018]Container exited with a non-zero exit code 143. 

2021-10-10 19:25:49,220 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:25:49,227 INFO mapreduce.Job: Job job_1633917566916_0058 completed successfully
2021-10-10 19:25:49,268 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=4662
		FILE: Number of bytes written=446219
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed reduce tasks=1
		Launched map tasks=1
		Launched reduce tasks=2
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3067
		Total time spent by all reduces in occupied slots (ms)=7069
		Total time spent by all map tasks (ms)=3067
		Total time spent by all reduce tasks (ms)=7069
		Total vcore-milliseconds taken by all map tasks=3067
		Total vcore-milliseconds taken by all reduce tasks=7069
		Total megabyte-milliseconds taken by all map tasks=3140608
		Total megabyte-milliseconds taken by all reduce tasks=7238656
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=4584
		Map output materialized bytes=4662
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=4662
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=149
		CPU time spent (ms)=1140
		Physical memory (bytes) snapshot=333602816
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216301568
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117301248
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:25:49,281 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:25:49,292 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:25:49,314 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:25:49,347 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:25:49,363 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:25:49,367 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0059
2021-10-10 19:25:49,374 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:25:49,387 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:25:49,396 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:25:49,405 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:25:49,419 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:25:49,426 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:25:49,440 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:25:49,441 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:25:49,459 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:25:49,475 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:25:49,480 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0059
2021-10-10 19:25:49,480 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:25:49,704 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0059
2021-10-10 19:25:49,732 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0059/
2021-10-10 19:25:49,732 INFO mapreduce.Job: Running job: job_1633917566916_0059
2021-10-10 19:26:02,937 INFO mapreduce.Job: Job job_1633917566916_0059 running in uber mode : false
2021-10-10 19:26:02,937 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:26:08,168 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:26:14,213 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:26:14,223 INFO mapreduce.Job: Job job_1633917566916_0059 completed successfully
2021-10-10 19:26:14,262 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=4662
		FILE: Number of bytes written=446219
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3094
		Total time spent by all reduces in occupied slots (ms)=3168
		Total time spent by all map tasks (ms)=3094
		Total time spent by all reduce tasks (ms)=3168
		Total vcore-milliseconds taken by all map tasks=3094
		Total vcore-milliseconds taken by all reduce tasks=3168
		Total megabyte-milliseconds taken by all map tasks=3168256
		Total megabyte-milliseconds taken by all reduce tasks=3244032
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=4584
		Map output materialized bytes=4662
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=4662
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=145
		CPU time spent (ms)=1070
		Physical memory (bytes) snapshot=329048064
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=213430272
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115617792
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:26:14,277 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:26:14,283 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:26:14,298 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:26:14,312 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:26:14,346 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:26:14,360 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:26:14,364 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0060
2021-10-10 19:26:14,371 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:26:14,382 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:26:14,391 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:26:14,398 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:26:14,411 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.closeInternal(DataStreamer.java:847)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:843)
2021-10-10 19:26:14,422 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:26:14,434 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:26:14,438 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:26:14,456 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:26:14,473 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:26:14,478 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0060
2021-10-10 19:26:14,479 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:26:14,698 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0060
2021-10-10 19:26:14,705 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0060/
2021-10-10 19:26:14,707 INFO mapreduce.Job: Running job: job_1633917566916_0060
2021-10-10 19:26:27,866 INFO mapreduce.Job: Job job_1633917566916_0060 running in uber mode : false
2021-10-10 19:26:27,866 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:26:33,941 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:26:39,975 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:26:40,000 INFO mapreduce.Job: Job job_1633917566916_0060 completed successfully
2021-10-10 19:26:40,055 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=4662
		FILE: Number of bytes written=446219
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3103
		Total time spent by all reduces in occupied slots (ms)=3238
		Total time spent by all map tasks (ms)=3103
		Total time spent by all reduce tasks (ms)=3238
		Total vcore-milliseconds taken by all map tasks=3103
		Total vcore-milliseconds taken by all reduce tasks=3238
		Total megabyte-milliseconds taken by all map tasks=3177472
		Total megabyte-milliseconds taken by all reduce tasks=3315712
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=4584
		Map output materialized bytes=4662
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=4662
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=143
		CPU time spent (ms)=1120
		Physical memory (bytes) snapshot=331317248
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215224320
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=116092928
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:26:40,062 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:26:40,078 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:26:40,094 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:26:40,122 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:26:40,137 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:26:40,142 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:26:40,147 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:26:40,160 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.closeInternal(DataStreamer.java:847)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:843)
2021-10-10 19:26:40,170 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:26:40,185 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:26:40,206 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:26:40,218 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:26:40,222 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0061
2021-10-10 19:26:40,232 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:26:40,254 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:26:40,261 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:26:40,279 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:26:40,295 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:26:40,309 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:26:40,330 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:26:40,335 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0061
2021-10-10 19:26:40,335 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:26:40,554 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0061
2021-10-10 19:26:40,566 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0061/
2021-10-10 19:26:40,568 INFO mapreduce.Job: Running job: job_1633917566916_0061
2021-10-10 19:26:52,708 INFO mapreduce.Job: Job job_1633917566916_0061 running in uber mode : false
2021-10-10 19:26:52,711 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:26:57,769 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:27:03,821 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:27:03,828 INFO mapreduce.Job: Job job_1633917566916_0061 completed successfully
2021-10-10 19:27:03,869 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=4950
		FILE: Number of bytes written=446795
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2996
		Total time spent by all reduces in occupied slots (ms)=3172
		Total time spent by all map tasks (ms)=2996
		Total time spent by all reduce tasks (ms)=3172
		Total vcore-milliseconds taken by all map tasks=2996
		Total vcore-milliseconds taken by all reduce tasks=3172
		Total megabyte-milliseconds taken by all map tasks=3067904
		Total megabyte-milliseconds taken by all reduce tasks=3248128
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=4872
		Map output materialized bytes=4950
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=4950
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=140
		CPU time spent (ms)=1090
		Physical memory (bytes) snapshot=328704000
		Virtual memory (bytes) snapshot=5163872256
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215240704
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=113463296
		Peak Reduce Virtual memory (bytes)=2586443776
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:27:03,894 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:27:03,912 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:27:03,936 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:27:03,970 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:27:03,981 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:27:03,986 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0062
2021-10-10 19:27:03,993 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:27:04,006 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:27:04,016 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:27:04,023 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:27:04,036 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:27:04,047 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:27:04,060 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:27:04,062 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:27:04,074 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:27:04,095 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:27:04,100 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0062
2021-10-10 19:27:04,101 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:27:04,117 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0062
2021-10-10 19:27:04,127 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0062/
2021-10-10 19:27:04,128 INFO mapreduce.Job: Running job: job_1633917566916_0062
2021-10-10 19:27:17,282 INFO mapreduce.Job: Job job_1633917566916_0062 running in uber mode : false
2021-10-10 19:27:17,282 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:27:22,331 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:27:28,374 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:27:28,383 INFO mapreduce.Job: Job job_1633917566916_0062 completed successfully
2021-10-10 19:27:28,437 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=4950
		FILE: Number of bytes written=446795
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2967
		Total time spent by all reduces in occupied slots (ms)=3229
		Total time spent by all map tasks (ms)=2967
		Total time spent by all reduce tasks (ms)=3229
		Total vcore-milliseconds taken by all map tasks=2967
		Total vcore-milliseconds taken by all reduce tasks=3229
		Total megabyte-milliseconds taken by all map tasks=3038208
		Total megabyte-milliseconds taken by all reduce tasks=3306496
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=4872
		Map output materialized bytes=4950
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=4950
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=131
		CPU time spent (ms)=1040
		Physical memory (bytes) snapshot=332464128
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215072768
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117391360
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:27:28,444 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:27:28,456 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:27:28,483 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:27:28,552 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:27:28,563 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:27:28,567 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0063
2021-10-10 19:27:28,575 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:27:28,587 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:27:28,595 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:27:28,600 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:27:28,618 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:27:28,633 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:27:28,640 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:27:28,652 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:27:28,670 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:27:28,674 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0063
2021-10-10 19:27:28,675 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:27:28,892 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0063
2021-10-10 19:27:28,898 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0063/
2021-10-10 19:27:28,898 INFO mapreduce.Job: Running job: job_1633917566916_0063
2021-10-10 19:27:43,053 INFO mapreduce.Job: Job job_1633917566916_0063 running in uber mode : false
2021-10-10 19:27:43,054 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:27:48,138 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:27:54,213 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:27:54,240 INFO mapreduce.Job: Job job_1633917566916_0063 completed successfully
2021-10-10 19:27:54,302 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=4950
		FILE: Number of bytes written=446795
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3424
		Total time spent by all reduces in occupied slots (ms)=3120
		Total time spent by all map tasks (ms)=3424
		Total time spent by all reduce tasks (ms)=3120
		Total vcore-milliseconds taken by all map tasks=3424
		Total vcore-milliseconds taken by all reduce tasks=3120
		Total megabyte-milliseconds taken by all map tasks=3506176
		Total megabyte-milliseconds taken by all reduce tasks=3194880
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=4872
		Map output materialized bytes=4950
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=4950
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=134
		CPU time spent (ms)=1330
		Physical memory (bytes) snapshot=330223616
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=214888448
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115335168
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:27:54,326 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:27:54,333 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:27:54,359 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:27:54,402 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:27:54,416 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:27:54,420 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0064
2021-10-10 19:27:54,431 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:27:54,445 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:27:54,457 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:27:54,469 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:27:54,490 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:27:54,501 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:27:54,518 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:27:54,540 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0064
2021-10-10 19:27:54,542 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:27:54,561 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0064
2021-10-10 19:27:54,570 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0064/
2021-10-10 19:27:54,572 INFO mapreduce.Job: Running job: job_1633917566916_0064
2021-10-10 19:28:07,735 INFO mapreduce.Job: Job job_1633917566916_0064 running in uber mode : false
2021-10-10 19:28:07,735 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:28:13,804 INFO mapreduce.Job: Task Id : attempt_1633917566916_0064_m_000000_0, Status : FAILED
[2021-10-10 19:28:12.419]Container [pid=11211,containerID=container_1633917566916_0064_01_000002] is running 322570752B beyond the 'VIRTUAL' memory limit. Current usage: 206.2 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0064_01_000002 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 11211 11209 11211 11211 (bash) 0 0 10162176 696 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0064/container_1633917566916_0064_01_000002/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0064/container_1633917566916_0064_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.10.102 32865 attempt_1633917566916_0064_m_000000_0 2 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0064/container_1633917566916_0064_01_000002/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0064/container_1633917566916_0064_01_000002/stderr  
	|- 11222 11211 11211 11211 (java) 165 196 2567266304 52100 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0064/container_1633917566916_0064_01_000002/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0064/container_1633917566916_0064_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.10.102 32865 attempt_1633917566916_0064_m_000000_0 2 

[2021-10-10 19:28:12.444]Container killed on request. Exit code is 143
[2021-10-10 19:28:12.446]Container exited with a non-zero exit code 143. 

2021-10-10 19:28:19,866 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:28:24,893 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:28:24,904 INFO mapreduce.Job: Job job_1633917566916_0064 completed successfully
2021-10-10 19:28:24,938 INFO mapreduce.Job: Counters: 55
	File System Counters
		FILE: Number of bytes read=4950
		FILE: Number of bytes written=446795
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed map tasks=1
		Launched map tasks=2
		Launched reduce tasks=1
		Other local map tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=7577
		Total time spent by all reduces in occupied slots (ms)=3049
		Total time spent by all map tasks (ms)=7577
		Total time spent by all reduce tasks (ms)=3049
		Total vcore-milliseconds taken by all map tasks=7577
		Total vcore-milliseconds taken by all reduce tasks=3049
		Total megabyte-milliseconds taken by all map tasks=7758848
		Total megabyte-milliseconds taken by all reduce tasks=3122176
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=4872
		Map output materialized bytes=4950
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=4950
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=134
		CPU time spent (ms)=1020
		Physical memory (bytes) snapshot=331153408
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215363584
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115789824
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:28:24,951 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:28:24,980 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:28:24,996 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:28:25,041 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:28:25,058 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:28:25,064 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0065
2021-10-10 19:28:25,083 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:28:25,103 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:28:25,114 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:28:25,139 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:28:25,164 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:28:25,182 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:28:25,202 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0065
2021-10-10 19:28:25,203 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:28:25,421 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0065
2021-10-10 19:28:25,426 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0065/
2021-10-10 19:28:25,427 INFO mapreduce.Job: Running job: job_1633917566916_0065
2021-10-10 19:28:37,595 INFO mapreduce.Job: Job job_1633917566916_0065 running in uber mode : false
2021-10-10 19:28:37,595 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:28:43,743 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:28:48,774 INFO mapreduce.Job: Task Id : attempt_1633917566916_0065_r_000000_0, Status : FAILED
[2021-10-10 19:28:47.972]Container [pid=22286,containerID=container_1633917566916_0065_01_000003] is running 293706240B beyond the 'VIRTUAL' memory limit. Current usage: 77.3 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0065_01_000003 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 22286 22284 22286 22286 (bash) 0 1 10162176 685 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0065/container_1633917566916_0065_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0065/container_1633917566916_0065_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.101 43459 attempt_1633917566916_0065_r_000000_0 3 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0065/container_1633917566916_0065_01_000003/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0065/container_1633917566916_0065_01_000003/stderr  
	|- 22297 22286 22286 22286 (java) 56 187 2538401792 19107 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0065/container_1633917566916_0065_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0065/container_1633917566916_0065_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.101 43459 attempt_1633917566916_0065_r_000000_0 3 

[2021-10-10 19:28:48.007]Container killed on request. Exit code is 143
[2021-10-10 19:28:48.009]Container exited with a non-zero exit code 143. 

2021-10-10 19:28:56,831 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:28:56,863 INFO mapreduce.Job: Job job_1633917566916_0065 completed successfully
2021-10-10 19:28:56,948 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=4950
		FILE: Number of bytes written=446795
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed reduce tasks=1
		Launched map tasks=1
		Launched reduce tasks=2
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3015
		Total time spent by all reduces in occupied slots (ms)=7195
		Total time spent by all map tasks (ms)=3015
		Total time spent by all reduce tasks (ms)=7195
		Total vcore-milliseconds taken by all map tasks=3015
		Total vcore-milliseconds taken by all reduce tasks=7195
		Total megabyte-milliseconds taken by all map tasks=3087360
		Total megabyte-milliseconds taken by all reduce tasks=7367680
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=4872
		Map output materialized bytes=4950
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=4950
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=143
		CPU time spent (ms)=1110
		Physical memory (bytes) snapshot=330481664
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215629824
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=114851840
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:28:56,956 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:28:56,967 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:28:56,998 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:28:57,021 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:28:57,025 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:28:57,032 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:28:57,050 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:28:57,082 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:28:57,093 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:28:57,096 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0066
2021-10-10 19:28:57,105 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:28:57,117 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:28:57,126 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:28:57,134 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:28:57,148 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:28:57,162 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:28:57,191 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:28:57,209 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:28:57,223 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:28:57,227 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0066
2021-10-10 19:28:57,228 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:28:57,241 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0066
2021-10-10 19:28:57,247 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0066/
2021-10-10 19:28:57,249 INFO mapreduce.Job: Running job: job_1633917566916_0066
2021-10-10 19:29:10,366 INFO mapreduce.Job: Job job_1633917566916_0066 running in uber mode : false
2021-10-10 19:29:10,367 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:29:15,402 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:29:21,452 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:29:21,467 INFO mapreduce.Job: Job job_1633917566916_0066 completed successfully
2021-10-10 19:29:21,556 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=5238
		FILE: Number of bytes written=447371
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2935
		Total time spent by all reduces in occupied slots (ms)=3254
		Total time spent by all map tasks (ms)=2935
		Total time spent by all reduce tasks (ms)=3254
		Total vcore-milliseconds taken by all map tasks=2935
		Total vcore-milliseconds taken by all reduce tasks=3254
		Total megabyte-milliseconds taken by all map tasks=3005440
		Total megabyte-milliseconds taken by all reduce tasks=3332096
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=5160
		Map output materialized bytes=5238
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=5238
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=140
		CPU time spent (ms)=1060
		Physical memory (bytes) snapshot=330883072
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216702976
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=114180096
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:29:21,568 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:29:21,594 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:29:21,614 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:29:21,644 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:29:21,665 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:29:21,674 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0067
2021-10-10 19:29:21,691 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:29:21,730 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:29:21,738 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:29:21,753 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:29:21,770 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:29:21,775 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:29:21,801 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:29:21,837 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0067
2021-10-10 19:29:21,837 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:29:21,857 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0067
2021-10-10 19:29:21,858 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0067/
2021-10-10 19:29:21,859 INFO mapreduce.Job: Running job: job_1633917566916_0067
2021-10-10 19:29:34,056 INFO mapreduce.Job: Job job_1633917566916_0067 running in uber mode : false
2021-10-10 19:29:34,059 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:29:39,135 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:29:45,191 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:29:46,204 INFO mapreduce.Job: Job job_1633917566916_0067 completed successfully
2021-10-10 19:29:46,257 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=5238
		FILE: Number of bytes written=447371
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2962
		Total time spent by all reduces in occupied slots (ms)=3265
		Total time spent by all map tasks (ms)=2962
		Total time spent by all reduce tasks (ms)=3265
		Total vcore-milliseconds taken by all map tasks=2962
		Total vcore-milliseconds taken by all reduce tasks=3265
		Total megabyte-milliseconds taken by all map tasks=3033088
		Total megabyte-milliseconds taken by all reduce tasks=3343360
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=5160
		Map output materialized bytes=5238
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=5238
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=136
		CPU time spent (ms)=1080
		Physical memory (bytes) snapshot=330076160
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=212340736
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117735424
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:29:46,270 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:29:46,286 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:29:46,310 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:29:46,328 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:29:46,350 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:29:46,362 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:29:46,366 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0068
2021-10-10 19:29:46,372 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:29:46,399 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:29:46,410 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:29:46,425 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:29:46,437 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:29:46,450 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:29:46,469 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:29:46,474 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0068
2021-10-10 19:29:46,474 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:29:46,490 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0068
2021-10-10 19:29:46,494 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0068/
2021-10-10 19:29:46,495 INFO mapreduce.Job: Running job: job_1633917566916_0068
2021-10-10 19:29:58,649 INFO mapreduce.Job: Job job_1633917566916_0068 running in uber mode : false
2021-10-10 19:29:58,653 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:30:03,751 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:30:09,805 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:30:09,825 INFO mapreduce.Job: Job job_1633917566916_0068 completed successfully
2021-10-10 19:30:09,863 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=5238
		FILE: Number of bytes written=447371
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3132
		Total time spent by all reduces in occupied slots (ms)=3226
		Total time spent by all map tasks (ms)=3132
		Total time spent by all reduce tasks (ms)=3226
		Total vcore-milliseconds taken by all map tasks=3132
		Total vcore-milliseconds taken by all reduce tasks=3226
		Total megabyte-milliseconds taken by all map tasks=3207168
		Total megabyte-milliseconds taken by all reduce tasks=3303424
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=5160
		Map output materialized bytes=5238
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=5238
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=134
		CPU time spent (ms)=1030
		Physical memory (bytes) snapshot=333697024
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216444928
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117252096
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:30:09,872 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:30:09,879 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:30:09,902 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:30:09,940 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:30:09,952 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:30:09,956 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0069
2021-10-10 19:30:09,962 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:30:09,974 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:30:09,983 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:30:09,991 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:30:10,008 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:30:10,023 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:30:10,045 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:30:10,063 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0069
2021-10-10 19:30:10,063 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:30:10,072 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0069
2021-10-10 19:30:10,077 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0069/
2021-10-10 19:30:10,078 INFO mapreduce.Job: Running job: job_1633917566916_0069
2021-10-10 19:30:23,250 INFO mapreduce.Job: Job job_1633917566916_0069 running in uber mode : false
2021-10-10 19:30:23,251 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:30:30,317 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:30:36,352 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:30:36,379 INFO mapreduce.Job: Job job_1633917566916_0069 completed successfully
2021-10-10 19:30:36,418 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=5238
		FILE: Number of bytes written=447371
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=4235
		Total time spent by all reduces in occupied slots (ms)=3402
		Total time spent by all map tasks (ms)=4235
		Total time spent by all reduce tasks (ms)=3402
		Total vcore-milliseconds taken by all map tasks=4235
		Total vcore-milliseconds taken by all reduce tasks=3402
		Total megabyte-milliseconds taken by all map tasks=4336640
		Total megabyte-milliseconds taken by all reduce tasks=3483648
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=5160
		Map output materialized bytes=5238
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=5238
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=176
		CPU time spent (ms)=1100
		Physical memory (bytes) snapshot=329347072
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215609344
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=113737728
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:30:36,431 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:30:36,438 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:30:36,455 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:30:36,482 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:30:36,524 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:30:36,535 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:30:36,540 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0070
2021-10-10 19:30:36,551 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:30:36,567 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:30:36,574 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:30:36,597 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:30:36,612 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:30:36,624 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:30:36,655 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0070
2021-10-10 19:30:36,656 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:30:36,667 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0070
2021-10-10 19:30:36,670 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0070/
2021-10-10 19:30:36,670 INFO mapreduce.Job: Running job: job_1633917566916_0070
2021-10-10 19:30:48,863 INFO mapreduce.Job: Job job_1633917566916_0070 running in uber mode : false
2021-10-10 19:30:48,863 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:30:53,908 INFO mapreduce.Job: Task Id : attempt_1633917566916_0070_m_000000_0, Status : FAILED
[2021-10-10 19:30:53.331]Container [pid=13377,containerID=container_1633917566916_0070_01_000002] is running 319420928B beyond the 'VIRTUAL' memory limit. Current usage: 176.2 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0070_01_000002 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 13377 13375 13377 13377 (bash) 0 0 10162176 677 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0070/container_1633917566916_0070_01_000002/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0070/container_1633917566916_0070_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.10.101 38211 attempt_1633917566916_0070_m_000000_0 2 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0070/container_1633917566916_0070_01_000002/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0070/container_1633917566916_0070_01_000002/stderr  
	|- 13388 13377 13377 13377 (java) 203 128 2564116480 44438 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0070/container_1633917566916_0070_01_000002/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0070/container_1633917566916_0070_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.10.101 38211 attempt_1633917566916_0070_m_000000_0 2 

[2021-10-10 19:30:53.388]Container killed on request. Exit code is 143
[2021-10-10 19:30:53.396]Container exited with a non-zero exit code 143. 

2021-10-10 19:31:02,004 INFO mapreduce.Job: Task Id : attempt_1633917566916_0070_m_000000_1, Status : FAILED
[2021-10-10 19:31:00.873]Container [pid=11973,containerID=container_1633917566916_0070_01_000003] is running 319420928B beyond the 'VIRTUAL' memory limit. Current usage: 177.9 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0070_01_000003 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 11973 11971 11973 11973 (bash) 0 0 10162176 665 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0070/container_1633917566916_0070_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0070/container_1633917566916_0070_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.10.101 38211 attempt_1633917566916_0070_m_000000_1 3 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0070/container_1633917566916_0070_01_000003/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0070/container_1633917566916_0070_01_000003/stderr  
	|- 11984 11973 11973 11973 (java) 147 358 2564116480 44874 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0070/container_1633917566916_0070_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0070/container_1633917566916_0070_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.10.101 38211 attempt_1633917566916_0070_m_000000_1 3 

[2021-10-10 19:31:00.924]Container killed on request. Exit code is 143
[2021-10-10 19:31:00.932]Container exited with a non-zero exit code 143. 

2021-10-10 19:31:08,073 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:31:13,116 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:31:14,156 INFO mapreduce.Job: Job job_1633917566916_0070 completed successfully
2021-10-10 19:31:14,235 INFO mapreduce.Job: Counters: 55
	File System Counters
		FILE: Number of bytes read=5238
		FILE: Number of bytes written=447371
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=263
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed map tasks=2
		Launched map tasks=3
		Launched reduce tasks=1
		Other local map tasks=2
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=12566
		Total time spent by all reduces in occupied slots (ms)=3241
		Total time spent by all map tasks (ms)=12566
		Total time spent by all reduce tasks (ms)=3241
		Total vcore-milliseconds taken by all map tasks=12566
		Total vcore-milliseconds taken by all reduce tasks=3241
		Total megabyte-milliseconds taken by all map tasks=12867584
		Total megabyte-milliseconds taken by all reduce tasks=3318784
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=5160
		Map output materialized bytes=5238
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=5238
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=143
		CPU time spent (ms)=980
		Physical memory (bytes) snapshot=333225984
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216010752
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117215232
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=263
2021-10-10 19:31:14,264 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:31:14,300 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:31:14,316 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:31:14,340 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:31:14,357 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:31:14,364 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:31:14,371 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:31:14,382 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:31:14,389 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:31:14,425 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:31:14,438 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:31:14,443 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0071
2021-10-10 19:31:14,454 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:31:14,471 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:31:14,483 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:31:14,500 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:31:14,516 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:31:14,530 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:31:14,549 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:31:14,553 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0071
2021-10-10 19:31:14,553 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:31:14,565 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0071
2021-10-10 19:31:14,569 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0071/
2021-10-10 19:31:14,571 INFO mapreduce.Job: Running job: job_1633917566916_0071
2021-10-10 19:31:26,842 INFO mapreduce.Job: Job job_1633917566916_0071 running in uber mode : false
2021-10-10 19:31:26,842 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:31:33,910 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:31:39,957 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:31:39,981 INFO mapreduce.Job: Job job_1633917566916_0071 completed successfully
2021-10-10 19:31:40,040 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=5526
		FILE: Number of bytes written=447947
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3975
		Total time spent by all reduces in occupied slots (ms)=3493
		Total time spent by all map tasks (ms)=3975
		Total time spent by all reduce tasks (ms)=3493
		Total vcore-milliseconds taken by all map tasks=3975
		Total vcore-milliseconds taken by all reduce tasks=3493
		Total megabyte-milliseconds taken by all map tasks=4070400
		Total megabyte-milliseconds taken by all reduce tasks=3576832
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=5448
		Map output materialized bytes=5526
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=5526
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=153
		CPU time spent (ms)=1210
		Physical memory (bytes) snapshot=332169216
		Virtual memory (bytes) snapshot=5164011520
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216457216
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115712000
		Peak Reduce Virtual memory (bytes)=2586583040
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:31:40,059 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:31:40,069 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:31:40,090 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:31:40,176 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:31:40,192 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:31:40,196 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0072
2021-10-10 19:31:40,206 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:31:40,224 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:31:40,235 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:31:40,262 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:31:40,278 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:31:40,298 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:31:40,314 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0072
2021-10-10 19:31:40,316 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:31:40,335 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0072
2021-10-10 19:31:40,340 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0072/
2021-10-10 19:31:40,341 INFO mapreduce.Job: Running job: job_1633917566916_0072
2021-10-10 19:31:52,473 INFO mapreduce.Job: Job job_1633917566916_0072 running in uber mode : false
2021-10-10 19:31:52,473 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:31:57,518 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:32:03,555 INFO mapreduce.Job: Task Id : attempt_1633917566916_0072_r_000000_0, Status : FAILED
[2021-10-10 19:32:02.727]Container [pid=13788,containerID=container_1633917566916_0072_01_000003] is running 326945280B beyond the 'VIRTUAL' memory limit. Current usage: 105.0 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0072_01_000003 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 13788 13786 13788 13788 (bash) 0 0 10162176 684 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0072/container_1633917566916_0072_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0072/container_1633917566916_0072_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.101 36367 attempt_1633917566916_0072_r_000000_0 3 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0072/container_1633917566916_0072_01_000003/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0072/container_1633917566916_0072_01_000003/stderr  
	|- 13799 13788 13788 13788 (java) 158 168 2571640832 26202 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0072/container_1633917566916_0072_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0072/container_1633917566916_0072_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.101 36367 attempt_1633917566916_0072_r_000000_0 3 

[2021-10-10 19:32:02.764]Container killed on request. Exit code is 143
[2021-10-10 19:32:02.773]Container exited with a non-zero exit code 143. 

2021-10-10 19:32:10,631 INFO mapreduce.Job: Task Id : attempt_1633917566916_0072_r_000000_1, Status : FAILED
[2021-10-10 19:32:09.598]Container [pid=24068,containerID=container_1633917566916_0072_01_000004] is running 326945280B beyond the 'VIRTUAL' memory limit. Current usage: 102.2 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0072_01_000004 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 24068 24066 24068 24068 (bash) 0 0 10162176 687 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0072/container_1633917566916_0072_01_000004/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0072/container_1633917566916_0072_01_000004 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.101 36367 attempt_1633917566916_0072_r_000000_1 4 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0072/container_1633917566916_0072_01_000004/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0072/container_1633917566916_0072_01_000004/stderr  
	|- 24079 24068 24068 24068 (java) 215 89 2571640832 25485 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0072/container_1633917566916_0072_01_000004/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0072/container_1633917566916_0072_01_000004 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.101 36367 attempt_1633917566916_0072_r_000000_1 4 

[2021-10-10 19:32:09.624]Container killed on request. Exit code is 143
[2021-10-10 19:32:09.639]Container exited with a non-zero exit code 143. 

2021-10-10 19:32:17,695 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:32:18,731 INFO mapreduce.Job: Job job_1633917566916_0072 completed successfully
2021-10-10 19:32:18,780 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=5526
		FILE: Number of bytes written=447947
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed reduce tasks=2
		Launched map tasks=1
		Launched reduce tasks=3
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2930
		Total time spent by all reduces in occupied slots (ms)=11226
		Total time spent by all map tasks (ms)=2930
		Total time spent by all reduce tasks (ms)=11226
		Total vcore-milliseconds taken by all map tasks=2930
		Total vcore-milliseconds taken by all reduce tasks=11226
		Total megabyte-milliseconds taken by all map tasks=3000320
		Total megabyte-milliseconds taken by all reduce tasks=11495424
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=5448
		Map output materialized bytes=5526
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=5526
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=136
		CPU time spent (ms)=1050
		Physical memory (bytes) snapshot=328937472
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=214065152
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=114872320
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:32:18,790 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:32:18,797 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:32:18,814 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:32:18,852 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:32:18,864 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:32:18,867 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0073
2021-10-10 19:32:18,874 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:32:18,894 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:32:18,905 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:32:18,924 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:32:18,937 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:32:18,948 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:32:18,989 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0073
2021-10-10 19:32:18,989 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:32:19,007 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0073
2021-10-10 19:32:19,011 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0073/
2021-10-10 19:32:19,012 INFO mapreduce.Job: Running job: job_1633917566916_0073
2021-10-10 19:32:33,181 INFO mapreduce.Job: Job job_1633917566916_0073 running in uber mode : false
2021-10-10 19:32:33,184 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:32:38,256 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:32:44,295 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:32:44,309 INFO mapreduce.Job: Job job_1633917566916_0073 completed successfully
2021-10-10 19:32:44,348 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=5526
		FILE: Number of bytes written=447947
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2909
		Total time spent by all reduces in occupied slots (ms)=3350
		Total time spent by all map tasks (ms)=2909
		Total time spent by all reduce tasks (ms)=3350
		Total vcore-milliseconds taken by all map tasks=2909
		Total vcore-milliseconds taken by all reduce tasks=3350
		Total megabyte-milliseconds taken by all map tasks=2978816
		Total megabyte-milliseconds taken by all reduce tasks=3430400
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=5448
		Map output materialized bytes=5526
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=5526
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=132
		CPU time spent (ms)=1060
		Physical memory (bytes) snapshot=330883072
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215691264
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115191808
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:32:44,355 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:32:44,366 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:32:44,384 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:32:44,397 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:32:44,490 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:32:44,507 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:32:44,511 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0074
2021-10-10 19:32:44,519 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:32:44,541 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:32:44,555 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:32:44,584 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:32:44,612 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:32:44,624 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:32:44,652 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:32:44,657 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0074
2021-10-10 19:32:44,657 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:32:44,881 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0074
2021-10-10 19:32:44,894 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0074/
2021-10-10 19:32:44,896 INFO mapreduce.Job: Running job: job_1633917566916_0074
2021-10-10 19:32:58,135 INFO mapreduce.Job: Job job_1633917566916_0074 running in uber mode : false
2021-10-10 19:32:58,135 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:33:03,194 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:33:09,271 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:33:09,302 INFO mapreduce.Job: Job job_1633917566916_0074 completed successfully
2021-10-10 19:33:09,374 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=5526
		FILE: Number of bytes written=447947
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=263
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3473
		Total time spent by all reduces in occupied slots (ms)=3192
		Total time spent by all map tasks (ms)=3473
		Total time spent by all reduce tasks (ms)=3192
		Total vcore-milliseconds taken by all map tasks=3473
		Total vcore-milliseconds taken by all reduce tasks=3192
		Total megabyte-milliseconds taken by all map tasks=3556352
		Total megabyte-milliseconds taken by all reduce tasks=3268608
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=5448
		Map output materialized bytes=5526
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=5526
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=141
		CPU time spent (ms)=1130
		Physical memory (bytes) snapshot=329289728
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=213798912
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115490816
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=263
2021-10-10 19:33:09,386 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:33:09,404 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:33:09,421 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:33:09,437 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:33:09,460 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:33:09,470 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:33:09,473 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0075
2021-10-10 19:33:09,481 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:33:09,499 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:33:09,506 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:33:09,515 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:33:09,530 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:33:09,542 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:33:09,546 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:33:09,564 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:33:09,579 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:33:09,584 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0075
2021-10-10 19:33:09,584 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:33:09,603 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0075
2021-10-10 19:33:09,607 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0075/
2021-10-10 19:33:09,609 INFO mapreduce.Job: Running job: job_1633917566916_0075
2021-10-10 19:33:21,802 INFO mapreduce.Job: Job job_1633917566916_0075 running in uber mode : false
2021-10-10 19:33:21,802 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:33:26,975 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:33:35,064 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:33:35,087 INFO mapreduce.Job: Job job_1633917566916_0075 completed successfully
2021-10-10 19:33:35,169 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=5526
		FILE: Number of bytes written=447947
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2857
		Total time spent by all reduces in occupied slots (ms)=4280
		Total time spent by all map tasks (ms)=2857
		Total time spent by all reduce tasks (ms)=4280
		Total vcore-milliseconds taken by all map tasks=2857
		Total vcore-milliseconds taken by all reduce tasks=4280
		Total megabyte-milliseconds taken by all map tasks=2925568
		Total megabyte-milliseconds taken by all reduce tasks=4382720
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=5448
		Map output materialized bytes=5526
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=5526
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=133
		CPU time spent (ms)=1060
		Physical memory (bytes) snapshot=327106560
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=212508672
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=114597888
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:33:35,181 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:33:35,187 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:33:35,202 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:33:35,224 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:33:35,238 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:33:35,245 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:33:35,252 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:33:35,264 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:33:35,270 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:33:35,284 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.closeInternal(DataStreamer.java:847)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:843)
2021-10-10 19:33:35,302 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:33:35,314 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:33:35,318 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0076
2021-10-10 19:33:35,325 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:33:35,341 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:33:35,349 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:33:35,355 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:33:35,367 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:33:35,376 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:33:35,391 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:33:35,396 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:33:35,410 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:33:35,445 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0076
2021-10-10 19:33:35,445 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:33:35,472 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0076
2021-10-10 19:33:35,476 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0076/
2021-10-10 19:33:35,476 INFO mapreduce.Job: Running job: job_1633917566916_0076
2021-10-10 19:33:47,678 INFO mapreduce.Job: Job job_1633917566916_0076 running in uber mode : false
2021-10-10 19:33:47,679 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:33:53,780 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:33:59,844 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:33:59,870 INFO mapreduce.Job: Job job_1633917566916_0076 completed successfully
2021-10-10 19:33:59,912 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=5814
		FILE: Number of bytes written=448523
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3267
		Total time spent by all reduces in occupied slots (ms)=3170
		Total time spent by all map tasks (ms)=3267
		Total time spent by all reduce tasks (ms)=3170
		Total vcore-milliseconds taken by all map tasks=3267
		Total vcore-milliseconds taken by all reduce tasks=3170
		Total megabyte-milliseconds taken by all map tasks=3345408
		Total megabyte-milliseconds taken by all reduce tasks=3246080
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=5736
		Map output materialized bytes=5814
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=5814
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=154
		CPU time spent (ms)=1370
		Physical memory (bytes) snapshot=333770752
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216166400
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117604352
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:33:59,935 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:33:59,950 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:33:59,963 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:33:59,973 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:33:59,983 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:34:00,021 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:34:00,045 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:34:00,048 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0077
2021-10-10 19:34:00,059 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:34:00,085 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:34:00,094 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:34:00,121 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:34:00,142 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:34:00,146 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:34:00,160 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:34:00,180 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0077
2021-10-10 19:34:00,180 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:34:00,211 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0077
2021-10-10 19:34:00,215 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0077/
2021-10-10 19:34:00,216 INFO mapreduce.Job: Running job: job_1633917566916_0077
2021-10-10 19:34:12,370 INFO mapreduce.Job: Job job_1633917566916_0077 running in uber mode : false
2021-10-10 19:34:12,370 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:34:18,479 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:34:26,531 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:34:26,563 INFO mapreduce.Job: Job job_1633917566916_0077 completed successfully
2021-10-10 19:34:26,624 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=5814
		FILE: Number of bytes written=448523
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3616
		Total time spent by all reduces in occupied slots (ms)=4311
		Total time spent by all map tasks (ms)=3616
		Total time spent by all reduce tasks (ms)=4311
		Total vcore-milliseconds taken by all map tasks=3616
		Total vcore-milliseconds taken by all reduce tasks=4311
		Total megabyte-milliseconds taken by all map tasks=3702784
		Total megabyte-milliseconds taken by all reduce tasks=4414464
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=5736
		Map output materialized bytes=5814
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=5814
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=175
		CPU time spent (ms)=1360
		Physical memory (bytes) snapshot=333873152
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216309760
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117563392
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:34:26,633 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:34:26,641 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:34:26,652 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:34:26,660 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:34:26,675 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.closeInternal(DataStreamer.java:847)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:843)
2021-10-10 19:34:26,699 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:34:26,709 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:34:26,712 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0078
2021-10-10 19:34:26,719 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:34:26,734 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:34:26,742 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:34:26,752 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:34:26,764 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:34:26,772 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:34:26,783 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:34:26,785 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:34:26,805 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:34:26,822 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:34:26,827 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0078
2021-10-10 19:34:26,827 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:34:27,043 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0078
2021-10-10 19:34:27,050 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0078/
2021-10-10 19:34:27,051 INFO mapreduce.Job: Running job: job_1633917566916_0078
2021-10-10 19:34:39,183 INFO mapreduce.Job: Job job_1633917566916_0078 running in uber mode : false
2021-10-10 19:34:39,190 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:34:45,278 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:34:50,322 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:34:51,353 INFO mapreduce.Job: Job job_1633917566916_0078 completed successfully
2021-10-10 19:34:51,432 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=5814
		FILE: Number of bytes written=448523
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3543
		Total time spent by all reduces in occupied slots (ms)=3244
		Total time spent by all map tasks (ms)=3543
		Total time spent by all reduce tasks (ms)=3244
		Total vcore-milliseconds taken by all map tasks=3543
		Total vcore-milliseconds taken by all reduce tasks=3244
		Total megabyte-milliseconds taken by all map tasks=3628032
		Total megabyte-milliseconds taken by all reduce tasks=3321856
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=5736
		Map output materialized bytes=5814
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=5814
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=146
		CPU time spent (ms)=1440
		Physical memory (bytes) snapshot=332120064
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=214806528
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117313536
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:34:51,446 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:34:51,455 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:34:51,476 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:34:51,588 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:34:51,599 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:34:51,603 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0079
2021-10-10 19:34:51,610 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:34:51,625 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:34:51,631 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:34:51,648 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:34:51,661 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:34:51,666 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:34:51,683 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:34:51,697 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:34:51,703 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0079
2021-10-10 19:34:51,703 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:34:51,723 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0079
2021-10-10 19:34:51,727 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0079/
2021-10-10 19:34:51,728 INFO mapreduce.Job: Running job: job_1633917566916_0079
2021-10-10 19:35:03,903 INFO mapreduce.Job: Job job_1633917566916_0079 running in uber mode : false
2021-10-10 19:35:03,903 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:35:08,985 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:35:15,059 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:35:15,096 INFO mapreduce.Job: Job job_1633917566916_0079 completed successfully
2021-10-10 19:35:15,138 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=5814
		FILE: Number of bytes written=448523
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2977
		Total time spent by all reduces in occupied slots (ms)=3130
		Total time spent by all map tasks (ms)=2977
		Total time spent by all reduce tasks (ms)=3130
		Total vcore-milliseconds taken by all map tasks=2977
		Total vcore-milliseconds taken by all reduce tasks=3130
		Total megabyte-milliseconds taken by all map tasks=3048448
		Total megabyte-milliseconds taken by all reduce tasks=3205120
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=5736
		Map output materialized bytes=5814
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=5814
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=132
		CPU time spent (ms)=1070
		Physical memory (bytes) snapshot=330936320
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215724032
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115212288
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:35:15,145 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:35:15,151 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:35:15,179 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:35:15,245 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:35:15,255 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:35:15,260 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0080
2021-10-10 19:35:15,268 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:35:15,287 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:35:15,294 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:35:15,307 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:35:15,322 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:35:15,337 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:35:15,354 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:35:15,375 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:35:15,381 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0080
2021-10-10 19:35:15,382 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:35:15,595 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0080
2021-10-10 19:35:15,599 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0080/
2021-10-10 19:35:15,599 INFO mapreduce.Job: Running job: job_1633917566916_0080
2021-10-10 19:35:27,742 INFO mapreduce.Job: Job job_1633917566916_0080 running in uber mode : false
2021-10-10 19:35:27,742 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:35:33,838 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:35:39,886 INFO mapreduce.Job: Task Id : attempt_1633917566916_0080_r_000000_0, Status : FAILED
[2021-10-10 19:35:39.230]Container [pid=14684,containerID=container_1633917566916_0080_01_000003] is running 311015936B beyond the 'VIRTUAL' memory limit. Current usage: 96.5 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0080_01_000003 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 14684 14682 14684 14684 (bash) 0 1 10162176 665 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0080/container_1633917566916_0080_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0080/container_1633917566916_0080_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.102 43331 attempt_1633917566916_0080_r_000000_0 3 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0080/container_1633917566916_0080_01_000003/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0080/container_1633917566916_0080_01_000003/stderr  
	|- 14695 14684 14684 14684 (java) 94 360 2555711488 24043 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0080/container_1633917566916_0080_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0080/container_1633917566916_0080_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.102 43331 attempt_1633917566916_0080_r_000000_0 3 

[2021-10-10 19:35:39.258]Container killed on request. Exit code is 143
[2021-10-10 19:35:39.265]Container exited with a non-zero exit code 143. 

2021-10-10 19:35:46,993 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:35:47,009 INFO mapreduce.Job: Job job_1633917566916_0080 completed successfully
2021-10-10 19:35:47,041 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=5814
		FILE: Number of bytes written=448523
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=263
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed reduce tasks=1
		Launched map tasks=1
		Launched reduce tasks=2
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3319
		Total time spent by all reduces in occupied slots (ms)=8206
		Total time spent by all map tasks (ms)=3319
		Total time spent by all reduce tasks (ms)=8206
		Total vcore-milliseconds taken by all map tasks=3319
		Total vcore-milliseconds taken by all reduce tasks=8206
		Total megabyte-milliseconds taken by all map tasks=3398656
		Total megabyte-milliseconds taken by all reduce tasks=8402944
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=5736
		Map output materialized bytes=5814
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=5814
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=135
		CPU time spent (ms)=1100
		Physical memory (bytes) snapshot=331882496
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216432640
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115449856
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=263
2021-10-10 19:35:47,055 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:35:47,069 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:35:47,089 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:35:47,121 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:35:47,134 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:35:47,138 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:35:47,144 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:35:47,155 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:35:47,160 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:35:47,198 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:35:47,209 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:35:47,213 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0081
2021-10-10 19:35:47,221 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:35:47,233 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:35:47,243 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:35:47,250 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:35:47,263 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:35:47,271 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:35:47,289 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:35:47,290 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:35:47,307 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:35:47,323 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:35:47,328 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0081
2021-10-10 19:35:47,328 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:35:47,341 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0081
2021-10-10 19:35:47,345 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0081/
2021-10-10 19:35:47,347 INFO mapreduce.Job: Running job: job_1633917566916_0081
2021-10-10 19:36:00,488 INFO mapreduce.Job: Job job_1633917566916_0081 running in uber mode : false
2021-10-10 19:36:00,491 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:36:05,567 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:36:11,618 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:36:12,652 INFO mapreduce.Job: Job job_1633917566916_0081 completed successfully
2021-10-10 19:36:12,726 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6102
		FILE: Number of bytes written=449099
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=263
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2969
		Total time spent by all reduces in occupied slots (ms)=3582
		Total time spent by all map tasks (ms)=2969
		Total time spent by all reduce tasks (ms)=3582
		Total vcore-milliseconds taken by all map tasks=2969
		Total vcore-milliseconds taken by all reduce tasks=3582
		Total megabyte-milliseconds taken by all map tasks=3040256
		Total megabyte-milliseconds taken by all reduce tasks=3667968
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=6024
		Map output materialized bytes=6102
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=6102
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=195
		CPU time spent (ms)=1190
		Physical memory (bytes) snapshot=331792384
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215818240
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115974144
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=263
2021-10-10 19:36:12,737 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:36:12,746 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:36:12,762 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:36:12,813 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:36:12,824 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:36:12,828 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0082
2021-10-10 19:36:12,836 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:36:12,928 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:36:12,939 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:36:12,954 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:36:12,966 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:36:12,977 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:36:12,998 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:36:13,003 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0082
2021-10-10 19:36:13,005 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:36:13,232 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0082
2021-10-10 19:36:13,244 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0082/
2021-10-10 19:36:13,247 INFO mapreduce.Job: Running job: job_1633917566916_0082
2021-10-10 19:36:25,367 INFO mapreduce.Job: Job job_1633917566916_0082 running in uber mode : false
2021-10-10 19:36:25,367 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:36:31,455 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:36:36,507 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:36:36,531 INFO mapreduce.Job: Job job_1633917566916_0082 completed successfully
2021-10-10 19:36:36,573 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6102
		FILE: Number of bytes written=449099
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3594
		Total time spent by all reduces in occupied slots (ms)=3212
		Total time spent by all map tasks (ms)=3594
		Total time spent by all reduce tasks (ms)=3212
		Total vcore-milliseconds taken by all map tasks=3594
		Total vcore-milliseconds taken by all reduce tasks=3212
		Total megabyte-milliseconds taken by all map tasks=3680256
		Total megabyte-milliseconds taken by all reduce tasks=3289088
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=6024
		Map output materialized bytes=6102
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=6102
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=152
		CPU time spent (ms)=1610
		Physical memory (bytes) snapshot=330203136
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215740416
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=114462720
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:36:36,590 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:36:36,596 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:36:36,619 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:36:36,661 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:36:36,671 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:36:36,674 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0083
2021-10-10 19:36:36,683 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:36:36,702 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:36:36,709 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:36:36,725 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:36:36,736 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:36:36,760 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:36:36,779 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0083
2021-10-10 19:36:36,779 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:36:36,996 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0083
2021-10-10 19:36:37,009 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0083/
2021-10-10 19:36:37,010 INFO mapreduce.Job: Running job: job_1633917566916_0083
2021-10-10 19:36:49,188 INFO mapreduce.Job: Job job_1633917566916_0083 running in uber mode : false
2021-10-10 19:36:49,188 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:36:55,239 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:37:01,277 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:37:01,308 INFO mapreduce.Job: Job job_1633917566916_0083 completed successfully
2021-10-10 19:37:01,363 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6102
		FILE: Number of bytes written=449099
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3392
		Total time spent by all reduces in occupied slots (ms)=3585
		Total time spent by all map tasks (ms)=3392
		Total time spent by all reduce tasks (ms)=3585
		Total vcore-milliseconds taken by all map tasks=3392
		Total vcore-milliseconds taken by all reduce tasks=3585
		Total megabyte-milliseconds taken by all map tasks=3473408
		Total megabyte-milliseconds taken by all reduce tasks=3671040
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=6024
		Map output materialized bytes=6102
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=6102
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=197
		CPU time spent (ms)=1620
		Physical memory (bytes) snapshot=331923456
		Virtual memory (bytes) snapshot=5163737088
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216055808
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115867648
		Peak Reduce Virtual memory (bytes)=2586308608
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:37:01,371 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:01,378 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:01,396 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:01,431 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:37:01,441 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:37:01,444 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0084
2021-10-10 19:37:01,452 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:01,470 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:37:01,478 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:01,495 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:37:01,504 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:01,518 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:37:01,520 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:37:01,542 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:01,565 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0084
2021-10-10 19:37:01,567 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:37:01,580 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0084
2021-10-10 19:37:01,584 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0084/
2021-10-10 19:37:01,585 INFO mapreduce.Job: Running job: job_1633917566916_0084
2021-10-10 19:37:13,755 INFO mapreduce.Job: Job job_1633917566916_0084 running in uber mode : false
2021-10-10 19:37:13,755 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:37:19,816 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:37:25,859 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:37:25,869 INFO mapreduce.Job: Job job_1633917566916_0084 completed successfully
2021-10-10 19:37:25,912 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6102
		FILE: Number of bytes written=449099
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=263
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3092
		Total time spent by all reduces in occupied slots (ms)=3206
		Total time spent by all map tasks (ms)=3092
		Total time spent by all reduce tasks (ms)=3206
		Total vcore-milliseconds taken by all map tasks=3092
		Total vcore-milliseconds taken by all reduce tasks=3206
		Total megabyte-milliseconds taken by all map tasks=3166208
		Total megabyte-milliseconds taken by all reduce tasks=3282944
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=6024
		Map output materialized bytes=6102
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=6102
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=140
		CPU time spent (ms)=1220
		Physical memory (bytes) snapshot=333905920
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215977984
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117927936
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=263
2021-10-10 19:37:25,920 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:25,929 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:25,949 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:25,992 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:37:26,004 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:37:26,009 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0085
2021-10-10 19:37:26,018 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:26,038 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:37:26,047 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:37:26,055 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:26,068 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:37:26,075 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:26,087 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:37:26,102 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:26,118 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:37:26,124 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0085
2021-10-10 19:37:26,124 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:37:26,140 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0085
2021-10-10 19:37:26,144 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0085/
2021-10-10 19:37:26,145 INFO mapreduce.Job: Running job: job_1633917566916_0085
2021-10-10 19:37:39,315 INFO mapreduce.Job: Job job_1633917566916_0085 running in uber mode : false
2021-10-10 19:37:39,315 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:37:44,390 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:37:52,466 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:37:52,492 INFO mapreduce.Job: Job job_1633917566916_0085 completed successfully
2021-10-10 19:37:52,572 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6102
		FILE: Number of bytes written=449099
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3600
		Total time spent by all reduces in occupied slots (ms)=5220
		Total time spent by all map tasks (ms)=3600
		Total time spent by all reduce tasks (ms)=5220
		Total vcore-milliseconds taken by all map tasks=3600
		Total vcore-milliseconds taken by all reduce tasks=5220
		Total megabyte-milliseconds taken by all map tasks=3686400
		Total megabyte-milliseconds taken by all reduce tasks=5345280
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=6024
		Map output materialized bytes=6102
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=6102
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=236
		CPU time spent (ms)=1300
		Physical memory (bytes) snapshot=333152256
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215994368
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117157888
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:37:52,579 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:52,585 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:52,598 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:37:52,618 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:52,632 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:37:52,640 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:52,649 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:52,666 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:52,700 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:37:52,714 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:37:52,718 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0086
2021-10-10 19:37:52,733 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:52,749 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:37:52,760 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:52,787 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:52,806 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:37:52,831 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:37:52,847 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0086
2021-10-10 19:37:52,847 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:37:52,866 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0086
2021-10-10 19:37:52,870 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0086/
2021-10-10 19:37:52,872 INFO mapreduce.Job: Running job: job_1633917566916_0086
2021-10-10 19:38:05,010 INFO mapreduce.Job: Job job_1633917566916_0086 running in uber mode : false
2021-10-10 19:38:05,011 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:38:10,062 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:38:19,121 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:38:19,138 INFO mapreduce.Job: Job job_1633917566916_0086 completed successfully
2021-10-10 19:38:19,185 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6414
		FILE: Number of bytes written=449723
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3085
		Total time spent by all reduces in occupied slots (ms)=5311
		Total time spent by all map tasks (ms)=3085
		Total time spent by all reduce tasks (ms)=5311
		Total vcore-milliseconds taken by all map tasks=3085
		Total vcore-milliseconds taken by all reduce tasks=5311
		Total megabyte-milliseconds taken by all map tasks=3159040
		Total megabyte-milliseconds taken by all reduce tasks=5438464
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=6312
		Map output materialized bytes=6414
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=6414
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=332
		CPU time spent (ms)=1130
		Physical memory (bytes) snapshot=331902976
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215236608
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=116666368
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:38:19,199 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:38:19,205 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:38:19,222 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:38:19,229 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:38:19,260 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:38:19,270 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:38:19,274 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0087
2021-10-10 19:38:19,282 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:38:19,300 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:38:19,309 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:38:19,329 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:38:19,341 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:38:19,359 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:38:19,373 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0087
2021-10-10 19:38:19,375 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:38:19,590 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0087
2021-10-10 19:38:19,597 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0087/
2021-10-10 19:38:19,598 INFO mapreduce.Job: Running job: job_1633917566916_0087
2021-10-10 19:38:31,771 INFO mapreduce.Job: Job job_1633917566916_0087 running in uber mode : false
2021-10-10 19:38:31,771 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:38:37,854 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:38:42,886 INFO mapreduce.Job: Task Id : attempt_1633917566916_0087_r_000000_0, Status : FAILED
[2021-10-10 19:38:41.940]Container [pid=14857,containerID=container_1633917566916_0087_01_000003] is running 304617984B beyond the 'VIRTUAL' memory limit. Current usage: 84.4 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0087_01_000003 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 14857 14855 14857 14857 (bash) 0 0 10162176 697 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0087/container_1633917566916_0087_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0087/container_1633917566916_0087_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.102 33393 attempt_1633917566916_0087_r_000000_0 3 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0087/container_1633917566916_0087_01_000003/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0087/container_1633917566916_0087_01_000003/stderr  
	|- 14868 14857 14857 14857 (java) 79 116 2549313536 20914 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0087/container_1633917566916_0087_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0087/container_1633917566916_0087_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.102 33393 attempt_1633917566916_0087_r_000000_0 3 

[2021-10-10 19:38:41.968]Container killed on request. Exit code is 143
[2021-10-10 19:38:41.971]Container exited with a non-zero exit code 143. 

2021-10-10 19:38:50,946 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:38:50,983 INFO mapreduce.Job: Job job_1633917566916_0087 completed successfully
2021-10-10 19:38:51,035 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=6414
		FILE: Number of bytes written=449723
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=263
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed reduce tasks=1
		Launched map tasks=1
		Launched reduce tasks=2
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3087
		Total time spent by all reduces in occupied slots (ms)=7571
		Total time spent by all map tasks (ms)=3087
		Total time spent by all reduce tasks (ms)=7571
		Total vcore-milliseconds taken by all map tasks=3087
		Total vcore-milliseconds taken by all reduce tasks=7571
		Total megabyte-milliseconds taken by all map tasks=3161088
		Total megabyte-milliseconds taken by all reduce tasks=7752704
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=6312
		Map output materialized bytes=6414
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=6414
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=163
		CPU time spent (ms)=1080
		Physical memory (bytes) snapshot=329015296
		Virtual memory (bytes) snapshot=5163978752
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215560192
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=113455104
		Peak Reduce Virtual memory (bytes)=2586550272
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=263
2021-10-10 19:38:51,043 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:38:51,052 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:38:51,065 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:38:51,097 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:38:51,111 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:38:51,115 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0088
2021-10-10 19:38:51,123 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:38:51,144 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:38:51,152 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:38:51,171 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:38:51,184 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:38:51,207 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:38:51,224 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0088
2021-10-10 19:38:51,225 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:38:51,238 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0088
2021-10-10 19:38:51,242 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0088/
2021-10-10 19:38:51,244 INFO mapreduce.Job: Running job: job_1633917566916_0088
2021-10-10 19:39:04,412 INFO mapreduce.Job: Job job_1633917566916_0088 running in uber mode : false
2021-10-10 19:39:04,412 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:39:09,522 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:39:15,624 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:39:15,651 INFO mapreduce.Job: Job job_1633917566916_0088 completed successfully
2021-10-10 19:39:15,720 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6414
		FILE: Number of bytes written=449723
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3214
		Total time spent by all reduces in occupied slots (ms)=3331
		Total time spent by all map tasks (ms)=3214
		Total time spent by all reduce tasks (ms)=3331
		Total vcore-milliseconds taken by all map tasks=3214
		Total vcore-milliseconds taken by all reduce tasks=3331
		Total megabyte-milliseconds taken by all map tasks=3291136
		Total megabyte-milliseconds taken by all reduce tasks=3410944
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=6312
		Map output materialized bytes=6414
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=6414
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=197
		CPU time spent (ms)=1160
		Physical memory (bytes) snapshot=324505600
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=210280448
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=114225152
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:39:15,730 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:39:15,741 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:39:15,755 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:39:15,804 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:39:15,814 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:39:15,817 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0089
2021-10-10 19:39:15,830 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:39:15,845 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:39:15,857 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:39:15,883 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:39:15,899 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:39:15,925 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:39:15,942 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0089
2021-10-10 19:39:15,943 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:39:15,955 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0089
2021-10-10 19:39:15,959 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0089/
2021-10-10 19:39:15,960 INFO mapreduce.Job: Running job: job_1633917566916_0089
2021-10-10 19:39:31,071 INFO mapreduce.Job: Job job_1633917566916_0089 running in uber mode : false
2021-10-10 19:39:31,072 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:39:36,108 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:39:42,135 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:39:42,144 INFO mapreduce.Job: Job job_1633917566916_0089 completed successfully
2021-10-10 19:39:42,179 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6414
		FILE: Number of bytes written=449723
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2909
		Total time spent by all reduces in occupied slots (ms)=3231
		Total time spent by all map tasks (ms)=2909
		Total time spent by all reduce tasks (ms)=3231
		Total vcore-milliseconds taken by all map tasks=2909
		Total vcore-milliseconds taken by all reduce tasks=3231
		Total megabyte-milliseconds taken by all map tasks=2978816
		Total megabyte-milliseconds taken by all reduce tasks=3308544
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=6312
		Map output materialized bytes=6414
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=6414
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=138
		CPU time spent (ms)=1080
		Physical memory (bytes) snapshot=330780672
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=214028288
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=116752384
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:39:42,189 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:39:42,200 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:39:42,215 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:39:42,228 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:39:42,247 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:39:42,275 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:39:42,285 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:39:42,290 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0090
2021-10-10 19:39:42,298 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:39:42,317 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:39:42,325 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:39:42,339 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:39:42,349 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:39:42,363 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:39:42,375 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:39:42,395 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:39:42,400 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0090
2021-10-10 19:39:42,400 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:39:42,414 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0090
2021-10-10 19:39:42,420 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0090/
2021-10-10 19:39:42,422 INFO mapreduce.Job: Running job: job_1633917566916_0090
2021-10-10 19:39:55,605 INFO mapreduce.Job: Job job_1633917566916_0090 running in uber mode : false
2021-10-10 19:39:55,605 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:40:00,664 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:40:06,725 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:40:06,748 INFO mapreduce.Job: Job job_1633917566916_0090 completed successfully
2021-10-10 19:40:06,809 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6414
		FILE: Number of bytes written=449723
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3025
		Total time spent by all reduces in occupied slots (ms)=3072
		Total time spent by all map tasks (ms)=3025
		Total time spent by all reduce tasks (ms)=3072
		Total vcore-milliseconds taken by all map tasks=3025
		Total vcore-milliseconds taken by all reduce tasks=3072
		Total megabyte-milliseconds taken by all map tasks=3097600
		Total megabyte-milliseconds taken by all reduce tasks=3145728
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=6312
		Map output materialized bytes=6414
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=6414
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=148
		CPU time spent (ms)=1020
		Physical memory (bytes) snapshot=333176832
		Virtual memory (bytes) snapshot=5164003328
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215396352
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117780480
		Peak Reduce Virtual memory (bytes)=2586574848
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:40:06,819 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:06,828 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:06,841 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:40:06,867 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:06,881 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:06,887 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:06,898 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:40:06,907 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:06,921 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:40:06,943 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:40:06,953 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:40:06,956 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0091
2021-10-10 19:40:06,961 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:06,973 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:40:06,979 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:40:06,986 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:06,998 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:40:07,009 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:07,024 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:40:07,027 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:40:07,047 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:07,073 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0091
2021-10-10 19:40:07,074 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:40:07,091 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0091
2021-10-10 19:40:07,095 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0091/
2021-10-10 19:40:07,097 INFO mapreduce.Job: Running job: job_1633917566916_0091
2021-10-10 19:40:19,292 INFO mapreduce.Job: Job job_1633917566916_0091 running in uber mode : false
2021-10-10 19:40:19,292 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:40:24,377 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:40:31,418 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:40:31,451 INFO mapreduce.Job: Job job_1633917566916_0091 completed successfully
2021-10-10 19:40:31,545 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6702
		FILE: Number of bytes written=450299
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2859
		Total time spent by all reduces in occupied slots (ms)=3314
		Total time spent by all map tasks (ms)=2859
		Total time spent by all reduce tasks (ms)=3314
		Total vcore-milliseconds taken by all map tasks=2859
		Total vcore-milliseconds taken by all reduce tasks=3314
		Total megabyte-milliseconds taken by all map tasks=2927616
		Total megabyte-milliseconds taken by all reduce tasks=3393536
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=6600
		Map output materialized bytes=6702
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=6702
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=147
		CPU time spent (ms)=1130
		Physical memory (bytes) snapshot=330907648
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=213401600
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117506048
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:40:31,558 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:31,574 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:31,589 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:40:31,597 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:31,637 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:40:31,653 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:40:31,657 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0092
2021-10-10 19:40:31,663 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:31,675 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:40:31,686 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:40:31,692 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:31,704 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:40:31,713 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:31,726 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.closeInternal(DataStreamer.java:847)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:843)
2021-10-10 19:40:31,726 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:40:31,745 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:31,761 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:40:31,765 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0092
2021-10-10 19:40:31,765 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:40:31,777 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0092
2021-10-10 19:40:31,781 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0092/
2021-10-10 19:40:31,782 INFO mapreduce.Job: Running job: job_1633917566916_0092
2021-10-10 19:40:43,923 INFO mapreduce.Job: Job job_1633917566916_0092 running in uber mode : false
2021-10-10 19:40:43,924 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:40:48,983 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:40:55,033 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:40:55,040 INFO mapreduce.Job: Job job_1633917566916_0092 completed successfully
2021-10-10 19:40:55,073 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6702
		FILE: Number of bytes written=450299
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=263
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3150
		Total time spent by all reduces in occupied slots (ms)=3061
		Total time spent by all map tasks (ms)=3150
		Total time spent by all reduce tasks (ms)=3061
		Total vcore-milliseconds taken by all map tasks=3150
		Total vcore-milliseconds taken by all reduce tasks=3061
		Total megabyte-milliseconds taken by all map tasks=3225600
		Total megabyte-milliseconds taken by all reduce tasks=3134464
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=6600
		Map output materialized bytes=6702
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=6702
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=137
		CPU time spent (ms)=1060
		Physical memory (bytes) snapshot=329867264
		Virtual memory (bytes) snapshot=5164003328
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=211988480
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117878784
		Peak Reduce Virtual memory (bytes)=2586574848
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=263
2021-10-10 19:40:55,080 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:55,090 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:55,103 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:40:55,110 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:55,147 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:40:55,158 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:40:55,161 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0093
2021-10-10 19:40:55,168 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:55,195 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:40:55,206 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:55,220 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:55,235 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:40:55,249 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:40:55,273 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:40:55,278 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0093
2021-10-10 19:40:55,278 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:40:55,292 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0093
2021-10-10 19:40:55,296 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0093/
2021-10-10 19:40:55,299 INFO mapreduce.Job: Running job: job_1633917566916_0093
2021-10-10 19:41:10,457 INFO mapreduce.Job: Job job_1633917566916_0093 running in uber mode : false
2021-10-10 19:41:10,457 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:41:16,543 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:41:22,609 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:41:22,634 INFO mapreduce.Job: Job job_1633917566916_0093 completed successfully
2021-10-10 19:41:22,701 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6702
		FILE: Number of bytes written=450299
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=4474
		Total time spent by all reduces in occupied slots (ms)=3374
		Total time spent by all map tasks (ms)=4474
		Total time spent by all reduce tasks (ms)=3374
		Total vcore-milliseconds taken by all map tasks=4474
		Total vcore-milliseconds taken by all reduce tasks=3374
		Total megabyte-milliseconds taken by all map tasks=4581376
		Total megabyte-milliseconds taken by all reduce tasks=3454976
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=6600
		Map output materialized bytes=6702
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=6702
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=152
		CPU time spent (ms)=1480
		Physical memory (bytes) snapshot=329408512
		Virtual memory (bytes) snapshot=5164003328
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=213938176
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115470336
		Peak Reduce Virtual memory (bytes)=2586574848
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:41:22,709 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:41:22,723 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:41:22,740 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:41:22,767 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:41:22,777 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:41:22,781 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0094
2021-10-10 19:41:22,787 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:41:22,798 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:41:22,813 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:41:22,820 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:41:22,836 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:41:22,844 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:41:22,855 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:41:22,857 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:41:22,872 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:41:22,892 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0094
2021-10-10 19:41:22,893 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:41:22,916 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0094
2021-10-10 19:41:22,920 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0094/
2021-10-10 19:41:22,921 INFO mapreduce.Job: Running job: job_1633917566916_0094
2021-10-10 19:41:36,080 INFO mapreduce.Job: Job job_1633917566916_0094 running in uber mode : false
2021-10-10 19:41:36,080 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:41:41,155 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:41:47,221 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:41:47,247 INFO mapreduce.Job: Job job_1633917566916_0094 completed successfully
2021-10-10 19:41:47,321 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6702
		FILE: Number of bytes written=450299
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3012
		Total time spent by all reduces in occupied slots (ms)=3085
		Total time spent by all map tasks (ms)=3012
		Total time spent by all reduce tasks (ms)=3085
		Total vcore-milliseconds taken by all map tasks=3012
		Total vcore-milliseconds taken by all reduce tasks=3085
		Total megabyte-milliseconds taken by all map tasks=3084288
		Total megabyte-milliseconds taken by all reduce tasks=3159040
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=6600
		Map output materialized bytes=6702
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=6702
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=143
		CPU time spent (ms)=1070
		Physical memory (bytes) snapshot=329834496
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216104960
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=113729536
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:41:47,328 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:41:47,339 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:41:47,357 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:41:47,400 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:41:47,418 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:41:47,421 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0095
2021-10-10 19:41:47,427 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:41:47,443 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:41:47,450 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:41:47,466 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:41:47,477 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:41:47,499 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:41:47,516 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0095
2021-10-10 19:41:47,516 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:41:47,528 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0095
2021-10-10 19:41:47,533 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0095/
2021-10-10 19:41:47,533 INFO mapreduce.Job: Running job: job_1633917566916_0095
2021-10-10 19:41:59,728 INFO mapreduce.Job: Job job_1633917566916_0095 running in uber mode : false
2021-10-10 19:41:59,731 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:42:04,804 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:42:10,843 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:42:10,858 INFO mapreduce.Job: Job job_1633917566916_0095 completed successfully
2021-10-10 19:42:10,915 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6702
		FILE: Number of bytes written=450299
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=261
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2915
		Total time spent by all reduces in occupied slots (ms)=3047
		Total time spent by all map tasks (ms)=2915
		Total time spent by all reduce tasks (ms)=3047
		Total vcore-milliseconds taken by all map tasks=2915
		Total vcore-milliseconds taken by all reduce tasks=3047
		Total megabyte-milliseconds taken by all map tasks=2984960
		Total megabyte-milliseconds taken by all reduce tasks=3120128
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=6600
		Map output materialized bytes=6702
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=6702
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=134
		CPU time spent (ms)=1050
		Physical memory (bytes) snapshot=329293824
		Virtual memory (bytes) snapshot=5164003328
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=213868544
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115425280
		Peak Reduce Virtual memory (bytes)=2586574848
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=261
2021-10-10 19:42:10,925 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:42:10,937 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:42:11,000 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:42:11,021 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:42:11,031 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:42:11,054 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:42:11,100 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:42:11,121 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:42:11,125 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0096
2021-10-10 19:42:11,139 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:42:11,161 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:42:11,170 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:42:11,196 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:42:11,215 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:42:11,235 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:42:11,253 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:42:11,257 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0096
2021-10-10 19:42:11,257 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:42:11,480 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0096
2021-10-10 19:42:11,490 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0096/
2021-10-10 19:42:11,490 INFO mapreduce.Job: Running job: job_1633917566916_0096
2021-10-10 19:42:24,641 INFO mapreduce.Job: Job job_1633917566916_0096 running in uber mode : false
2021-10-10 19:42:24,641 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:42:29,674 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:42:35,709 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:42:35,717 INFO mapreduce.Job: Job job_1633917566916_0096 completed successfully
2021-10-10 19:42:35,780 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6990
		FILE: Number of bytes written=450875
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3005
		Total time spent by all reduces in occupied slots (ms)=3238
		Total time spent by all map tasks (ms)=3005
		Total time spent by all reduce tasks (ms)=3238
		Total vcore-milliseconds taken by all map tasks=3005
		Total vcore-milliseconds taken by all reduce tasks=3238
		Total megabyte-milliseconds taken by all map tasks=3077120
		Total megabyte-milliseconds taken by all reduce tasks=3315712
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=6888
		Map output materialized bytes=6990
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=6990
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=132
		CPU time spent (ms)=1100
		Physical memory (bytes) snapshot=327733248
		Virtual memory (bytes) snapshot=5163868160
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=214175744
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=113557504
		Peak Reduce Virtual memory (bytes)=2586439680
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:42:35,797 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:42:35,804 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:42:35,831 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:42:35,880 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:42:35,900 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:42:35,903 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0097
2021-10-10 19:42:35,913 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:42:35,935 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:42:35,941 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:42:35,955 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:42:35,962 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:42:35,973 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.closeInternal(DataStreamer.java:847)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:843)
2021-10-10 19:42:35,974 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:42:36,000 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:42:36,025 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0097
2021-10-10 19:42:36,027 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:42:36,241 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0097
2021-10-10 19:42:36,249 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0097/
2021-10-10 19:42:36,252 INFO mapreduce.Job: Running job: job_1633917566916_0097
2021-10-10 19:42:48,445 INFO mapreduce.Job: Job job_1633917566916_0097 running in uber mode : false
2021-10-10 19:42:48,445 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:42:53,514 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:42:59,581 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:43:00,608 INFO mapreduce.Job: Job job_1633917566916_0097 completed successfully
2021-10-10 19:43:00,663 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6990
		FILE: Number of bytes written=450875
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2977
		Total time spent by all reduces in occupied slots (ms)=3109
		Total time spent by all map tasks (ms)=2977
		Total time spent by all reduce tasks (ms)=3109
		Total vcore-milliseconds taken by all map tasks=2977
		Total vcore-milliseconds taken by all reduce tasks=3109
		Total megabyte-milliseconds taken by all map tasks=3048448
		Total megabyte-milliseconds taken by all reduce tasks=3183616
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=6888
		Map output materialized bytes=6990
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=6990
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=139
		CPU time spent (ms)=1030
		Physical memory (bytes) snapshot=333918208
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215728128
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=118190080
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:43:00,670 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:43:00,676 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:43:00,697 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:43:00,816 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:43:00,834 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:43:00,839 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0098
2021-10-10 19:43:00,844 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:43:00,858 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:43:00,864 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:43:00,883 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:43:00,899 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:43:00,926 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:43:01,346 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0098
2021-10-10 19:43:01,346 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:43:01,369 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0098
2021-10-10 19:43:01,374 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0098/
2021-10-10 19:43:01,376 INFO mapreduce.Job: Running job: job_1633917566916_0098
2021-10-10 19:43:12,558 INFO mapreduce.Job: Job job_1633917566916_0098 running in uber mode : false
2021-10-10 19:43:12,558 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:43:18,638 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:43:24,671 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:43:24,713 INFO mapreduce.Job: Job job_1633917566916_0098 completed successfully
2021-10-10 19:43:24,759 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6990
		FILE: Number of bytes written=450875
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3181
		Total time spent by all reduces in occupied slots (ms)=3199
		Total time spent by all map tasks (ms)=3181
		Total time spent by all reduce tasks (ms)=3199
		Total vcore-milliseconds taken by all map tasks=3181
		Total vcore-milliseconds taken by all reduce tasks=3199
		Total megabyte-milliseconds taken by all map tasks=3257344
		Total megabyte-milliseconds taken by all reduce tasks=3275776
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=6888
		Map output materialized bytes=6990
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=6990
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=140
		CPU time spent (ms)=1080
		Physical memory (bytes) snapshot=334028800
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215867392
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=118161408
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:43:24,770 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:43:24,783 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:43:24,798 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:43:24,831 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:43:24,841 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:43:24,844 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0099
2021-10-10 19:43:24,850 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:43:24,862 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:43:24,871 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:43:24,878 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:43:24,895 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:43:24,907 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:43:24,948 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:43:24,967 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:43:24,973 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0099
2021-10-10 19:43:24,973 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:43:24,991 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0099
2021-10-10 19:43:24,995 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0099/
2021-10-10 19:43:24,997 INFO mapreduce.Job: Running job: job_1633917566916_0099
2021-10-10 19:43:40,147 INFO mapreduce.Job: Job job_1633917566916_0099 running in uber mode : false
2021-10-10 19:43:40,147 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:43:46,205 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:43:52,244 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:43:52,251 INFO mapreduce.Job: Job job_1633917566916_0099 completed successfully
2021-10-10 19:43:52,314 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6990
		FILE: Number of bytes written=450875
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=4155
		Total time spent by all reduces in occupied slots (ms)=3282
		Total time spent by all map tasks (ms)=4155
		Total time spent by all reduce tasks (ms)=3282
		Total vcore-milliseconds taken by all map tasks=4155
		Total vcore-milliseconds taken by all reduce tasks=3282
		Total megabyte-milliseconds taken by all map tasks=4254720
		Total megabyte-milliseconds taken by all reduce tasks=3360768
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=6888
		Map output materialized bytes=6990
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=6990
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=181
		CPU time spent (ms)=1900
		Physical memory (bytes) snapshot=329666560
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=214687744
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=114978816
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:43:52,321 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:43:52,330 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:43:52,347 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:43:52,360 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:43:52,384 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:43:52,396 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:43:52,400 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0100
2021-10-10 19:43:52,407 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:43:52,421 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:43:52,431 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:43:52,450 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:43:52,458 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:43:52,470 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:43:52,472 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:43:52,488 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:43:52,509 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:43:52,513 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0100
2021-10-10 19:43:52,514 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:43:52,526 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0100
2021-10-10 19:43:52,531 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0100/
2021-10-10 19:43:52,533 INFO mapreduce.Job: Running job: job_1633917566916_0100
2021-10-10 19:44:06,807 INFO mapreduce.Job: Job job_1633917566916_0100 running in uber mode : false
2021-10-10 19:44:06,807 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:44:12,894 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:44:18,935 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:44:18,959 INFO mapreduce.Job: Job job_1633917566916_0100 completed successfully
2021-10-10 19:44:19,019 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6990
		FILE: Number of bytes written=450875
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1836
		HDFS: Number of bytes written=276
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3170
		Total time spent by all reduces in occupied slots (ms)=3188
		Total time spent by all map tasks (ms)=3170
		Total time spent by all reduce tasks (ms)=3188
		Total vcore-milliseconds taken by all map tasks=3170
		Total vcore-milliseconds taken by all reduce tasks=3188
		Total megabyte-milliseconds taken by all map tasks=3246080
		Total megabyte-milliseconds taken by all reduce tasks=3264512
	Map-Reduce Framework
		Map input records=96
		Map output records=24
		Map output bytes=6888
		Map output materialized bytes=6990
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=6990
		Reduce input records=24
		Reduce output records=1
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=152
		CPU time spent (ms)=1090
		Physical memory (bytes) snapshot=331534336
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216289280
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115245056
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1728
	File Output Format Counters 
		Bytes Written=276
2021-10-10 19:44:19,025 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:44:19,040 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:44:19,074 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:44:19,090 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:44:19,113 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:44:19,123 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:44:19,126 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0101
2021-10-10 19:44:19,132 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:44:19,144 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:44:19,151 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:44:19,161 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:44:19,176 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:44:19,186 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:44:19,198 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:44:19,219 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:44:19,224 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0101
2021-10-10 19:44:19,224 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:44:19,239 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0101
2021-10-10 19:44:19,243 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0101/
2021-10-10 19:44:19,244 INFO mapreduce.Job: Running job: job_1633917566916_0101
2021-10-10 19:44:32,403 INFO mapreduce.Job: Job job_1633917566916_0101 running in uber mode : false
2021-10-10 19:44:32,407 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:44:37,484 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:44:43,542 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:44:43,567 INFO mapreduce.Job: Job job_1633917566916_0101 completed successfully
2021-10-10 19:44:43,629 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=1836
		FILE: Number of bytes written=440605
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2279
		HDFS: Number of bytes written=330
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3638
		Total time spent by all reduces in occupied slots (ms)=3197
		Total time spent by all map tasks (ms)=3638
		Total time spent by all reduce tasks (ms)=3197
		Total vcore-milliseconds taken by all map tasks=3638
		Total vcore-milliseconds taken by all reduce tasks=3197
		Total megabyte-milliseconds taken by all map tasks=3725312
		Total megabyte-milliseconds taken by all reduce tasks=3273728
	Map-Reduce Framework
		Map input records=120
		Map output records=30
		Map output bytes=1770
		Map output materialized bytes=1836
		Input split bytes=119
		Combine input records=0
		Combine output records=0
		Reduce input groups=30
		Reduce shuffle bytes=1836
		Reduce input records=30
		Reduce output records=1
		Spilled Records=60
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=164
		CPU time spent (ms)=1620
		Physical memory (bytes) snapshot=333492224
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216363008
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117129216
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2160
	File Output Format Counters 
		Bytes Written=330
2021-10-10 19:44:43,642 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:44:43,666 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:44:43,681 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:44:43,705 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:44:43,715 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:44:43,718 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0102
2021-10-10 19:44:43,729 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:44:43,749 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:44:43,758 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:44:43,768 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:44:43,779 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:44:43,792 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:44:43,792 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:44:43,806 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:44:43,825 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:44:43,829 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0102
2021-10-10 19:44:43,829 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:44:43,844 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0102
2021-10-10 19:44:43,848 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0102/
2021-10-10 19:44:43,849 INFO mapreduce.Job: Running job: job_1633917566916_0102
2021-10-10 19:44:56,087 INFO mapreduce.Job: Job job_1633917566916_0102 running in uber mode : false
2021-10-10 19:44:56,087 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:45:02,211 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:45:08,266 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:45:08,286 INFO mapreduce.Job: Job job_1633917566916_0102 completed successfully
2021-10-10 19:45:08,341 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=2196
		FILE: Number of bytes written=441325
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2279
		HDFS: Number of bytes written=330
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3098
		Total time spent by all reduces in occupied slots (ms)=3227
		Total time spent by all map tasks (ms)=3098
		Total time spent by all reduce tasks (ms)=3227
		Total vcore-milliseconds taken by all map tasks=3098
		Total vcore-milliseconds taken by all reduce tasks=3227
		Total megabyte-milliseconds taken by all map tasks=3172352
		Total megabyte-milliseconds taken by all reduce tasks=3304448
	Map-Reduce Framework
		Map input records=120
		Map output records=30
		Map output bytes=2130
		Map output materialized bytes=2196
		Input split bytes=119
		Combine input records=0
		Combine output records=0
		Reduce input groups=30
		Reduce shuffle bytes=2196
		Reduce input records=30
		Reduce output records=1
		Spilled Records=60
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=137
		CPU time spent (ms)=1050
		Physical memory (bytes) snapshot=330248192
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215748608
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=114499584
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2160
	File Output Format Counters 
		Bytes Written=330
2021-10-10 19:45:08,349 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:45:08,370 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:45:08,382 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:45:08,406 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:45:08,418 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:45:08,422 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0103
2021-10-10 19:45:08,428 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:45:08,439 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:45:08,454 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:45:08,465 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:45:08,477 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:45:08,486 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:45:08,502 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:45:08,513 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:45:08,533 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:45:08,541 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0103
2021-10-10 19:45:08,541 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:45:08,763 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0103
2021-10-10 19:45:08,768 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0103/
2021-10-10 19:45:08,768 INFO mapreduce.Job: Running job: job_1633917566916_0103
2021-10-10 19:45:20,975 INFO mapreduce.Job: Job job_1633917566916_0103 running in uber mode : false
2021-10-10 19:45:20,975 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:45:27,034 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:45:32,076 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:45:33,102 INFO mapreduce.Job: Job job_1633917566916_0103 completed successfully
2021-10-10 19:45:33,158 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=2556
		FILE: Number of bytes written=442045
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2279
		HDFS: Number of bytes written=330
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3331
		Total time spent by all reduces in occupied slots (ms)=3225
		Total time spent by all map tasks (ms)=3331
		Total time spent by all reduce tasks (ms)=3225
		Total vcore-milliseconds taken by all map tasks=3331
		Total vcore-milliseconds taken by all reduce tasks=3225
		Total megabyte-milliseconds taken by all map tasks=3410944
		Total megabyte-milliseconds taken by all reduce tasks=3302400
	Map-Reduce Framework
		Map input records=120
		Map output records=30
		Map output bytes=2490
		Map output materialized bytes=2556
		Input split bytes=119
		Combine input records=0
		Combine output records=0
		Reduce input groups=30
		Reduce shuffle bytes=2556
		Reduce input records=30
		Reduce output records=1
		Spilled Records=60
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=142
		CPU time spent (ms)=1310
		Physical memory (bytes) snapshot=329396224
		Virtual memory (bytes) snapshot=5163704320
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=213823488
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115572736
		Peak Reduce Virtual memory (bytes)=2586275840
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2160
	File Output Format Counters 
		Bytes Written=330
2021-10-10 19:45:33,165 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:45:33,186 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:45:33,202 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:45:33,235 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:45:33,246 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:45:33,249 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0104
2021-10-10 19:45:33,261 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:45:33,282 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:45:33,297 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:45:33,322 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:45:33,340 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:45:33,357 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:45:33,375 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0104
2021-10-10 19:45:33,377 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:45:33,388 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0104
2021-10-10 19:45:33,392 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0104/
2021-10-10 19:45:33,394 INFO mapreduce.Job: Running job: job_1633917566916_0104
2021-10-10 19:45:45,534 INFO mapreduce.Job: Job job_1633917566916_0104 running in uber mode : false
2021-10-10 19:45:45,536 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:45:50,595 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:45:56,656 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:45:57,707 INFO mapreduce.Job: Job job_1633917566916_0104 completed successfully
2021-10-10 19:45:57,777 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=2916
		FILE: Number of bytes written=442765
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2279
		HDFS: Number of bytes written=330
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3142
		Total time spent by all reduces in occupied slots (ms)=3561
		Total time spent by all map tasks (ms)=3142
		Total time spent by all reduce tasks (ms)=3561
		Total vcore-milliseconds taken by all map tasks=3142
		Total vcore-milliseconds taken by all reduce tasks=3561
		Total megabyte-milliseconds taken by all map tasks=3217408
		Total megabyte-milliseconds taken by all reduce tasks=3646464
	Map-Reduce Framework
		Map input records=120
		Map output records=30
		Map output bytes=2850
		Map output materialized bytes=2916
		Input split bytes=119
		Combine input records=0
		Combine output records=0
		Reduce input groups=30
		Reduce shuffle bytes=2916
		Reduce input records=30
		Reduce output records=1
		Spilled Records=60
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=201
		CPU time spent (ms)=1130
		Physical memory (bytes) snapshot=334376960
		Virtual memory (bytes) snapshot=5163876352
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216399872
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117977088
		Peak Reduce Virtual memory (bytes)=2586447872
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2160
	File Output Format Counters 
		Bytes Written=330
2021-10-10 19:45:57,793 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:45:57,832 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:45:57,846 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:45:57,868 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:45:57,877 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:45:57,880 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0105
2021-10-10 19:45:57,888 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:45:57,901 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:45:57,915 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:45:57,925 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:45:57,939 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:45:57,951 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:45:57,962 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:45:57,982 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:45:57,989 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0105
2021-10-10 19:45:57,989 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:45:58,001 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0105
2021-10-10 19:45:58,003 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0105/
2021-10-10 19:45:58,003 INFO mapreduce.Job: Running job: job_1633917566916_0105
2021-10-10 19:46:10,206 INFO mapreduce.Job: Job job_1633917566916_0105 running in uber mode : false
2021-10-10 19:46:10,206 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:46:16,267 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:46:24,315 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:46:24,350 INFO mapreduce.Job: Job job_1633917566916_0105 completed successfully
2021-10-10 19:46:24,410 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=3276
		FILE: Number of bytes written=443485
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2279
		HDFS: Number of bytes written=330
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2990
		Total time spent by all reduces in occupied slots (ms)=5373
		Total time spent by all map tasks (ms)=2990
		Total time spent by all reduce tasks (ms)=5373
		Total vcore-milliseconds taken by all map tasks=2990
		Total vcore-milliseconds taken by all reduce tasks=5373
		Total megabyte-milliseconds taken by all map tasks=3061760
		Total megabyte-milliseconds taken by all reduce tasks=5501952
	Map-Reduce Framework
		Map input records=120
		Map output records=30
		Map output bytes=3210
		Map output materialized bytes=3276
		Input split bytes=119
		Combine input records=0
		Combine output records=0
		Reduce input groups=30
		Reduce shuffle bytes=3276
		Reduce input records=30
		Reduce output records=1
		Spilled Records=60
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=211
		CPU time spent (ms)=1110
		Physical memory (bytes) snapshot=329285632
		Virtual memory (bytes) snapshot=5163999232
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=214208512
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115077120
		Peak Reduce Virtual memory (bytes)=2586570752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2160
	File Output Format Counters 
		Bytes Written=330
2021-10-10 19:46:24,430 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:46:24,461 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:46:24,495 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:46:24,506 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:46:24,510 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0106
2021-10-10 19:46:24,519 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:46:24,534 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:46:24,543 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:46:24,552 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:46:24,567 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:46:24,576 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:46:24,587 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:46:24,606 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:46:24,610 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0106
2021-10-10 19:46:24,610 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:46:24,622 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0106
2021-10-10 19:46:24,625 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0106/
2021-10-10 19:46:24,627 INFO mapreduce.Job: Running job: job_1633917566916_0106
2021-10-10 19:46:37,816 INFO mapreduce.Job: Job job_1633917566916_0106 running in uber mode : false
2021-10-10 19:46:37,816 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:46:42,890 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:46:48,929 INFO mapreduce.Job: Task Id : attempt_1633917566916_0106_r_000000_0, Status : FAILED
[2021-10-10 19:46:47.270]Container [pid=18671,containerID=container_1633917566916_0106_01_000003] is running 313113088B beyond the 'VIRTUAL' memory limit. Current usage: 100.4 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0106_01_000003 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 18671 18668 18671 18671 (bash) 0 0 10162176 696 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0106/container_1633917566916_0106_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0106/container_1633917566916_0106_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.101 36135 attempt_1633917566916_0106_r_000000_0 3 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0106/container_1633917566916_0106_01_000003/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0106/container_1633917566916_0106_01_000003/stderr  
	|- 18682 18671 18671 18671 (java) 138 155 2557808640 25012 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0106/container_1633917566916_0106_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0106/container_1633917566916_0106_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.101 36135 attempt_1633917566916_0106_r_000000_0 3 

[2021-10-10 19:46:47.302]Container killed on request. Exit code is 143
[2021-10-10 19:46:47.304]Container exited with a non-zero exit code 143. 

2021-10-10 19:46:56,020 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:46:57,054 INFO mapreduce.Job: Job job_1633917566916_0106 completed successfully
2021-10-10 19:46:57,117 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=3636
		FILE: Number of bytes written=444205
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2279
		HDFS: Number of bytes written=330
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed reduce tasks=1
		Launched map tasks=1
		Launched reduce tasks=2
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3125
		Total time spent by all reduces in occupied slots (ms)=7705
		Total time spent by all map tasks (ms)=3125
		Total time spent by all reduce tasks (ms)=7705
		Total vcore-milliseconds taken by all map tasks=3125
		Total vcore-milliseconds taken by all reduce tasks=7705
		Total megabyte-milliseconds taken by all map tasks=3200000
		Total megabyte-milliseconds taken by all reduce tasks=7889920
	Map-Reduce Framework
		Map input records=120
		Map output records=30
		Map output bytes=3570
		Map output materialized bytes=3636
		Input split bytes=119
		Combine input records=0
		Combine output records=0
		Reduce input groups=30
		Reduce shuffle bytes=3636
		Reduce input records=30
		Reduce output records=1
		Spilled Records=60
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=195
		CPU time spent (ms)=1220
		Physical memory (bytes) snapshot=327430144
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=212254720
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115175424
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2160
	File Output Format Counters 
		Bytes Written=330
2021-10-10 19:46:57,124 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:46:57,146 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:46:57,159 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:46:57,187 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:46:57,197 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:46:57,200 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0107
2021-10-10 19:46:57,208 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:46:57,220 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:46:57,229 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:46:57,236 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:46:57,249 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:46:57,256 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:46:57,267 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:46:57,268 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:46:57,280 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:46:57,304 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0107
2021-10-10 19:46:57,304 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:46:57,326 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0107
2021-10-10 19:46:57,330 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0107/
2021-10-10 19:46:57,331 INFO mapreduce.Job: Running job: job_1633917566916_0107
2021-10-10 19:47:09,457 INFO mapreduce.Job: Job job_1633917566916_0107 running in uber mode : false
2021-10-10 19:47:09,460 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:47:15,546 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:47:20,591 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:47:21,610 INFO mapreduce.Job: Job job_1633917566916_0107 completed successfully
2021-10-10 19:47:21,644 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=3996
		FILE: Number of bytes written=444925
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2279
		HDFS: Number of bytes written=330
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3639
		Total time spent by all reduces in occupied slots (ms)=3220
		Total time spent by all map tasks (ms)=3639
		Total time spent by all reduce tasks (ms)=3220
		Total vcore-milliseconds taken by all map tasks=3639
		Total vcore-milliseconds taken by all reduce tasks=3220
		Total megabyte-milliseconds taken by all map tasks=3726336
		Total megabyte-milliseconds taken by all reduce tasks=3297280
	Map-Reduce Framework
		Map input records=120
		Map output records=30
		Map output bytes=3930
		Map output materialized bytes=3996
		Input split bytes=119
		Combine input records=0
		Combine output records=0
		Reduce input groups=30
		Reduce shuffle bytes=3996
		Reduce input records=30
		Reduce output records=1
		Spilled Records=60
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=141
		CPU time spent (ms)=1780
		Physical memory (bytes) snapshot=332365824
		Virtual memory (bytes) snapshot=5164007424
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=214536192
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117829632
		Peak Reduce Virtual memory (bytes)=2586578944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2160
	File Output Format Counters 
		Bytes Written=330
2021-10-10 19:47:21,652 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:47:21,677 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:47:21,689 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:47:21,714 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:47:21,725 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:47:21,733 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0108
2021-10-10 19:47:21,754 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:47:21,769 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:47:21,774 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:47:21,787 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:47:21,802 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:47:21,813 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:47:21,830 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:47:21,833 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0108
2021-10-10 19:47:21,833 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:47:21,847 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0108
2021-10-10 19:47:21,850 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0108/
2021-10-10 19:47:21,850 INFO mapreduce.Job: Running job: job_1633917566916_0108
2021-10-10 19:47:35,053 INFO mapreduce.Job: Job job_1633917566916_0108 running in uber mode : false
2021-10-10 19:47:35,053 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:47:41,164 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:47:48,218 INFO mapreduce.Job: Task Id : attempt_1633917566916_0108_r_000000_0, Status : FAILED
[2021-10-10 19:47:47.284]Container [pid=18208,containerID=container_1633917566916_0108_01_000003] is running 326945280B beyond the 'VIRTUAL' memory limit. Current usage: 104.4 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0108_01_000003 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 18208 18206 18208 18208 (bash) 0 1 10162176 667 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0108/container_1633917566916_0108_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0108/container_1633917566916_0108_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.100 44693 attempt_1633917566916_0108_r_000000_0 3 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0108/container_1633917566916_0108_01_000003/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0108/container_1633917566916_0108_01_000003/stderr  
	|- 18219 18208 18208 18208 (java) 166 328 2571640832 26071 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0108/container_1633917566916_0108_01_000003/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0108/container_1633917566916_0108_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Dyarn.app.mapreduce.shuffle.logger=INFO,shuffleCLA -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle -Dyarn.app.mapreduce.shuffle.log.filesize=0 -Dyarn.app.mapreduce.shuffle.log.backups=0 org.apache.hadoop.mapred.YarnChild 192.168.10.100 44693 attempt_1633917566916_0108_r_000000_0 3 

[2021-10-10 19:47:47.302]Container killed on request. Exit code is 143
[2021-10-10 19:47:47.321]Container exited with a non-zero exit code 143. 

2021-10-10 19:47:56,277 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:47:56,296 INFO mapreduce.Job: Job job_1633917566916_0108 completed successfully
2021-10-10 19:47:56,369 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=4386
		FILE: Number of bytes written=445705
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2279
		HDFS: Number of bytes written=315
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed reduce tasks=1
		Launched map tasks=1
		Launched reduce tasks=2
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3191
		Total time spent by all reduces in occupied slots (ms)=9318
		Total time spent by all map tasks (ms)=3191
		Total time spent by all reduce tasks (ms)=9318
		Total vcore-milliseconds taken by all map tasks=3191
		Total vcore-milliseconds taken by all reduce tasks=9318
		Total megabyte-milliseconds taken by all map tasks=3267584
		Total megabyte-milliseconds taken by all reduce tasks=9541632
	Map-Reduce Framework
		Map input records=120
		Map output records=30
		Map output bytes=4290
		Map output materialized bytes=4386
		Input split bytes=119
		Combine input records=0
		Combine output records=0
		Reduce input groups=30
		Reduce shuffle bytes=4386
		Reduce input records=30
		Reduce output records=1
		Spilled Records=60
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=183
		CPU time spent (ms)=1340
		Physical memory (bytes) snapshot=332169216
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=214007808
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=118161408
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2160
	File Output Format Counters 
		Bytes Written=315
2021-10-10 19:47:56,388 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:47:56,437 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:47:56,459 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:47:56,500 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:47:56,514 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:47:56,518 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0109
2021-10-10 19:47:56,525 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:47:56,538 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:47:56,547 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:47:56,556 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:47:56,568 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:47:56,576 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:47:56,587 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:47:56,594 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:47:56,605 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:47:56,628 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:47:56,633 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0109
2021-10-10 19:47:56,633 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:47:56,653 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0109
2021-10-10 19:47:56,658 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0109/
2021-10-10 19:47:56,660 INFO mapreduce.Job: Running job: job_1633917566916_0109
2021-10-10 19:48:09,787 INFO mapreduce.Job: Job job_1633917566916_0109 running in uber mode : false
2021-10-10 19:48:09,788 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:48:14,853 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:48:20,906 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:48:20,916 INFO mapreduce.Job: Job job_1633917566916_0109 completed successfully
2021-10-10 19:48:20,964 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=4746
		FILE: Number of bytes written=446425
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2279
		HDFS: Number of bytes written=315
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3277
		Total time spent by all reduces in occupied slots (ms)=3106
		Total time spent by all map tasks (ms)=3277
		Total time spent by all reduce tasks (ms)=3106
		Total vcore-milliseconds taken by all map tasks=3277
		Total vcore-milliseconds taken by all reduce tasks=3106
		Total megabyte-milliseconds taken by all map tasks=3355648
		Total megabyte-milliseconds taken by all reduce tasks=3180544
	Map-Reduce Framework
		Map input records=120
		Map output records=30
		Map output bytes=4650
		Map output materialized bytes=4746
		Input split bytes=119
		Combine input records=0
		Combine output records=0
		Reduce input groups=30
		Reduce shuffle bytes=4746
		Reduce input records=30
		Reduce output records=1
		Spilled Records=60
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=135
		CPU time spent (ms)=1020
		Physical memory (bytes) snapshot=332951552
		Virtual memory (bytes) snapshot=5164003328
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215457792
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117493760
		Peak Reduce Virtual memory (bytes)=2586574848
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2160
	File Output Format Counters 
		Bytes Written=315
2021-10-10 19:48:20,974 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:48:20,994 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:48:21,023 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:48:21,033 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:48:21,037 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0110
2021-10-10 19:48:21,051 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:48:21,080 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:48:21,091 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:48:21,105 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:48:21,114 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:48:21,134 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:48:21,134 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:48:21,148 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:48:21,163 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:48:21,167 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0110
2021-10-10 19:48:21,167 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:48:21,178 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0110
2021-10-10 19:48:21,181 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0110/
2021-10-10 19:48:21,182 INFO mapreduce.Job: Running job: job_1633917566916_0110
2021-10-10 19:48:33,346 INFO mapreduce.Job: Job job_1633917566916_0110 running in uber mode : false
2021-10-10 19:48:33,346 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:48:39,414 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:48:45,470 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:48:45,498 INFO mapreduce.Job: Job job_1633917566916_0110 completed successfully
2021-10-10 19:48:45,566 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=5106
		FILE: Number of bytes written=447145
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2279
		HDFS: Number of bytes written=330
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3189
		Total time spent by all reduces in occupied slots (ms)=3295
		Total time spent by all map tasks (ms)=3189
		Total time spent by all reduce tasks (ms)=3295
		Total vcore-milliseconds taken by all map tasks=3189
		Total vcore-milliseconds taken by all reduce tasks=3295
		Total megabyte-milliseconds taken by all map tasks=3265536
		Total megabyte-milliseconds taken by all reduce tasks=3374080
	Map-Reduce Framework
		Map input records=120
		Map output records=30
		Map output bytes=5010
		Map output materialized bytes=5106
		Input split bytes=119
		Combine input records=0
		Combine output records=0
		Reduce input groups=30
		Reduce shuffle bytes=5106
		Reduce input records=30
		Reduce output records=1
		Spilled Records=60
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=135
		CPU time spent (ms)=1270
		Physical memory (bytes) snapshot=333099008
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=214700032
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=118398976
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2160
	File Output Format Counters 
		Bytes Written=330
2021-10-10 19:48:45,575 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:48:45,614 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:48:45,651 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:48:45,660 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:48:45,663 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0111
2021-10-10 19:48:45,671 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:48:45,686 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:48:45,691 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:48:45,708 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:48:45,714 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:48:45,727 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:48:45,728 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:48:45,739 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:48:45,754 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:48:45,759 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0111
2021-10-10 19:48:45,759 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:48:45,772 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0111
2021-10-10 19:48:45,777 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0111/
2021-10-10 19:48:45,779 INFO mapreduce.Job: Running job: job_1633917566916_0111
2021-10-10 19:48:57,965 INFO mapreduce.Job: Job job_1633917566916_0111 running in uber mode : false
2021-10-10 19:48:57,966 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:49:04,065 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:49:10,116 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:49:11,128 INFO mapreduce.Job: Job job_1633917566916_0111 completed successfully
2021-10-10 19:49:11,170 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=5466
		FILE: Number of bytes written=447865
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2279
		HDFS: Number of bytes written=315
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3426
		Total time spent by all reduces in occupied slots (ms)=3203
		Total time spent by all map tasks (ms)=3426
		Total time spent by all reduce tasks (ms)=3203
		Total vcore-milliseconds taken by all map tasks=3426
		Total vcore-milliseconds taken by all reduce tasks=3203
		Total megabyte-milliseconds taken by all map tasks=3508224
		Total megabyte-milliseconds taken by all reduce tasks=3279872
	Map-Reduce Framework
		Map input records=120
		Map output records=30
		Map output bytes=5370
		Map output materialized bytes=5466
		Input split bytes=119
		Combine input records=0
		Combine output records=0
		Reduce input groups=30
		Reduce shuffle bytes=5466
		Reduce input records=30
		Reduce output records=1
		Spilled Records=60
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=122
		CPU time spent (ms)=1240
		Physical memory (bytes) snapshot=330256384
		Virtual memory (bytes) snapshot=5164003328
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=216104960
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=114151424
		Peak Reduce Virtual memory (bytes)=2586574848
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2160
	File Output Format Counters 
		Bytes Written=315
2021-10-10 19:49:11,185 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:49:11,273 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:49:11,326 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:49:11,344 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:49:11,348 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0112
2021-10-10 19:49:11,370 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:49:11,407 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:49:11,415 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:49:11,446 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:49:11,462 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:49:11,481 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:49:11,536 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0112
2021-10-10 19:49:11,536 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:49:11,548 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0112
2021-10-10 19:49:11,556 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0112/
2021-10-10 19:49:11,560 INFO mapreduce.Job: Running job: job_1633917566916_0112
2021-10-10 19:49:24,705 INFO mapreduce.Job: Job job_1633917566916_0112 running in uber mode : false
2021-10-10 19:49:24,705 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:49:29,769 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:49:35,815 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:49:35,823 INFO mapreduce.Job: Job job_1633917566916_0112 completed successfully
2021-10-10 19:49:35,883 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=5826
		FILE: Number of bytes written=448585
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2279
		HDFS: Number of bytes written=315
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3170
		Total time spent by all reduces in occupied slots (ms)=3209
		Total time spent by all map tasks (ms)=3170
		Total time spent by all reduce tasks (ms)=3209
		Total vcore-milliseconds taken by all map tasks=3170
		Total vcore-milliseconds taken by all reduce tasks=3209
		Total megabyte-milliseconds taken by all map tasks=3246080
		Total megabyte-milliseconds taken by all reduce tasks=3286016
	Map-Reduce Framework
		Map input records=120
		Map output records=30
		Map output bytes=5730
		Map output materialized bytes=5826
		Input split bytes=119
		Combine input records=0
		Combine output records=0
		Reduce input groups=30
		Reduce shuffle bytes=5826
		Reduce input records=30
		Reduce output records=1
		Spilled Records=60
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=136
		CPU time spent (ms)=1060
		Physical memory (bytes) snapshot=328708096
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=213733376
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=114974720
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2160
	File Output Format Counters 
		Bytes Written=315
2021-10-10 19:49:35,889 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:49:35,910 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:49:35,921 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:49:35,949 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:49:35,959 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:49:35,962 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0113
2021-10-10 19:49:35,967 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:49:35,981 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:49:35,987 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:49:35,993 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:49:36,008 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:49:36,032 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:49:36,036 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:49:36,051 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:49:36,076 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0113
2021-10-10 19:49:36,077 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:49:36,092 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0113
2021-10-10 19:49:36,095 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0113/
2021-10-10 19:49:36,097 INFO mapreduce.Job: Running job: job_1633917566916_0113
2021-10-10 19:49:50,242 INFO mapreduce.Job: Job job_1633917566916_0113 running in uber mode : false
2021-10-10 19:49:50,242 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:49:55,301 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:50:01,379 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:50:01,413 INFO mapreduce.Job: Job job_1633917566916_0113 completed successfully
2021-10-10 19:50:01,503 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6186
		FILE: Number of bytes written=449305
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2279
		HDFS: Number of bytes written=315
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2970
		Total time spent by all reduces in occupied slots (ms)=3076
		Total time spent by all map tasks (ms)=2970
		Total time spent by all reduce tasks (ms)=3076
		Total vcore-milliseconds taken by all map tasks=2970
		Total vcore-milliseconds taken by all reduce tasks=3076
		Total megabyte-milliseconds taken by all map tasks=3041280
		Total megabyte-milliseconds taken by all reduce tasks=3149824
	Map-Reduce Framework
		Map input records=120
		Map output records=30
		Map output bytes=6090
		Map output materialized bytes=6186
		Input split bytes=119
		Combine input records=0
		Combine output records=0
		Reduce input groups=30
		Reduce shuffle bytes=6186
		Reduce input records=30
		Reduce output records=1
		Spilled Records=60
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=132
		CPU time spent (ms)=980
		Physical memory (bytes) snapshot=329605120
		Virtual memory (bytes) snapshot=5163843584
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=213635072
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115970048
		Peak Reduce Virtual memory (bytes)=2586415104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2160
	File Output Format Counters 
		Bytes Written=315
2021-10-10 19:50:01,514 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:50:01,545 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:50:01,558 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:50:01,583 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:50:01,592 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:50:01,595 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0114
2021-10-10 19:50:01,601 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:50:01,618 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:50:01,625 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:50:01,635 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:50:01,646 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:50:01,655 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:50:01,672 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:50:01,687 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:50:01,702 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:50:01,707 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0114
2021-10-10 19:50:01,707 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:50:01,718 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0114
2021-10-10 19:50:01,721 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0114/
2021-10-10 19:50:01,723 INFO mapreduce.Job: Running job: job_1633917566916_0114
2021-10-10 19:50:13,886 INFO mapreduce.Job: Job job_1633917566916_0114 running in uber mode : false
2021-10-10 19:50:13,886 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:50:20,007 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:50:26,057 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:50:26,080 INFO mapreduce.Job: Job job_1633917566916_0114 completed successfully
2021-10-10 19:50:26,130 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6546
		FILE: Number of bytes written=450025
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2279
		HDFS: Number of bytes written=315
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2964
		Total time spent by all reduces in occupied slots (ms)=3187
		Total time spent by all map tasks (ms)=2964
		Total time spent by all reduce tasks (ms)=3187
		Total vcore-milliseconds taken by all map tasks=2964
		Total vcore-milliseconds taken by all reduce tasks=3187
		Total megabyte-milliseconds taken by all map tasks=3035136
		Total megabyte-milliseconds taken by all reduce tasks=3263488
	Map-Reduce Framework
		Map input records=120
		Map output records=30
		Map output bytes=6450
		Map output materialized bytes=6546
		Input split bytes=119
		Combine input records=0
		Combine output records=0
		Reduce input groups=30
		Reduce shuffle bytes=6546
		Reduce input records=30
		Reduce output records=1
		Spilled Records=60
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=138
		CPU time spent (ms)=1060
		Physical memory (bytes) snapshot=329777152
		Virtual memory (bytes) snapshot=5163859968
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=214781952
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=114995200
		Peak Reduce Virtual memory (bytes)=2586431488
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2160
	File Output Format Counters 
		Bytes Written=315
2021-10-10 19:50:26,141 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:50:26,161 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:50:26,173 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:50:26,197 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:50:26,207 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:50:26,210 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0115
2021-10-10 19:50:26,216 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:50:26,227 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:50:26,236 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:50:26,243 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:50:26,255 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:50:26,262 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:50:26,280 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:50:26,294 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:50:26,309 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:50:26,314 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0115
2021-10-10 19:50:26,314 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:50:26,326 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0115
2021-10-10 19:50:26,330 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0115/
2021-10-10 19:50:26,331 INFO mapreduce.Job: Running job: job_1633917566916_0115
2021-10-10 19:50:38,498 INFO mapreduce.Job: Job job_1633917566916_0115 running in uber mode : false
2021-10-10 19:50:38,498 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:50:43,569 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:50:50,646 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:50:50,658 INFO mapreduce.Job: Job job_1633917566916_0115 completed successfully
2021-10-10 19:50:50,709 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6906
		FILE: Number of bytes written=450745
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2279
		HDFS: Number of bytes written=315
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2937
		Total time spent by all reduces in occupied slots (ms)=3599
		Total time spent by all map tasks (ms)=2937
		Total time spent by all reduce tasks (ms)=3599
		Total vcore-milliseconds taken by all map tasks=2937
		Total vcore-milliseconds taken by all reduce tasks=3599
		Total megabyte-milliseconds taken by all map tasks=3007488
		Total megabyte-milliseconds taken by all reduce tasks=3685376
	Map-Reduce Framework
		Map input records=120
		Map output records=30
		Map output bytes=6810
		Map output materialized bytes=6906
		Input split bytes=119
		Combine input records=0
		Combine output records=0
		Reduce input groups=30
		Reduce shuffle bytes=6906
		Reduce input records=30
		Reduce output records=1
		Spilled Records=60
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=132
		CPU time spent (ms)=1110
		Physical memory (bytes) snapshot=331079680
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215810048
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115269632
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2160
	File Output Format Counters 
		Bytes Written=315
2021-10-10 19:50:50,715 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:50:50,736 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:50:50,750 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:50:50,772 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:50:50,784 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:50:50,788 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0116
2021-10-10 19:50:50,796 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:50:50,807 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:50:50,817 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:50:50,830 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:50:50,843 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:50:50,854 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:50:50,865 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:50:50,868 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:50:50,880 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:50:50,899 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:50:50,903 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0116
2021-10-10 19:50:50,903 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:50:50,920 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0116
2021-10-10 19:50:50,924 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0116/
2021-10-10 19:50:50,926 INFO mapreduce.Job: Running job: job_1633917566916_0116
2021-10-10 19:51:09,072 INFO mapreduce.Job: Job job_1633917566916_0116 running in uber mode : false
2021-10-10 19:51:09,072 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:51:14,130 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:51:21,184 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:51:21,200 INFO mapreduce.Job: Job job_1633917566916_0116 completed successfully
2021-10-10 19:51:21,267 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=7266
		FILE: Number of bytes written=451465
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2279
		HDFS: Number of bytes written=315
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2977
		Total time spent by all reduces in occupied slots (ms)=3304
		Total time spent by all map tasks (ms)=2977
		Total time spent by all reduce tasks (ms)=3304
		Total vcore-milliseconds taken by all map tasks=2977
		Total vcore-milliseconds taken by all reduce tasks=3304
		Total megabyte-milliseconds taken by all map tasks=3048448
		Total megabyte-milliseconds taken by all reduce tasks=3383296
	Map-Reduce Framework
		Map input records=120
		Map output records=30
		Map output bytes=7170
		Map output materialized bytes=7266
		Input split bytes=119
		Combine input records=0
		Combine output records=0
		Reduce input groups=30
		Reduce shuffle bytes=7266
		Reduce input records=30
		Reduce output records=1
		Spilled Records=60
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=137
		CPU time spent (ms)=990
		Physical memory (bytes) snapshot=329973760
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=214982656
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=114991104
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2160
	File Output Format Counters 
		Bytes Written=315
2021-10-10 19:51:21,281 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:51:21,304 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:51:21,320 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:51:21,351 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:51:21,360 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:51:21,364 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0117
2021-10-10 19:51:21,381 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:51:21,397 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:51:21,403 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:51:21,415 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:51:21,424 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:51:21,442 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:51:21,455 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:51:21,470 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:51:21,475 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0117
2021-10-10 19:51:21,475 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:51:21,695 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0117
2021-10-10 19:51:21,705 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0117/
2021-10-10 19:51:21,705 INFO mapreduce.Job: Running job: job_1633917566916_0117
2021-10-10 19:51:33,811 INFO mapreduce.Job: Job job_1633917566916_0117 running in uber mode : false
2021-10-10 19:51:33,811 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:51:40,930 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:51:46,973 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:51:46,998 INFO mapreduce.Job: Job job_1633917566916_0117 completed successfully
2021-10-10 19:51:47,049 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=7626
		FILE: Number of bytes written=452185
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2279
		HDFS: Number of bytes written=315
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=4294
		Total time spent by all reduces in occupied slots (ms)=3587
		Total time spent by all map tasks (ms)=4294
		Total time spent by all reduce tasks (ms)=3587
		Total vcore-milliseconds taken by all map tasks=4294
		Total vcore-milliseconds taken by all reduce tasks=3587
		Total megabyte-milliseconds taken by all map tasks=4397056
		Total megabyte-milliseconds taken by all reduce tasks=3673088
	Map-Reduce Framework
		Map input records=120
		Map output records=30
		Map output bytes=7530
		Map output materialized bytes=7626
		Input split bytes=119
		Combine input records=0
		Combine output records=0
		Reduce input groups=30
		Reduce shuffle bytes=7626
		Reduce input records=30
		Reduce output records=1
		Spilled Records=60
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=235
		CPU time spent (ms)=1540
		Physical memory (bytes) snapshot=330211328
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215089152
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115122176
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2160
	File Output Format Counters 
		Bytes Written=315
2021-10-10 19:51:47,075 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:51:47,113 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:51:47,179 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:51:47,199 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:51:47,202 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0118
2021-10-10 19:51:47,212 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:51:47,232 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:51:47,241 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:51:47,257 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:51:47,271 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:51:47,275 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:51:47,292 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:51:47,308 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:51:47,313 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0118
2021-10-10 19:51:47,315 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:51:47,336 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0118
2021-10-10 19:51:47,341 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0118/
2021-10-10 19:51:47,342 INFO mapreduce.Job: Running job: job_1633917566916_0118
2021-10-10 19:51:58,527 INFO mapreduce.Job: Job job_1633917566916_0118 running in uber mode : false
2021-10-10 19:51:58,527 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:52:04,666 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:52:10,707 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:52:10,731 INFO mapreduce.Job: Job job_1633917566916_0118 completed successfully
2021-10-10 19:52:10,801 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=8016
		FILE: Number of bytes written=452965
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2279
		HDFS: Number of bytes written=315
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3061
		Total time spent by all reduces in occupied slots (ms)=3138
		Total time spent by all map tasks (ms)=3061
		Total time spent by all reduce tasks (ms)=3138
		Total vcore-milliseconds taken by all map tasks=3061
		Total vcore-milliseconds taken by all reduce tasks=3138
		Total megabyte-milliseconds taken by all map tasks=3134464
		Total megabyte-milliseconds taken by all reduce tasks=3213312
	Map-Reduce Framework
		Map input records=120
		Map output records=30
		Map output bytes=7890
		Map output materialized bytes=8016
		Input split bytes=119
		Combine input records=0
		Combine output records=0
		Reduce input groups=30
		Reduce shuffle bytes=8016
		Reduce input records=30
		Reduce output records=1
		Spilled Records=60
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=154
		CPU time spent (ms)=1060
		Physical memory (bytes) snapshot=330047488
		Virtual memory (bytes) snapshot=5163999232
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=214953984
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115093504
		Peak Reduce Virtual memory (bytes)=2586570752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2160
	File Output Format Counters 
		Bytes Written=315
2021-10-10 19:52:10,813 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:52:10,834 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:52:10,868 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:52:10,879 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:52:10,882 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0119
2021-10-10 19:52:10,890 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:52:10,902 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:52:10,912 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:52:10,919 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:52:10,932 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:52:10,940 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:52:10,951 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:52:10,953 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:52:10,965 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:52:10,985 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0119
2021-10-10 19:52:10,986 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:52:11,200 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0119
2021-10-10 19:52:11,209 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0119/
2021-10-10 19:52:11,213 INFO mapreduce.Job: Running job: job_1633917566916_0119
2021-10-10 19:52:24,383 INFO mapreduce.Job: Job job_1633917566916_0119 running in uber mode : false
2021-10-10 19:52:24,383 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:52:31,460 INFO mapreduce.Job: Task Id : attempt_1633917566916_0119_m_000000_0, Status : FAILED
[2021-10-10 19:52:30.408]Container [pid=20224,containerID=container_1633917566916_0119_01_000002] is running 319420928B beyond the 'VIRTUAL' memory limit. Current usage: 202.5 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1633917566916_0119_01_000002 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 20236 20224 20224 20224 (java) 144 288 2564116480 51136 /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0119/container_1633917566916_0119_01_000002/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0119/container_1633917566916_0119_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.10.101 35623 attempt_1633917566916_0119_m_000000_0 2 
	|- 20224 20222 20224 20224 (bash) 0 0 10162176 693 /bin/bash -c /opt/module/jdk1.8.0_212/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/module/hadoop-3.1.3/data/nm-local-dir/usercache/cong/appcache/application_1633917566916_0119/container_1633917566916_0119_01_000002/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0119/container_1633917566916_0119_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.10.101 35623 attempt_1633917566916_0119_m_000000_0 2 1>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0119/container_1633917566916_0119_01_000002/stdout 2>/opt/module/hadoop-3.1.3/logs/userlogs/application_1633917566916_0119/container_1633917566916_0119_01_000002/stderr  

[2021-10-10 19:52:30.493]Container killed on request. Exit code is 143
[2021-10-10 19:52:30.510]Container exited with a non-zero exit code 143. 

2021-10-10 19:52:37,538 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:52:43,578 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:52:43,585 INFO mapreduce.Job: Job job_1633917566916_0119 completed successfully
2021-10-10 19:52:43,621 INFO mapreduce.Job: Counters: 55
	File System Counters
		FILE: Number of bytes read=8376
		FILE: Number of bytes written=453685
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2279
		HDFS: Number of bytes written=315
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed map tasks=1
		Launched map tasks=2
		Launched reduce tasks=1
		Other local map tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=8737
		Total time spent by all reduces in occupied slots (ms)=3172
		Total time spent by all map tasks (ms)=8737
		Total time spent by all reduce tasks (ms)=3172
		Total vcore-milliseconds taken by all map tasks=8737
		Total vcore-milliseconds taken by all reduce tasks=3172
		Total megabyte-milliseconds taken by all map tasks=8946688
		Total megabyte-milliseconds taken by all reduce tasks=3248128
	Map-Reduce Framework
		Map input records=120
		Map output records=30
		Map output bytes=8250
		Map output materialized bytes=8376
		Input split bytes=119
		Combine input records=0
		Combine output records=0
		Reduce input groups=30
		Reduce shuffle bytes=8376
		Reduce input records=30
		Reduce output records=1
		Spilled Records=60
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=146
		CPU time spent (ms)=1110
		Physical memory (bytes) snapshot=332922880
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=215552000
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=117370880
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2160
	File Output Format Counters 
		Bytes Written=315
2021-10-10 19:52:43,633 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:52:43,657 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:52:43,669 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:52:43,700 INFO client.RMProxy: Connecting to ResourceManager at hadoop101/192.168.10.101:8032
2021-10-10 19:52:43,710 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-10-10 19:52:43,713 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/cong/.staging/job_1633917566916_0120
2021-10-10 19:52:43,722 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:52:43,736 INFO input.FileInputFormat: Total input files to process : 1
2021-10-10 19:52:43,743 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:52:44,164 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:52:44,186 INFO mapreduce.JobSubmitter: number of splits:1
2021-10-10 19:52:44,205 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-10-10 19:52:44,281 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2021-10-10 19:52:44,288 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633917566916_0120
2021-10-10 19:52:44,288 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-10-10 19:52:44,504 INFO impl.YarnClientImpl: Submitted application application_1633917566916_0120
2021-10-10 19:52:44,511 INFO mapreduce.Job: The url to track the job: http://hadoop101:8088/proxy/application_1633917566916_0120/
2021-10-10 19:52:44,512 INFO mapreduce.Job: Running job: job_1633917566916_0120
2021-10-10 19:52:56,679 INFO mapreduce.Job: Job job_1633917566916_0120 running in uber mode : false
2021-10-10 19:52:56,679 INFO mapreduce.Job:  map 0% reduce 0%
2021-10-10 19:53:02,742 INFO mapreduce.Job:  map 100% reduce 0%
2021-10-10 19:53:08,797 INFO mapreduce.Job:  map 100% reduce 100%
2021-10-10 19:53:09,827 INFO mapreduce.Job: Job job_1633917566916_0120 completed successfully
2021-10-10 19:53:09,903 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=8736
		FILE: Number of bytes written=454405
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2279
		HDFS: Number of bytes written=315
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3829
		Total time spent by all reduces in occupied slots (ms)=3097
		Total time spent by all map tasks (ms)=3829
		Total time spent by all reduce tasks (ms)=3097
		Total vcore-milliseconds taken by all map tasks=3829
		Total vcore-milliseconds taken by all reduce tasks=3097
		Total megabyte-milliseconds taken by all map tasks=3920896
		Total megabyte-milliseconds taken by all reduce tasks=3171328
	Map-Reduce Framework
		Map input records=120
		Map output records=30
		Map output bytes=8610
		Map output materialized bytes=8736
		Input split bytes=119
		Combine input records=0
		Combine output records=0
		Reduce input groups=30
		Reduce shuffle bytes=8736
		Reduce input records=30
		Reduce output records=1
		Spilled Records=60
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=189
		CPU time spent (ms)=1250
		Physical memory (bytes) snapshot=330211328
		Virtual memory (bytes) snapshot=5163847680
		Total committed heap usage (bytes)=170004480
		Peak Map Physical memory (bytes)=214650880
		Peak Map Virtual memory (bytes)=2577428480
		Peak Reduce Physical memory (bytes)=115560448
		Peak Reduce Virtual memory (bytes)=2586419200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2160
	File Output Format Counters 
		Bytes Written=315
2021-10-10 19:53:09,919 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
{
  "config": {
    "K": 20,
    "dsInfo": {
      "datasetName": "iris",
      "trainingFile": "/demo/data/iris/iris_training.csv",
      "testingFile": "/demo/data/iris/iris_test.csv"
    },
    "rsInfo": {
      "resampleMethod": "cv",
      "resampleParams": [
        "5"
      ]
    }
  },
  "tuningResults": [
    {
      "K": 1,
      "acc": 0.9583333333333334
    },
    {
      "K": 2,
      "acc": 0.9416666666666668
    },
    {
      "K": 3,
      "acc": 0.9666666666666668
    },
    {
      "K": 4,
      "acc": 0.9166666666666666
    },
    {
      "K": 5,
      "acc": 0.95
    },
    {
      "K": 6,
      "acc": 0.9416666666666668
    },
    {
      "K": 7,
      "acc": 0.975
    },
    {
      "K": 8,
      "acc": 0.95
    },
    {
      "K": 9,
      "acc": 0.975
    },
    {
      "K": 10,
      "acc": 0.9416666666666667
    },
    {
      "K": 11,
      "acc": 0.9583333333333333
    },
    {
      "K": 12,
      "acc": 0.9666666666666666
    },
    {
      "K": 13,
      "acc": 0.9416666666666667
    },
    {
      "K": 14,
      "acc": 0.95
    },
    {
      "K": 15,
      "acc": 0.9416666666666668
    },
    {
      "K": 16,
      "acc": 0.95
    },
    {
      "K": 17,
      "acc": 0.9416666666666667
    },
    {
      "K": 18,
      "acc": 0.95
    },
    {
      "K": 19,
      "acc": 0.95
    },
    {
      "K": 20,
      "acc": 0.9416666666666667
    }
  ],
  "testingResults": [
    {
      "K": 1,
      "acc": 0.9333333333333333
    },
    {
      "K": 2,
      "acc": 0.9333333333333333
    },
    {
      "K": 3,
      "acc": 0.9666666666666667
    },
    {
      "K": 4,
      "acc": 0.9666666666666667
    },
    {
      "K": 5,
      "acc": 0.9666666666666667
    },
    {
      "K": 6,
      "acc": 0.9666666666666667
    },
    {
      "K": 7,
      "acc": 0.9666666666666667
    },
    {
      "K": 8,
      "acc": 1.0
    },
    {
      "K": 9,
      "acc": 1.0
    },
    {
      "K": 10,
      "acc": 0.9666666666666667
    },
    {
      "K": 11,
      "acc": 1.0
    },
    {
      "K": 12,
      "acc": 1.0
    },
    {
      "K": 13,
      "acc": 1.0
    },
    {
      "K": 14,
      "acc": 1.0
    },
    {
      "K": 15,
      "acc": 1.0
    },
    {
      "K": 16,
      "acc": 1.0
    },
    {
      "K": 17,
      "acc": 1.0
    },
    {
      "K": 18,
      "acc": 1.0
    },
    {
      "K": 19,
      "acc": 1.0
    },
    {
      "K": 20,
      "acc": 1.0
    }
  ],
  "bestTuningResult": {
    "K": 7,
    "acc": 0.975
  },
  "bestTestingResult": {
    "K": 8,
    "acc": 1.0
  }
}
+ echo 0
0
